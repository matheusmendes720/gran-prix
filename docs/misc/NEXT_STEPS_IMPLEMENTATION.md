# üöÄ Pr√≥ximos Passos - Implementa√ß√£o

## Nova Corrente - Demand Forecasting System

---

## ‚úÖ Progresso Atual

### Conclu√≠do:
1. ‚úÖ **18 datasets configurados** (incluindo 4 brasileiros)
2. ‚úÖ **Pipeline corrigido** (Zenodo funcionando)
3. ‚úÖ **Training datasets atualizados** (valores corretos)
4. ‚úÖ **Documenta√ß√£o criada** (guia completo de datasets brasileiros)
5. ‚úÖ **Suporte GitHub implementado** (download de reposit√≥rios)

### Em Progresso:
1. ‚è≥ **Suporte para downloads diretos** (Anatel, Internet Aberta, Springer)
2. ‚è≥ **Parsing de PDFs** (Internet Aberta forecast)
3. ‚è≥ **Scraping de sites regulat√≥rios** (Anatel)

---

## üìã Implementa√ß√µes Realizadas

### 1. Suporte para Downloads Diretos

**Arquivo:** `src/pipeline/download_datasets.py`

**Melhorias:**
- ‚úÖ Suporte para sources: `anatel`, `internet_aberta`, `springer`
- ‚úÖ Detec√ß√£o autom√°tica de formato de arquivo (PDF, CSV, etc.)
- ‚úÖ Tratamento de query parameters em URLs
- ‚úÖ Suporte para `file_format` no config

**Implementa√ß√£o:**
```python
elif source in ['mit', 'direct', 'anatel', 'internet_aberta', 'springer']:
    # Download direto com suporte para PDFs
    if file_format == 'pdf':
        # Download PDF e preparar para parsing
        logger.info("PDF downloaded. Consider using PDF parsing tools")
```

---

### 2. Parsing de PDFs

**Arquivo:** `src/utils/pdf_parser.py` ‚≠ê NOVO

**Funcionalidades:**
- ‚úÖ Extra√ß√£o de tabelas de PDFs usando m√∫ltiplas bibliotecas:
  - `pdfplumber` (preferencial)
  - `tabula-py`
  - `camelot-py`
- ‚úÖ Extra√ß√£o de texto
- ‚úÖ Suporte para p√°ginas espec√≠ficas
- ‚úÖ Convers√£o autom√°tica para CSV

**Uso:**
```python
from src.utils.pdf_parser import PDFParser

parser = PDFParser()
tables = parser.extract_tables(pdf_path, method='auto')
# Salvar tabelas extra√≠das
csv_files = parser.save_tables_to_csv(tables, output_dir)
```

**Depend√™ncias Adicionadas ao `requirements.txt`:**
- `pdfplumber>=0.10.0`
- `PyPDF2>=3.0.0`
- `tabula-py>=2.5.0`
- `camelot-py[cv]>=0.11.0`

---

### 3. Download de Datasets Anatel

**Arquivo:** `src/pipeline/download_datasets.py`

**M√©todo:** `download_anatel_dataset()` ‚≠ê NOVO

**Funcionalidades:**
- ‚úÖ Scraping da p√°gina Data Basis para encontrar links CSV
- ‚úÖ Fallback para API Data Basis
- ‚úÖ Detec√ß√£o autom√°tica de links de download
- ‚úÖ Suporte para URLs relativas/absolutas

**Implementa√ß√£o:**
```python
def download_anatel_dataset(self, url: str, output_dir: Path, dataset_info: Dict) -> bool:
    # Scraping da p√°gina Data Basis
    # Busca por links CSV
    # Fallback para API
```

---

## üéØ Pr√≥ximos Passos Detalhados

### Passo 1: Testar Downloads dos Novos Datasets

**A√ß√£o:** Testar downloads dos datasets brasileiros

```bash
# Testar download do Zenodo Broadband Brasil (j√° funciona)
python -m src.pipeline.download_datasets --datasets zenodo_broadband_brazil

# Testar download direto (Anatel, Internet Aberta, Springer)
python -m src.pipeline.download_datasets --datasets anatel_mobile_brazil
python -m src.pipeline.download_datasets --datasets internet_aberta_forecast
python -m src.pipeline.download_datasets --datasets springer_digital_divide
```

**Resultado Esperado:**
- ‚úÖ Zenodo Broadband Brasil: Download CSV direto
- ‚è≥ Anatel: Pode requerer scraping refinado
- ‚è≥ Internet Aberta: PDF baixado, requer parsing
- ‚è≥ Springer: Artigo, pode requerer acesso especial

---

### Passo 2: Parsing de PDFs (Internet Aberta)

**A√ß√£o:** Extrair tabelas do PDF do Internet Aberta

```bash
# Ap√≥s download do PDF
python -m src.utils.pdf_parser data/raw/internet_aberta_forecast/ --method pdfplumber --output data/processed/internet_aberta_forecast/
```

**Processo:**
1. Download do PDF
2. Parsing com pdfplumber/tabula
3. Extra√ß√£o de tabelas
4. Convers√£o para CSV
5. Preprocessing padr√£o

---

### Passo 3: Melhorar Scraping Anatel

**A√ß√£o:** Refinar scraping para encontrar links CSV corretos

**Melhorias Necess√°rias:**
1. Verificar estrutura real da p√°gina Data Basis
2. Adicionar seletores CSS mais espec√≠ficos
3. Suporte para autentica√ß√£o se necess√°rio
4. Fallback para download manual com instru√ß√µes

---

### Passo 4: Integrar ao Pipeline Completo

**A√ß√£o:** Adicionar parsing de PDFs ao pipeline de preprocessing

**Modifica√ß√µes:**
- Adicionar passo de parsing de PDFs antes de preprocessing
- Detectar arquivos PDF e extrair tabelas automaticamente
- Integrar tabelas extra√≠das ao fluxo normal

---

### Passo 5: Preprocessing Espec√≠fico Brasileiro

**A√ß√£o:** Criar preprocessing espec√≠fico para contexto brasileiro

**Features Especiais:**
- Tratamento de datas no formato brasileiro (DD/MM/YYYY)
- Normaliza√ß√£o de nomes de regi√µes/estados
- Mapeamento de tecnologias (GSM, 3G, 4G, 5G)
- Agrega√ß√µes por regi√£o/munic√≠pio

---

## üîß Instala√ß√£o de Depend√™ncias

**Instalar bibliotecas de PDF parsing:**

```bash
pip install pdfplumber PyPDF2 tabula-py camelot-py[cv]
```

**Nota:** `camelot-py` requer OpenCV, pode ser mais complexo de instalar:
```bash
# Linux/Mac
pip install camelot-py[cv]

# Windows (pode requerer bin√°rios OpenCV)
pip install camelot-py
```

**Alternativa mais leve:**
```bash
# Usar apenas pdfplumber (mais f√°cil)
pip install pdfplumber
```

---

## üìä Status de Implementa√ß√£o

| Funcionalidade | Status | Prioridade |
|----------------|--------|------------|
| **Downloads Diretos** | ‚úÖ Implementado | Alta |
| **Parsing de PDFs** | ‚úÖ Implementado | Alta |
| **Download Anatel** | ‚úÖ Implementado | M√©dia |
| **Teste Downloads** | ‚è≥ Pendente | Alta |
| **Integra√ß√£o Pipeline** | ‚è≥ Pendente | Alta |
| **Preprocessing Brasileiro** | ‚è≥ Pendente | M√©dia |

---

## üß™ Testes Recomendados

### Teste 1: Download Zenodo Broadband Brasil

```bash
python -m src.pipeline.download_datasets --datasets zenodo_broadband_brazil
```

**Verificar:**
- ‚úÖ CSV baixado corretamente
- ‚úÖ Formato esperado
- ‚úÖ Preprocessing funciona

---

### Teste 2: Download e Parsing PDF (Internet Aberta)

```bash
# 1. Download PDF
python -m src.pipeline.download_datasets --datasets internet_aberta_forecast

# 2. Parsing PDF
python -m src.utils.pdf_parser data/raw/internet_aberta_forecast/*.pdf --method pdfplumber --output data/processed/internet_aberta_forecast/
```

**Verificar:**
- ‚úÖ PDF baixado
- ‚úÖ Tabelas extra√≠das corretamente
- ‚úÖ CSVs gerados e v√°lidos

---

### Teste 3: Download Anatel (com scraping)

```bash
python -m src.pipeline.download_datasets --datasets anatel_mobile_brazil
```

**Verificar:**
- ‚úÖ Scraping encontra links CSV
- ‚úÖ Download funciona
- ‚úÖ Dados no formato esperado

---

## üéØ Resultado Final Esperado

### Datasets Prontos para Uso:

1. **zenodo_broadband_brazil** ‚úÖ
   - Download direto via Zenodo
   - Preprocessing padr√£o
   - Pronto para ML

2. **internet_aberta_forecast** ‚è≥
   - Download PDF ‚úÖ
   - Parsing de tabelas ‚è≥
   - Preprocessing espec√≠fico ‚è≥

3. **anatel_mobile_brazil** ‚è≥
   - Scraping Data Basis ‚è≥
   - Download CSV ‚è≥
   - Preprocessing brasileiro ‚è≥

4. **springer_digital_divide** ‚è≥
   - Download (pode requerer acesso)
   - Preprocessing massivo (~100M registros)
   - Amostragem inicial ‚è≥

---

## üìù Notas Importantes

### 1. PDF Parsing
- **pdfplumber** √© mais confi√°vel para tabelas simples
- **tabula-py** funciona melhor para tabelas complexas
- **camelot-py** √© mais pesado mas mais preciso
- **Recomenda√ß√£o:** Come√ßar com pdfplumber, usar tabula como fallback

### 2. Scraping Anatel
- Data Basis pode mudar estrutura do site
- Pode requerer autentica√ß√£o em alguns casos
- **Fallback:** Instru√ß√µes para download manual

### 3. Dataset Springer (~100M registros)
- Requer Dask para processamento
- **Recomenda√ß√£o:** Amostrar 1-5M registros inicialmente
- Processar em batches
- Usar sampling estratificado

---

## ‚úÖ Checklist de Implementa√ß√£o

- [x] Suporte downloads diretos (Anatel, Internet Aberta, Springer)
- [x] Parsing de PDFs implementado
- [x] Download Anatel com scraping
- [ ] Testar downloads de todos os datasets brasileiros
- [ ] Validar parsing de PDFs
- [ ] Integrar parsing de PDFs ao pipeline
- [ ] Preprocessing espec√≠fico brasileiro
- [ ] Documentar processos e limita√ß√µes

---

**Status:** üöÄ **IMPLEMENTA√á√ÉO INICIADA - Pronto para Testes**

**Pr√≥ximo:** Testar downloads e validar funcionalidades!

---

**Nova Corrente Grand Prix SENAI - Demand Forecasting System**

