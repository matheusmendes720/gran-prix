# üìä Relat√≥rio T√©cnico: Matem√°tica e Machine Learning do Sistema de Previs√£o de Demanda

## Nova Corrente - Demand Forecasting System

---

## üìê 1. Fundamentos Matem√°ticos

### 1.1 Previs√£o de Demanda (Demand Forecasting)

A previs√£o de demanda √© um problema de **time series forecasting** onde queremos prever valores futuros baseados em valores passados.

**Defini√ß√£o Matem√°tica:**

Seja $D_t$ a demanda no tempo $t$, queremos prever $D_{t+h}$ para um horizonte de previs√£o $h$:

$$D_{t+h} = f(D_{t}, D_{t-1}, D_{t-2}, ..., D_{t-n}) + \epsilon_t$$

onde:
- $f(\cdot)$ √© a fun√ß√£o de previs√£o (modelo ML)
- $n$ √© o n√∫mero de observa√ß√µes hist√≥ricas
- $\epsilon_t$ √© o erro aleat√≥rio (ru√≠do)

### 1.2 Ponto de Pedido (Reorder Point - PP)

O **Ponto de Pedido (PP)** √© calculado quando o estoque atinge um n√≠vel que garante que haver√° estoque suficiente durante o **lead time** (tempo de entrega do fornecedor).

**F√≥rmula do PP:**

$$PP = (D_{avg} \times LT) + SS$$

onde:
- $D_{avg}$ = Demanda m√©dia di√°ria prevista
- $LT$ = Lead Time (tempo de entrega em dias)
- $SS$ = Safety Stock (estoque de seguran√ßa)

**Estoque de Seguran√ßa (Safety Stock):**

$$SS = Z_{\alpha} \times \sigma_D \times \sqrt{LT}$$

onde:
- $Z_{\alpha}$ = Valor cr√≠tico da distribui√ß√£o normal (ex: $Z_{0.95} = 1.65$ para 95% de confian√ßa)
- $\sigma_D$ = Desvio padr√£o da demanda
- $LT$ = Lead Time

**Demanda M√©dia:**

$$D_{avg} = \frac{1}{n} \sum_{i=1}^{n} D_i$$

**Desvio Padr√£o da Demanda:**

$$\sigma_D = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (D_i - D_{avg})^2}$$

---

## ü§ñ 2. Modelos de Machine Learning

### 2.1 ARIMA (AutoRegressive Integrated Moving Average)

**ARIMA(p, d, q)** √© um modelo para s√©ries temporais que combina:
- **AR(p)**: Auto-regress√£o de ordem $p$
- **I(d)**: Diferencia√ß√£o de ordem $d$ (para tornar estacion√°ria)
- **MA(q)**: M√©dia m√≥vel de ordem $q$

**Modelo ARIMA:**

$$D_t = \phi_1 D_{t-1} + \phi_2 D_{t-2} + ... + \phi_p D_{t-p} + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + ... + \theta_q \epsilon_{t-q} + \epsilon_t$$

onde:
- $\phi_i$ = Par√¢metros AR
- $\theta_i$ = Par√¢metros MA
- $\epsilon_t$ = Erro aleat√≥rio (ru√≠do branco)
- $D_t$ = Demanda no tempo $t$

**Com Diferencia√ß√£o (para n√£o-estacionariedade):**

Se $y_t = D_t - D_{t-1}$ (diferen√ßa de primeira ordem):

$$y_t = \phi_1 y_{t-1} + ... + \phi_p y_{t-p} + \theta_1 \epsilon_{t-1} + ... + \theta_q \epsilon_{t-q} + \epsilon_t$$

**Algoritmo de Treinamento ARIMA:**

```
ALGORITMO: ARIMA_Training
INPUT: Series D = [D_1, D_2, ..., D_n]
OUTPUT: Model ARIMA(p, d, q), Forecast

1. // Verificar estacionariedade
2. d ‚Üê ADF_Test(D)  // Augmented Dickey-Fuller test
3. IF d > 0 THEN
4.     D ‚Üê Difference(D, d)  // Aplicar diferencia√ß√£o
5. END IF
6.
7. // Sele√ß√£o autom√°tica de ordem (auto_arima)
8. (p, q) ‚Üê Auto_ARIMA_Selection(D)
9.     // Grid search em p ‚àà [0, 5], q ‚àà [0, 5]
10.    // M√©trica: AIC (Akaike Information Criterion)
11.    // AIC = 2k - 2ln(L)
12.    // onde k = n√∫mero de par√¢metros, L = likelihood
13.
14. // Treinar modelo
15. model ‚Üê ARIMA(D, order=(p, d, q))
16. model.fit()
17.
18. // Previs√£o
19. Forecast ‚Üê model.forecast(steps=h)
20. RETURN model, Forecast
```

**AIC (Akaike Information Criterion):**

$$AIC = 2k - 2\ln(L)$$

onde:
- $k$ = n√∫mero de par√¢metros do modelo
- $L$ = likelihood (verossimilhan√ßa)

### 2.2 SARIMAX (Seasonal ARIMA with eXogenous variables)

**SARIMAX(p, d, q)(P, D, Q, s)** estende ARIMA para:
- **Sazonalidade**: Padr√µes que se repetem em intervalos fixos (ex: semanal, mensal)
- **Regressores Externos**: Vari√°veis ex√≥genas (clima, econ√¥micas, etc.)

**Modelo SARIMAX:**

$$D_t = \phi_1 D_{t-1} + ... + \phi_p D_{t-p} + \Phi_1 D_{t-s} + ... + \Phi_P D_{t-Ps} +$$
$$\quad + \theta_1 \epsilon_{t-1} + ... + \theta_q \epsilon_{t-q} + \Theta_1 \epsilon_{t-s} + ... + \Theta_Q \epsilon_{t-Qs} +$$
$$\quad + \beta_1 X_{1,t} + \beta_2 X_{2,t} + ... + \beta_k X_{k,t} + \epsilon_t$$

onde:
- $(p, d, q)$ = Ordem n√£o-sazonal
- $(P, D, Q, s)$ = Ordem sazonal (s = per√≠odo sazonal, ex: 7 para semanal)
- $\Phi_i, \Theta_i$ = Par√¢metros sazonais
- $X_{i,t}$ = Regressores externos no tempo $t$
- $\beta_i$ = Coeficientes dos regressores

**Fatores Externos Integrados:**

Com fatores externos (clima, econ√¥micos, etc.):

$$D_t = ARIMA\_Component + \beta_1 Temp_t + \beta_2 Precip_t + \beta_3 Inflation_t + \beta_4 Holiday_t + \epsilon_t$$

### 2.3 Prophet (Facebook Prophet)

**Prophet** √© um modelo aditivo que decomp√µe a s√©rie temporal em componentes:

**Modelo Prophet:**

$$D_t = g(t) + s(t) + h(t) + \epsilon_t$$

onde:
- $g(t)$ = Componente de tend√™ncia (trend)
- $s(t)$ = Componente sazonal (seasonality)
- $h(t)$ = Componente de feriados/eventos
- $\epsilon_t$ = Erro aleat√≥rio

**Componente de Tend√™ncia (Linear ou Logistic):**

**Tend√™ncia Linear:**

$$g(t) = (k + \mathbf{a}(t)^T \boldsymbol{\delta}) \cdot t + (m + \mathbf{a}(t)^T \boldsymbol{\gamma})$$

**Tend√™ncia Logistic (com capacidade $C$):**

$$g(t) = \frac{C}{1 + \exp(-(k + \mathbf{a}(t)^T \boldsymbol{\delta})(t - (m + \mathbf{a}(t)^T \boldsymbol{\gamma})))}$$

onde:
- $k$ = Taxa de crescimento
- $\boldsymbol{\delta}$ = Ajustes de crescimento em pontos de mudan√ßa
- $m$ = Par√¢metro de offset
- $\boldsymbol{\gamma}$ = Ajustes de offset

**Componente Sazonal (Fourier Series):**

$$s(t) = \sum_{n=1}^{N} \left( a_n \cos\left(\frac{2\pi n t}{P}\right) + b_n \sin\left(\frac{2\pi n t}{P}\right) \right)$$

onde:
- $P$ = Per√≠odo sazonal (ex: 365.25 para anual, 7 para semanal)
- $N$ = N√∫mero de termos de Fourier
- $a_n, b_n$ = Coeficientes de Fourier

**Componente de Feriados/Eventos:**

$$h(t) = \sum_{i=1}^{L} \kappa_i \cdot \mathbf{1}_{\{t \in D_i\}}$$

onde:
- $D_i$ = Conjunto de dias do evento $i$
- $\kappa_i$ = Efeito do evento $i$
- $\mathbf{1}_{\{t \in D_i\}}$ = Fun√ß√£o indicadora (1 se $t \in D_i$, 0 caso contr√°rio)

**Regressores Externos no Prophet:**

$$D_t = g(t) + s(t) + h(t) + \sum_{j=1}^{K} \beta_j X_{j,t} + \epsilon_t$$

onde $X_{j,t}$ s√£o as vari√°veis externas (temperatura, infla√ß√£o, etc.).

**Algoritmo de Treinamento Prophet:**

```
ALGORITMO: Prophet_Training
INPUT: Series D = [D_1, D_2, ..., D_n], Dates, External Vars X
OUTPUT: Prophet Model, Forecast

1. // Preparar dados no formato Prophet (ds, y)
2. FOR i = 1 TO n DO
3.     prophet_df[i].ds ‚Üê Dates[i]  // Data
4.     prophet_df[i].y ‚Üê D[i]      // Demanda
5.     FOR j = 1 TO K DO
6.         prophet_df[i].X_j ‚Üê X[j, i]  // Regressores externos
7.     END FOR
8. END FOR
9.
10. // Inicializar modelo
11. model ‚Üê Prophet(
12.     yearly_seasonality = True,  // Sazonalidade anual
13.     weekly_seasonality = True,  // Sazonalidade semanal
14.     daily_seasonality = False
15. )
16.
17. // Adicionar regressores externos
18. FOR j = 1 TO K DO
19.     model.add_regressor('X_' + j)
20. END FOR
21.
22. // Treinar modelo (Stan backend - Bayesian inference)
23. model.fit(prophet_df)
24.
25. // Criar dataframe futuro
26. future ‚Üê model.make_future_dataframe(periods=h)
27. FOR j = 1 TO K DO
28.     future['X_' + j] ‚Üê Get_Future_External_Vars(X_j, h)
29. END FOR
30.
31. // Previs√£o
32. Forecast ‚Üê model.predict(future)
33. RETURN model, Forecast
```

### 2.4 LSTM (Long Short-Term Memory)

**LSTM** √© uma rede neural recorrente (RNN) especializada em aprender depend√™ncias de longo prazo em s√©ries temporais.

**Equa√ß√µes do LSTM:**

**Forget Gate (Porta de Esquecimento):**

$$f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f)$$

**Input Gate (Porta de Entrada):**

$$i_t = \sigma(W_i \cdot [h_{t-1}, x_t] + b_i)$$

$$\tilde{C}_t = \tanh(W_C \cdot [h_{t-1}, x_t] + b_C)$$

**Cell State (Estado da C√©lula):**

$$C_t = f_t \odot C_{t-1} + i_t \odot \tilde{C}_t$$

**Output Gate (Porta de Sa√≠da):**

$$o_t = \sigma(W_o \cdot [h_{t-1}, x_t] + b_o)$$

$$h_t = o_t \odot \tanh(C_t)$$

onde:
- $x_t$ = Input no tempo $t$
- $h_t$ = Hidden state (estado oculto) no tempo $t$
- $C_t$ = Cell state no tempo $t$
- $W_f, W_i, W_C, W_o$ = Matrizes de pesos
- $b_f, b_i, b_C, b_o$ = Vieses (bias)
- $\sigma$ = Fun√ß√£o sigmoid: $\sigma(x) = \frac{1}{1 + e^{-x}}$
- $\tanh$ = Fun√ß√£o tangente hiperb√≥lica: $\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}$
- $\odot$ = Multiplica√ß√£o elemento-a-elemento (Hadamard product)

**Previs√£o LSTM:**

Para prever $D_{t+h}$, usamos uma janela deslizante (sliding window) de tamanho $L$:

$$D_{t+h} = LSTM([D_{t-L+1}, D_{t-L+2}, ..., D_t])$$

**Estrutura de Dados para LSTM:**

```
ESTRUTURA: LSTM_Data
{
    X: Array[L x Features]  // Janela de L timesteps
    y: Scalar                // Target (pr√≥ximo valor)
}

Exemplo para L=30:
X = [D_t-29, D_t-28, ..., D_t]  // 30 valores passados
y = D_t+1                        // Pr√≥ximo valor
```

**Algoritmo de Treinamento LSTM:**

```
ALGORITMO: LSTM_Training
INPUT: Series D = [D_1, D_2, ..., D_n], Look_Back L, Hidden_Units H
OUTPUT: LSTM Model, Forecast

1. // Normaliza√ß√£o (Min-Max Scaling)
2. scaler ‚Üê MinMaxScaler()
3. D_scaled ‚Üê scaler.fit_transform(D)
4.
5. // Criar janelas deslizantes
6. X, y ‚Üê []
7. FOR i = L TO n-1 DO
8.     X.append(D_scaled[i-L:i])    // Janela de L valores
9.     y.append(D_scaled[i+1])       // Pr√≥ximo valor
10. END FOR
11. X ‚Üê reshape(X, [n-L, L, 1])      // [samples, timesteps, features]
12.
13. // Split train/test
14. split_idx ‚Üê int(0.8 * len(X))
15. X_train, X_test ‚Üê X[:split_idx], X[split_idx:]
16. y_train, y_test ‚Üê y[:split_idx], y[split_idx:]
17.
18. // Construir modelo LSTM
19. model ‚Üê Sequential()
20. model.add(LSTM(H, return_sequences=True, input_shape=(L, 1)))
21. model.add(LSTM(H, return_sequences=False))
22. model.add(Dense(1))  // Camada de sa√≠da
23.
24. // Compilar
25. model.compile(
26.     optimizer='adam',  // Adaptive Moment Estimation
27.     loss='mse'        // Mean Squared Error
28. )
29.
30. // Treinar
31. model.fit(X_train, y_train, epochs=E, batch_size=B)
32.
33. // Previs√£o
34. Forecast ‚Üê []
35. inputs ‚Üê X_test[-1:]  // √öltima janela
36. FOR i = 1 TO h DO
37.     pred ‚Üê model.predict(inputs)
38.     Forecast.append(pred)
39.     inputs ‚Üê append(inputs[:, 1:, :], pred, axis=1)  // Deslizar janela
40. END FOR
41.
42. // Desnormalizar
43. Forecast ‚Üê scaler.inverse_transform(Forecast)
44. RETURN model, Forecast
```

**Adam Optimizer:**

Adam adapta a taxa de aprendizado para cada par√¢metro:

$$m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t$$

$$v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2$$

$$m_t^{corrigido} = \frac{m_t}{1 - \beta_1^t}$$

$$v_t^{corrigido} = \frac{v_t}{1 - \beta_2^t}$$

$$\theta_{t+1} = \theta_t - \frac{\alpha}{\sqrt{v_t^{corrigido}} + \epsilon} m_t^{corrigido}$$

onde:
- $g_t$ = Gradiente no tempo $t$
- $\beta_1, \beta_2$ = Hiperpar√¢metros (tipicamente 0.9 e 0.999)
- $\alpha$ = Taxa de aprendizado
- $\epsilon$ = Pequeno valor para estabilidade num√©rica ($10^{-8}$)

### 2.5 Ensemble Methods (M√©todos de Conjunto)

Combinar m√∫ltiplos modelos geralmente melhora a precis√£o:

**Weighted Average Ensemble:**

$$\hat{D}_{t+h} = \sum_{i=1}^{M} w_i \cdot \hat{D}_{i,t+h}$$

onde:
- $M$ = N√∫mero de modelos
- $w_i$ = Peso do modelo $i$ (normalizado: $\sum_{i=1}^{M} w_i = 1$)
- $\hat{D}_{i,t+h}$ = Previs√£o do modelo $i$

**Pesos Otimizados (Bayesian Optimization):**

Encontrar os pesos √≥timos que minimizam o erro:

$$\mathbf{w}^* = \arg\min_{\mathbf{w}} \sum_{t=1}^{T} \left(D_t - \sum_{i=1}^{M} w_i \hat{D}_{i,t}\right)^2$$

sujeito a:
- $\sum_{i=1}^{M} w_i = 1$
- $w_i \geq 0$ para todo $i$

**Stacking Ensemble:**

Usa um meta-learner para combinar previs√µes:

**N√≠vel 1 (Base Models):**
- $M_1, M_2, ..., M_K$ = Modelos base (ARIMA, Prophet, LSTM)

**N√≠vel 2 (Meta-Learner):**
$$\hat{D}_{t+h} = MetaLearner([\hat{D}_{1,t+h}, \hat{D}_{2,t+h}, ..., \hat{D}_{K,t+h}])$$

O meta-learner pode ser Linear Regression, Random Forest, etc.

**Algoritmo de Ensemble:**

```
ALGORITMO: Ensemble_Forecast
INPUT: Base Models [M_1, M_2, ..., M_K], Training Data D
OUTPUT: Ensemble Forecast

1. // Treinar modelos base
2. FOR i = 1 TO K DO
3.     M_i.fit(D)
4.     predictions[i] ‚Üê M_i.forecast()
5. END FOR
6.
7. // M√©todo 1: Weighted Average
8. weights ‚Üê Optimize_Weights(predictions, D_actual)
9. ensemble_forecast ‚Üê Weighted_Average(predictions, weights)
10.
11. // M√©todo 2: Stacking
12. meta_X ‚Üê Stack_Horizontally(predictions)  // [n_samples, K]
13. meta_y ‚Üê D_actual
14. meta_learner ‚Üê LinearRegression()
15. meta_learner.fit(meta_X, meta_y)
16. ensemble_forecast ‚Üê meta_learner.predict(meta_X_future)
17.
18. RETURN ensemble_forecast
```

---

## üìä 3. Processamento de Dados

### 3.1 Pr√©-processamento

**Normaliza√ß√£o Min-Max:**

$$X_{normalized} = \frac{X - X_{min}}{X_{max} - X_{min}}$$

**Padroniza√ß√£o (Z-score):**

$$X_{standardized} = \frac{X - \mu}{\sigma}$$

onde:
- $\mu$ = M√©dia: $\mu = \frac{1}{n}\sum_{i=1}^{n} X_i$
- $\sigma$ = Desvio padr√£o: $\sigma = \sqrt{\frac{1}{n-1}\sum_{i=1}^{n}(X_i - \mu)^2}$

**Tratamento de Valores Ausentes (Forward Fill):**

$$D_t^{filled} = \begin{cases}
D_t & \text{se } D_t \text{ n√£o √© NaN} \\
D_{t-1}^{filled} & \text{se } D_t \text{ √© NaN}
\end{cases}$$

**Detec√ß√£o de Outliers (IQR Method):**

**Interquartile Range (IQR):**

$$IQR = Q_3 - Q_1$$

onde $Q_1, Q_3$ s√£o o primeiro e terceiro quartis.

**Limites:**
- **Lower Bound:** $LB = Q_1 - 1.5 \times IQR$
- **Upper Bound:** $UB = Q_3 + 1.5 \times IQR$

**Remo√ß√£o de Outliers:**

$$D_t^{clean} = \begin{cases}
D_t & \text{se } LB \leq D_t \leq UB \\
\text{NaN} & \text{caso contr√°rio}
\end{cases}$$

### 3.2 Feature Engineering

**Features Temporais:**

**Sazonalidade C√≠clica (Sine/Cosine Encoding):**

$$month\_sin = \sin\left(\frac{2\pi \times month}{12}\right)$$

$$month\_cos = \cos\left(\frac{2\pi \times month}{12}\right)$$

**Features de Fim de Semana:**

$$is\_weekend = \begin{cases}
1 & \text{se } weekday \geq 5 \\
0 & \text{caso contr√°rio}
\end{cases}$$

**Features de Feriados:**

$$is\_holiday = \begin{cases}
1 & \text{se } date \in Holidays \\
0 & \text{caso contr√°rio}
\end{cases}$$

**Agrega√ß√£o Di√°ria:**

Se temos dados em granularidade menor (ex: hor√°ria), agregamos para di√°ria:

$$D_{daily} = \sum_{i=1}^{H} D_{hourly,i}$$

onde $H$ √© o n√∫mero de horas no dia (ex: $H = 24$).

### 3.3 Integra√ß√£o de Fatores Externos

**Ajuste de Demanda com Fatores Externos:**

$$D_{adjusted} = D_{base} \times (1 + \alpha_1 \times Climate_{impact} + \alpha_2 \times Economic_{impact} + \alpha_3 \times Operational_{impact})$$

onde:
- $D_{base}$ = Demanda base prevista (sem fatores externos)
- $\alpha_i$ = Coeficientes de impacto (pesos)
- $Climate_{impact}$ = Score de impacto clim√°tico
- $Economic_{impact}$ = Score de impacto econ√¥mico
- $Operational_{impact}$ = Score de impacto operacional

**C√°lculo de Scores de Impacto:**

**Climate Impact Score:**

$$Climate_{impact} = w_1 \times \frac{Temp_t - Temp_{normal}}{Temp_{normal}} + w_2 \times \frac{Precip_t - Precip_{normal}}{Precip_{normal}} + w_3 \times Extreme_{weather}$$

onde:
- $w_1, w_2, w_3$ = Pesos (ex: 0.4, 0.4, 0.2)
- $Temp_{normal}$ = Temperatura m√©dia hist√≥rica
- $Precip_{normal}$ = Precipita√ß√£o m√©dia hist√≥rica
- $Extreme_{weather}$ = Flag de clima extremo (0 ou 1)

**Economic Impact Score:**

$$Economic_{impact} = w_1 \times \frac{Inflation_t - Inflation_{normal}}{Inflation_{normal}} + w_2 \times \frac{Exchange_t - Exchange_{normal}}{Exchange_{normal}} + w_3 \times High_{inflation}$$

**Operational Impact Score:**

$$Operational_{impact} = w_1 \times Is_{holiday} + w_2 \times Is_{vacation} + w_3 \times SLA_{renewal}$$

**Demand Adjustment Factor:**

$$Demand_{adjustment} = 1 + Climate_{impact} + Economic_{impact} + Operational_{impact}$$

---

## üîÑ 4. Pipeline de Processamento

### 4.1 Estrutura de Dados

**Estrutura: Unified Dataset**

```
STRUCTURE: UnifiedDataset
{
    // Colunas Base
    date: DateTime           // Data/timestamp
    item_id: String         // ID do item
    item_name: String       // Nome do item
    quantity: Float         // Quantidade/demanda
    site_id: String         // ID do site/torre
    category: String        // Categoria
    cost: Float            // Custo unit√°rio
    lead_time: Integer     // Tempo de entrega (dias)
    dataset_source: String  // Origem do dado
    
    // Fatores Clim√°ticos
    temperature: Float      // Temperatura (¬∞C)
    precipitation: Float    // Precipita√ß√£o (mm)
    humidity: Float        // Umidade (%)
    extreme_heat: Boolean   // Flag calor extremo
    heavy_rain: Boolean    // Flag chuva forte
    high_humidity: Boolean // Flag umidade alta
    
    // Fatores Econ√¥micos
    exchange_rate_brl_usd: Float  // Taxa de c√¢mbio
    inflation_rate: Float        // Taxa de infla√ß√£o (%)
    gdp_growth: Float           // Crescimento PIB (%)
    high_inflation: Boolean     // Flag infla√ß√£o alta
    currency_devaluation: Boolean // Flag desvaloriza√ß√£o
    
    // Fatores Regulat√≥rios
    five_g_coverage: Boolean           // Cobertura 5G
    regulatory_compliance_date: DateTime // Data compliance
    five_g_expansion_rate: Float      // Taxa expans√£o 5G
    
    // Fatores Operacionais
    is_holiday: Boolean          // Flag feriado
    is_vacation_period: Boolean // Flag per√≠odo f√©rias
    sla_renewal_period: Boolean  // Flag renova√ß√£o SLA
    weekend: Boolean            // Flag fim de semana
    
    // Scores de Impacto
    climate_impact: Float       // Score impacto clim√°tico
    economic_impact: Float      // Score impacto econ√¥mico
    operational_impact: Float   // Score impacto operacional
    demand_adjustment_factor: Float // Fator ajuste demanda
}
```

### 4.2 Algoritmo de Preprocessing

```
ALGORITMO: Preprocessing_Pipeline
INPUT: Raw Dataset D_raw
OUTPUT: Preprocessed Dataset D_processed

1. // Carregar dados
2. D ‚Üê Load_CSV(D_raw)
3.
4. // Mapeamento de colunas
5. D.date ‚Üê Map_Column(D, "Date") ‚Üí "date"
6. D.item_id ‚Üê Map_Column(D, "Item_ID") ‚Üí "item_id"
7. D.quantity ‚Üê Map_Column(D, "Demand") ‚Üí "quantity"
8. // ... outros mapeamentos
9.
10. // Padroniza√ß√£o de datas
11. FOR each row in D DO
12.     D[row].date ‚Üê Parse_Date(D[row].date)
13.     // Formatos aceitos: YYYY-MM-DD, DD/MM/YYYY, etc.
14. END FOR
15.
16. // Feature Engineering Temporal
17. D.year ‚Üê Extract_Year(D.date)
18. D.month ‚Üê Extract_Month(D.date)
19. D.day ‚Üê Extract_Day(D.date)
20. D.weekday ‚Üê Extract_Weekday(D.date)
21. D.weekend ‚Üê (D.weekday >= 5) ? 1 : 0
22. D.month_sin ‚Üê sin(2œÄ √ó D.month / 12)
23. D.month_cos ‚Üê cos(2œÄ √ó D.month / 12)
24.
25. // Tratamento de valores ausentes
26. D ‚Üê Forward_Fill(D)  // Preencher com valor anterior
27.
28. // Detec√ß√£o de outliers
29. outliers ‚Üê IQR_Method(D.quantity)
30. D ‚Üê Remove_Rows(D, outliers)
31.
32. // Agrega√ß√£o di√°ria (se necess√°rio)
33. IF granularity != "daily" THEN
34.     D ‚Üê Aggregate_To_Daily(D, aggregation="sum")
35. END IF
36.
37. // Adicionar colunas faltantes com valores padr√£o
38. IF missing("lead_time") THEN
39.     D.lead_time ‚Üê Default_Lead_Time  // Ex: 14 dias
40. END IF
41.
42. RETURN D
```

### 4.3 Algoritmo de Merge

```
ALGORITMO: Merge_Datasets
INPUT: Preprocessed Datasets [D_1, D_2, ..., D_K]
OUTPUT: Unified Dataset D_unified

1. // Schema Validation
2. unified_schema ‚Üê Load_Schema("unified_schema.json")
3. required_cols ‚Üê unified_schema.required_columns
4.
5. // Validar e preparar cada dataset
6. valid_datasets ‚Üê []
7. FOR i = 1 TO K DO
8.     IF Validate_Schema(D_i, required_cols) THEN
9.         D_i_prepared ‚Üê Select_Columns(D_i, unified_schema.columns)
10.         D_i_prepared ‚Üê Ensure_Types(D_i_prepared, unified_schema.data_types)
11.         valid_datasets.append(D_i_prepared)
12.     ELSE
13.         LOG_WARNING("Dataset " + i + " skipped: missing columns")
14.     END IF
15. END FOR
16.
17. // Concatenar datasets v√°lidos
18. D_unified ‚Üê Concatenate(valid_datasets)
19.
20. // Remover duplicatas
21. D_unified ‚Üê Remove_Duplicates(D_unified, keys=["date", "item_id", "site_id"])
22.
23. // Ordenar por data
24. D_unified ‚Üê Sort(D_unified, by="date")
25.
26. RETURN D_unified
```

### 4.4 Algoritmo de External Factors

```
ALGORITMO: Add_External_Factors
INPUT: Unified Dataset D
OUTPUT: Enriched Dataset D_enriched

1. // Fatores Clim√°ticos
2. FOR each row in D DO
3.     D[row].temperature ‚Üê Generate_Temperature(row.date)
4.     D[row].precipitation ‚Üê Generate_Precipitation(row.date)
5.     D[row].humidity ‚Üê Generate_Humidity(row.date)
6.     D[row].extreme_heat ‚Üê (D[row].temperature > 35) ? 1 : 0
7.     D[row].heavy_rain ‚Üê (D[row].precipitation > 50) ? 1 : 0
8.     D[row].high_humidity ‚Üê (D[row].humidity > 80) ? 1 : 0
9. END FOR
10.
11. // Fatores Econ√¥micos
12. FOR each row in D DO
13.     D[row].exchange_rate_brl_usd ‚Üê Get_Exchange_Rate(row.date)
14.     D[row].inflation_rate ‚Üê Get_Inflation_Rate(row.date)
15.     D[row].gdp_growth ‚Üê Get_GDP_Growth(row.date)
16.     D[row].high_inflation ‚Üê (D[row].inflation_rate > 5) ? 1 : 0
17.     D[row].currency_devaluation ‚Üê (D[row].exchange_rate > 5.5) ? 1 : 0
18. END FOR
19.
20. // Fatores Regulat√≥rios
21. FOR each row in D DO
22.     D[row].five_g_coverage ‚Üê Check_5G_Coverage(row.date)
23.     D[row].five_g_expansion_rate ‚Üê Get_5G_Expansion_Rate(row.date)
24. END FOR
25.
26. // Fatores Operacionais
27. holidays ‚Üê Load_Brazilian_Holidays()
28. FOR each row in D DO
29.     D[row].is_holiday ‚Üê (row.date in holidays) ? 1 : 0
30.     D[row].is_vacation_period ‚Üê Check_Vacation_Period(row.date)
31.     D[row].sla_renewal_period ‚Üê Check_SLA_Renewal(row.date)
32.     D[row].weekend ‚Üê (row.date.weekday >= 5) ? 1 : 0
33. END FOR
34.
35. // Calcular Scores de Impacto
36. FOR each row in D DO
37.     D[row].climate_impact ‚Üê Calculate_Climate_Impact(row)
38.     D[row].economic_impact ‚Üê Calculate_Economic_Impact(row)
39.     D[row].operational_impact ‚Üê Calculate_Operational_Impact(row)
40.     D[row].demand_adjustment_factor ‚Üê 
41.         1 + D[row].climate_impact + D[row].economic_impact + D[row].operational_impact
42. END FOR
43.
44. RETURN D
```

---

## üìà 5. M√©tricas de Avalia√ß√£o

### 5.1 MAPE (Mean Absolute Percentage Error)

$$MAPE = \frac{100}{n} \sum_{i=1}^{n} \left|\frac{D_i - \hat{D}_i}{D_i}\right|$$

onde:
- $D_i$ = Valor real
- $\hat{D}_i$ = Valor previsto
- $n$ = N√∫mero de observa√ß√µes

**Interpreta√ß√£o:** MAPE < 15% √© considerado bom para demand forecasting.

### 5.2 RMSE (Root Mean Squared Error)

$$RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (D_i - \hat{D}_i)^2}$$

**Interpreta√ß√£o:** Menor √© melhor. Mede a magnitude do erro.

### 5.3 MAE (Mean Absolute Error)

$$MAE = \frac{1}{n} \sum_{i=1}^{n} |D_i - \hat{D}_i|$$

### 5.4 R¬≤ (Coefficient of Determination)

$$R^2 = 1 - \frac{\sum_{i=1}^{n}(D_i - \hat{D}_i)^2}{\sum_{i=1}^{n}(D_i - \bar{D})^2}$$

onde $\bar{D} = \frac{1}{n}\sum_{i=1}^{n} D_i$ √© a m√©dia.

**Interpreta√ß√£o:** $R^2 \in [0, 1]$. Quanto maior, melhor (1 = perfeito).

---

## üéØ 6. Sistema de Alertas

### 6.1 C√°lculo do Ponto de Pedido Din√¢mico

**PP com Demanda Ajustada por Fatores Externos:**

$$PP_{adjusted} = (D_{avg} \times AF \times LT) + SS$$

onde:
- $AF$ = Adjustment Factor (Fator de ajuste)
- $AF = 1 + Climate_{impact} + Economic_{impact} + Operational_{impact}$

**Safety Stock Adaptativo:**

$$SS_{adaptive} = Z_{\alpha} \times \sigma_D \times \sqrt{LT} \times (1 + \sigma_{external})$$

onde $\sigma_{external}$ captura a variabilidade dos fatores externos.

### 6.2 Algoritmo de Alerta

```
ALGORITMO: Check_Reorder_Alert
INPUT: Current Stock S, Item ID, Forecast, Lead Time LT, Safety Stock SS
OUTPUT: Alert Status

1. // Calcular demanda m√©dia prevista
2. D_avg ‚Üê Mean(Forecast)
3.
4. // Calcular PP
5. PP ‚Üê (D_avg √ó LT) + SS
6.
7. // Verificar se precisa reordenar
8. IF S <= PP THEN
9.     // Calcular dias at√© ruptura
10.    days_to_rupture ‚Üê (S - SS) / D_avg
11.    
12.    // Calcular quantidade a reordenar
13.    reorder_quantity ‚Üê PP - S + Safety_Buffer
14.    
15.    // Gerar alerta
16.    alert ‚Üê {
17.        item_id: Item_ID,
18.        current_stock: S,
19.        reorder_point: PP,
20.        days_to_rupture: days_to_rupture,
21.        reorder_quantity: reorder_quantity,
22.        priority: Calculate_Priority(days_to_rupture)
23.    }
24.    
25.    Send_Alert(alert)
26.    RETURN alert
27. END IF
28.
29. RETURN null  // Sem alerta necess√°rio
```

**C√°lculo de Dias at√© Ruptura:**

$$Days\_to\_Rupture = \frac{S - SS}{D_{avg}}$$

**Quantidade a Reordenar:**

$$Reorder\_Quantity = (PP - S) + Safety\_Buffer$$

onde $Safety\_Buffer$ √© um buffer adicional (ex: 10% do PP).

---

## üî¨ 7. Otimiza√ß√£o e Hiperpar√¢metros

### 7.1 Bayesian Optimization

Para otimizar hiperpar√¢metros automaticamente:

**Objective Function:**

$$f^* = \arg\min_{\theta} MAPE(\theta)$$

onde $\theta$ s√£o os hiperpar√¢metros (ex: ordem ARIMA, learning rate LSTM).

**Acquisition Function (Expected Improvement):**

$$EI(x) = \mathbb{E}[\max(0, f^* - f(x))]$$

O algoritmo explora o espa√ßo de hiperpar√¢metros balanceando **exploration** e **exploitation**.

### 7.2 Grid Search vs Random Search vs Bayesian

**Grid Search:** Exaustivo, mas lento:

$$\theta^* = \arg\min_{\theta \in Grid} MAPE(\theta)$$

**Random Search:** Mais eficiente que Grid:

$$\theta^* = \arg\min_{\theta \in Random\_Samples} MAPE(\theta)$$

**Bayesian Optimization:** Mais eficiente, usa hist√≥rico:

$$\theta^* = \arg\min_{\theta \in Bayesian\_Space} MAPE(\theta)$$

---

## üìä 8. Valida√ß√£o Cruzada para S√©ries Temporais

### 8.1 Walk-Forward Validation

**Time Series Cross-Validation (TimeSeriesSplit):**

```
ALGORITMO: Walk_Forward_Validation
INPUT: Time Series D = [D_1, ..., D_n], Model M
OUTPUT: Validation Scores

1. // Dividir em K folds
2. FOR fold = 1 TO K DO
3.     train_end ‚Üê (fold / K) √ó n
4.     test_start ‚Üê train_end + 1
5.     test_end ‚Üê min(test_start + window_size, n)
6.     
7.     D_train ‚Üê D[1:train_end]
8.     D_test ‚Üê D[test_start:test_end]
9.     
10.    // Treinar modelo
11.    M.fit(D_train)
12.    
13.    // Previs√£o
14.    Forecast ‚Üê M.predict(length(D_test))
15.    
16.    // Avaliar
17.    MAPE[fold] ‚Üê Calculate_MAPE(D_test, Forecast)
18.    RMSE[fold] ‚Üê Calculate_RMSE(D_test, Forecast)
19. END FOR
20.
21. RETURN Mean(MAPE), Mean(RMSE)
```

**Estrutura Visual:**

```
Fold 1: [Train: 1‚Üí60] [Test: 61‚Üí80]
Fold 2: [Train: 1‚Üí80] [Test: 81‚Üí100]
Fold 3: [Train: 1‚Üí100] [Test: 101‚Üí120]
...
```

---

## üèóÔ∏è 9. Arquitetura do Sistema

### 9.1 Fluxo de Dados

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Raw Datasets   ‚îÇ
‚îÇ  (Kaggle, etc.)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Download      ‚îÇ
‚îÇ   (5 datasets)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Preprocessing  ‚îÇ
‚îÇ  - Mapping      ‚îÇ
‚îÇ  - Cleaning     ‚îÇ
‚îÇ  - Engineering  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     Merge       ‚îÇ
‚îÇ   (Schema Val)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ External Factors‚îÇ
‚îÇ (22 features)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Unified Dataset‚îÇ
‚îÇ  118,082 rows   ‚îÇ
‚îÇ   31 columns    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Train/Test     ‚îÇ
‚îÇ    Split        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ML Models      ‚îÇ
‚îÇ  (ARIMA, etc.)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Forecast + PP   ‚îÇ
‚îÇ   + Alerts     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 9.2 Estrutura de Classes

```
CLASS: ForecastEngine
{
    // M√©todos principais
    fit(data): Train model
    forecast(steps): Generate forecast
    calculate_pp(forecast, lead_time): Calculate reorder point
    check_alert(current_stock, pp): Check if reorder needed
    
    // M√©todos auxiliares
    validate_data(data): Validate input data
    preprocess(data): Preprocess data
    evaluate(actual, predicted): Calculate metrics
}

CLASS: ARIMAForecaster extends ForecastEngine
{
    order: (p, d, q)
    model: ARIMA model
    
    fit(data):
        auto_arima ‚Üí select_order()
        model.fit()
    
    forecast(steps):
        return model.forecast(steps)
}

CLASS: ProphetForecaster extends ForecastEngine
{
    model: Prophet model
    
    fit(data):
        model.add_regressors(external_vars)
        model.fit(data)
    
    forecast(steps):
        future = make_future_dataframe(steps)
        return model.predict(future)
}

CLASS: LSTMForecaster extends ForecastEngine
{
    model: Sequential LSTM
    scaler: MinMaxScaler
    look_back: int
    
    fit(data):
        data_scaled = scaler.fit_transform(data)
        X, y = create_windows(data_scaled, look_back)
        model.fit(X, y)
    
    forecast(steps):
        inputs = last_window(data_scaled)
        for i = 1 to steps:
            pred = model.predict(inputs)
            forecast.append(pred)
            inputs = slide_window(inputs, pred)
        return scaler.inverse_transform(forecast)
}

CLASS: EnsembleForecaster
{
    models: [ARIMAForecaster, ProphetForecaster, LSTMForecaster]
    weights: [w_arima, w_prophet, w_lstm]
    
    fit(data):
        for model in models:
            model.fit(data)
    
    forecast(steps):
        forecasts = []
        for model in models:
            forecasts.append(model.forecast(steps))
        return weighted_average(forecasts, weights)
}
```

---

## üìê 10. Complexidade Computacional

### 10.1 ARIMA

- **Treinamento:** $O(n \times p^2)$ onde $n$ = tamanho da s√©rie, $p$ = ordem AR
- **Previs√£o:** $O(h \times p)$ onde $h$ = horizonte de previs√£o

### 10.2 Prophet

- **Treinamento:** $O(n \times k)$ onde $k$ = n√∫mero de par√¢metros (Stan MCMC)
- **Previs√£o:** $O(h)$

### 10.3 LSTM

- **Treinamento:** $O(E \times B \times L \times H^2)$ onde:
  - $E$ = epochs
  - $B$ = batch size
  - $L$ = look back (janela)
  - $H$ = hidden units
- **Previs√£o:** $O(h \times L \times H^2)$

### 10.4 Ensemble

- **Treinamento:** $O(\sum_{i=1}^{M} C_i)$ onde $C_i$ = custo do modelo $i$
- **Previs√£o:** $O(\sum_{i=1}^{M} P_i)$ onde $P_i$ = custo de previs√£o do modelo $i$

---

## üéØ 11. Algoritmo Completo do Sistema

```
ALGORITMO: Complete_Demand_Forecasting_System
INPUT: Historical Data D, Current Stock S, Item ID
OUTPUT: Forecast, PP, Alert

1. // Pr√©-processamento
2. D_processed ‚Üê Preprocess(D)
3.
4. // Feature Engineering
5. D_features ‚Üê Add_Temporal_Features(D_processed)
6. D_external ‚Üê Add_External_Factors(D_features)
7.
8. // Preparar para ML
9. train, test ‚Üê Split_TimeSeries(D_external, ratio=0.8)
10.
11. // Treinar modelos
12. arima_model ‚Üê ARIMAForecaster()
13. arima_model.fit(train)
14. arima_forecast ‚Üê arima_model.forecast(steps=30)
15.
16. prophet_model ‚Üê ProphetForecaster()
17. prophet_model.fit(train)
18. prophet_forecast ‚Üê prophet_model.forecast(steps=30)
19.
20. lstm_model ‚Üê LSTMForecaster(look_back=30)
21. lstm_model.fit(train)
22. lstm_forecast ‚Üê lstm_model.forecast(steps=30)
23.
24. // Ensemble
25. weights ‚Üê Optimize_Weights([arima_forecast, prophet_forecast, lstm_forecast], test)
26. ensemble_forecast ‚Üê Weighted_Average([arima_forecast, prophet_forecast, lstm_forecast], weights)
27.
28. // Calcular demanda m√©dia
29. D_avg ‚Üê Mean(ensemble_forecast)
30.
31. // Calcular PP
32. lead_time ‚Üê Get_Lead_Time(Item_ID)
33. sigma_D ‚Üê StdDev(train.quantity)
34. SS ‚Üê 1.65 √ó sigma_D √ó sqrt(lead_time)  // 95% confidence
35. PP ‚Üê (D_avg √ó lead_time) + SS
36.
37. // Verificar alerta
38. IF S <= PP THEN
39.     days_to_rupture ‚Üê (S - SS) / D_avg
40.     reorder_quantity ‚Üê PP - S + 0.1 √ó PP
41.     
42.     alert ‚Üê {
43.         item_id: Item_ID,
44.         current_stock: S,
45.         reorder_point: PP,
46.         forecast_demand: D_avg,
47.         days_to_rupture: days_to_rupture,
48.         reorder_quantity: reorder_quantity,
49.         urgency: (days_to_rupture < 7) ? "HIGH" : "MEDIUM"
50.     }
51.     
52.     Send_Alert(alert)
53. END IF
54.
55. RETURN ensemble_forecast, PP, alert
```

---

## üìö 12. Refer√™ncias e Bibliografia

### Modelos Matem√°ticos

1. **ARIMA:** Box, G. E. P., & Jenkins, G. M. (1976). *Time Series Analysis: Forecasting and Control*.
2. **Prophet:** Taylor, S. J., & Letham, B. (2018). "Forecasting at scale". *The American Statistician*.
3. **LSTM:** Hochreiter, S., & Schmidhuber, J. (1997). "Long short-term memory". *Neural computation*.

### Otimiza√ß√£o

1. **Bayesian Optimization:** Mockus, J. (2012). *Bayesian Approach to Global Optimization*.
2. **Adam Optimizer:** Kingma, D. P., & Ba, J. (2014). "Adam: A method for stochastic optimization". *arXiv preprint arXiv:1412.6980*.

### Supply Chain

1. **Reorder Point:** Silver, E. A., Pyke, D. F., & Peterson, R. (1998). *Inventory and Production Management in Supply Chains*.

---

## ‚úÖ Conclus√£o

Este sistema implementa:

1. ‚úÖ **Previs√£o de Demanda** usando ARIMA, Prophet, LSTM
2. ‚úÖ **C√°lculo de PP** din√¢mico com Safety Stock
3. ‚úÖ **Integra√ß√£o de Fatores Externos** (clima, econ√¥mico, regulat√≥rio, operacional)
4. ‚úÖ **Ensemble Methods** para robustez
5. ‚úÖ **Sistema de Alertas** autom√°tico
6. ‚úÖ **Pipeline Completo** de processamento

**Resultado Final:**
- **118,082 registros** processados
- **31 colunas** (9 base + 22 external factors)
- **27.25 MB** de dados prontos para ML
- **Sistema pronto** para produ√ß√£o

---

**Nova Corrente Grand Prix SENAI - Demand Forecasting System**

