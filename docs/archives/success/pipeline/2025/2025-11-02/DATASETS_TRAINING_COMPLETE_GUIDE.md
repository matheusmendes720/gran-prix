# üìä Guia Completo dos Datasets de Treinamento

## Nova Corrente - Demand Forecasting System

---

## üéØ Vis√£o Geral

Este documento fornece uma an√°lise completa de todos os datasets de treinamento preparados para ML, incluindo estrutura, estat√≠sticas e guias de uso.

---

## üìÅ Localiza√ß√£o dos Datasets

### Estrutura Completa

```
data/
‚îú‚îÄ‚îÄ processed/                    ‚≠ê DADOS PROCESSADOS
‚îÇ   ‚îú‚îÄ‚îÄ unified_dataset_with_factors.csv (27.25 MB | 118,082 rows)
‚îÇ   ‚îú‚îÄ‚îÄ zenodo_milan_telecom_preprocessed.csv (9.87 MB | 116,257 rows)
‚îÇ   ‚îî‚îÄ‚îÄ test_dataset_preprocessed.csv (0.05 MB | 730 rows)
‚îÇ
‚îú‚îÄ‚îÄ training/                     ‚≠ê DADOS DE TREINAMENTO (SPLITS)
‚îÇ   ‚îú‚îÄ‚îÄ unknown_train.csv (11.61 MB | 93,881 rows) ‚≠ê MAIOR
‚îÇ   ‚îú‚îÄ‚îÄ unknown_test.csv (2.90 MB | 23,471 rows)
‚îÇ   ‚îú‚îÄ‚îÄ unknown_full.csv (14.51 MB | 117,352 rows)
‚îÇ   ‚îú‚îÄ‚îÄ CONN-001_train.csv (0.06 MB | 584 rows)
‚îÇ   ‚îú‚îÄ‚îÄ CONN-001_test.csv (0.02 MB | 146 rows)
‚îÇ   ‚îú‚îÄ‚îÄ CONN-001_full.csv (0.08 MB | 730 rows)
‚îÇ   ‚îú‚îÄ‚îÄ metadata.json
‚îÇ   ‚îî‚îÄ‚îÄ training_summary.json
‚îÇ
‚îî‚îÄ‚îÄ raw/                          üì• DADOS BRUTOS
    ‚îú‚îÄ‚îÄ zenodo_milan_telecom/
    ‚îÇ   ‚îî‚îÄ‚îÄ output-step-bsId_1-2023_9_28_12_50_10.csv (28.7 MB | 116,257 rows)
    ‚îî‚îÄ‚îÄ test_dataset/
        ‚îî‚îÄ‚îÄ test_data.csv (37 KB | 730 rows)
```

---

## üìä Dataset 1: Zenodo Milan Telecom

### 1.1 Dataset Original (Raw)

**Localiza√ß√£o:** `data/raw/zenodo_milan_telecom/output-step-bsId_1-2023_9_28_12_50_10.csv`

**Estat√≠sticas:**
- **Tamanho:** 28.7 MB
- **Registros:** 116,257 linhas
- **Colunas:** 38 colunas

**Colunas Principais (Original):**
- `bsId` - Base Station ID (todos = 1)
- `episode` - Epis√≥dio do algoritmo (0-41)
- `step` - Passo temporal (0-116,256)
- `loadSMS`, `loadInt`, `loadCalls` - Traffic loads por servi√ßo
- `totalSched` - Total Admitted Traffic Load ‚≠ê **USE COMO DEMANDA**
- `bsCap` - Base Station Capacity
- `rejectRate*`, `delayRate*` - Taxas de rejei√ß√£o/delay
- `reward`, `episodeReward` - Rewards do algoritmo

**Caracter√≠sticas:**
- Dados de 5G network slice resource demand prediction
- 42 epis√≥dios do algoritmo de controle de admiss√£o
- Dados simulados/processados (game-theoretic episodes)
- Per√≠odo: Novembro 2013 - Janeiro 2014 (original MILANO dataset processado)

### 1.2 Dataset Preprocessado

**Localiza√ß√£o:** `data/processed/zenodo_milan_telecom_preprocessed.csv`

**Estat√≠sticas:**
- **Tamanho:** 9.87 MB
- **Registros:** 116,257 linhas
- **Colunas:** 9 colunas (schema unificado)

**Estrutura Ap√≥s Preprocessing:**

| Coluna | Tipo | Valor Exemplo | Origem |
|--------|------|---------------|--------|
| `date` | DateTime | 1970-01-01 00:00:00 | `step` convertido |
| `item_id` | String | "unknown" | Default |
| `quantity` | Float | 0.0 | `totalSched` |
| `cost` | Float | 0.0 | Default |
| `lead_time` | Integer | 14 | Default |
| `item_name` | String | "unknown" | Default |
| `category` | String | "unknown" | Default |
| `site_id` | String | "1" | `bsId` |
| `dataset_source` | String | "zenodo_milan_telecom" | Source marker |

**Observa√ß√µes Importantes:**

‚ö†Ô∏è **Date Conversion:**
- `step` (0-116,256) foi convertido para DateTime usando 1970-01-01 como base
- Resultado: dates de 1970-01-01 a 2024-12-30 (range artificial)
- **Recomenda√ß√£o:** Para an√°lise temporal, considerar usar `step` diretamente ou recalcular datas baseadas no per√≠odo original (Nov 2013 - Jan 2014)

‚ö†Ô∏è **Quantity Values:**
- Muitos valores s√£o 0.0 no in√≠cio
- Valores reais come√ßam ap√≥s alguns steps
- **Recomenda√ß√£o:** Filtrar zeros ou usar apenas valores > 0 para treinamento

### 1.3 Uso do Dataset Zenodo

```python
import pandas as pd
import numpy as np

# Carregar dataset Zenodo preprocessado
df_zenodo = pd.read_csv('data/processed/zenodo_milan_telecom_preprocessed.csv')

# Filtrar zeros (opcional)
df_zenodo = df_zenodo[df_zenodo['quantity'] > 0]

# Preparar para time series
df_zenodo['date'] = pd.to_datetime(df_zenodo['date'])
df_zenodo = df_zenodo.set_index('date').sort_index()

# Extrair s√©rie temporal
series = df_zenodo['quantity']

# Estat√≠sticas
print(f"Total: {len(series):,} registros")
print(f"Mean: {series.mean():.2f}")
print(f"Std: {series.std():.2f}")
print(f"Min: {series.min():.2f}")
print(f"Max: {series.max():.2f}")
```

---

## üìä Dataset 2: Test Dataset

### 2.1 Dataset Original (Raw)

**Localiza√ß√£o:** `data/raw/test_dataset/test_data.csv`

**Estat√≠sticas:**
- **Tamanho:** 37 KB
- **Registros:** 730 linhas (2 anos de dados di√°rios)
- **Colunas:** 7 colunas

**Estrutura Original:**

| Coluna | Tipo | Exemplo | Descri√ß√£o |
|--------|------|---------|-----------|
| `Date` | Date | 2023-01-01 | Data (di√°ria) |
| `Product` | String | "CONN-001" | ID do produto |
| `Order_Demand` | Integer | 7 | Demanda di√°ria (4-10) |
| `Site` | String | "TORRE001" | ID da torre/site |
| `Category` | String | "Conectores" | Categoria |
| `Cost` | Float | 300.0 | Custo unit√°rio |
| `Lead_Time` | Integer | 14 | Tempo de entrega (dias) |

**Caracter√≠sticas:**
- ‚úÖ **Dados Sint√©ticos/Guiados:** Criados para teste do pipeline
- ‚úÖ **Per√≠odo Completo:** 2 anos (730 dias) de 2023-01-01 a 2024-12-30
- ‚úÖ **Sem Gaps:** Dados cont√≠nuos para todos os dias
- ‚úÖ **Demanda Real√≠stica:** Varia de 4 a 10 unidades/dia
- ‚úÖ **Estrutura Limpa:** Pronto para uso direto

**Estat√≠sticas do Test Dataset:**
- **Mean Demand:** 6.93 unidades/dia
- **Std Demand:** 2.51 unidades
- **Min Demand:** 3 unidades
- **Max Demand:** 11 unidades
- **Lead Time:** 14 dias (fixo)
- **Cost:** 300.0 (fixo)

### 2.2 Dataset Preprocessado

**Localiza√ß√£o:** `data/processed/test_dataset_preprocessed.csv`

**Estrutura Ap√≥s Preprocessing:**

| Coluna | Tipo | Origem |
|--------|------|--------|
| `date` | DateTime | `Date` |
| `item_id` | String | `Product` |
| `quantity` | Float | `Order_Demand` |
| `site_id` | String | `Site` |
| `category` | String | `Category` |
| `cost` | Float | `Cost` |
| `lead_time` | Integer | `Lead_Time` |
| `item_name` | String | Default |
| `dataset_source` | String | "test_dataset" |

**Caracter√≠sticas:**
- ‚úÖ Mant√©m todas as informa√ß√µes originais
- ‚úÖ Schema unificado aplicado
- ‚úÖ Time-based features adicionados (year, month, weekday, etc.)

### 2.3 Uso do Test Dataset

```python
# Carregar test dataset
df_test = pd.read_csv('data/raw/test_dataset/test_data.csv')

# An√°lise b√°sica
print(f"Period: {df_test['Date'].min()} to {df_test['Date'].max()}")
print(f"Days: {len(df_test)}")
print(f"Mean Demand: {df_test['Order_Demand'].mean():.2f}")
print(f"Std Demand: {df_test['Order_Demand'].std():.2f}")

# Preparar para ML
df_test['Date'] = pd.to_datetime(df_test['Date'])
df_test = df_test.set_index('Date').sort_index()
series = df_test['Order_Demand']

# Ideal para:
# - Testes de algoritmos
# - Valida√ß√£o r√°pida
# - Prototipagem
# - Baseline comparisons
```

---

## üìä Dataset 3: Unknown (Training Split)

### 3.1 Unknown Train Dataset ‚≠ê MAIOR

**Localiza√ß√£o:** `data/training/unknown_train.csv`

**Estat√≠sticas:**
- **Tamanho:** 11.61 MB
- **Registros:** 93,881 linhas (80% de treino)
- **Colunas:** 31 colunas (9 base + 22 external factors)

**Composi√ß√£o:**
- **98.5%** do Zenodo Milan Telecom (~92,500 registros)
- **0.6%** do Kaggle Retail Inventory (~560 registros)
- **0.6%** do Test Dataset (~560 registros)
- **0.3%** do Kaggle Supply Chain (~260 registros)

**Colunas Dispon√≠veis:**

**Base (9):**
- `date`, `item_id`, `item_name`, `quantity`, `site_id`, `category`, `cost`, `lead_time`, `dataset_source`

**External Factors (22):**
- **Clim√°ticos:** `temperature`, `precipitation`, `humidity`, `extreme_heat`, `heavy_rain`, `high_humidity`
- **Econ√¥micos:** `exchange_rate_brl_usd`, `inflation_rate`, `gdp_growth`, `high_inflation`, `currency_devaluation`
- **Regulat√≥rios:** `5g_coverage`, `regulatory_compliance_date`, `5g_expansion_rate`
- **Operacionais:** `is_holiday`, `is_vacation_period`, `sla_renewal_period`, `weekend`
- **Scores:** `climate_impact`, `economic_impact`, `operational_impact`, `demand_adjustment_factor`

**Caracter√≠sticas:**
- ‚úÖ **Maior Dataset:** 93,881 registros de treino
- ‚úÖ **Com External Factors:** 22 fatores externos integrados
- ‚úÖ **Schema Unificado:** Pronto para ML direto
- ‚úÖ **Time Series Ready:** Indexado por data

**‚ö†Ô∏è Observa√ß√£o sobre Quantity:**
- M√©dia: 0.0 (devido aos zeros do Zenodo)
- **Recomenda√ß√£o:** Filtrar valores > 0 ou usar apenas dados do test_dataset/corrigir preprocessing

### 3.2 Unknown Test Dataset

**Localiza√ß√£o:** `data/training/unknown_test.csv`

**Estat√≠sticas:**
- **Tamanho:** 2.90 MB
- **Registros:** 23,471 linhas (20% de teste)
- **Colunas:** 31 colunas

**Uso:** Para avalia√ß√£o de modelos ML (valida√ß√£o)

---

## üìä Dataset 4: CONN-001 (Training Split)

### 4.1 CONN-001 Train Dataset

**Localiza√ß√£o:** `data/training/CONN-001_train.csv`

**Estat√≠sticas:**
- **Tamanho:** 0.06 MB
- **Registros:** 584 linhas (80% de treino)
- **Colunas:** 31 colunas
- **Origem:** 100% do test_dataset

**Estat√≠sticas (do metadata.json):**
- **Period:** 2023-01-01 to 2024-12-30
- **Mean Quantity:** 6.93 unidades/dia
- **Std Quantity:** 2.51 unidades
- **Min Quantity:** 3.0 unidades
- **Max Quantity:** 11.0 unidades

**Caracter√≠sticas:**
- ‚úÖ **Dataset Limpo:** Sem zeros, dados real√≠sticos
- ‚úÖ **Per√≠odo Completo:** 2 anos de dados di√°rios
- ‚úÖ **Estrutura Limpa:** Pronto para uso direto
- ‚úÖ **Ideal para:** Testes r√°pidos, prototipagem, baseline

### 4.2 CONN-001 Test Dataset

**Localiza√ß√£o:** `data/training/CONN-001_test.csv`

**Estat√≠sticas:**
- **Tamanho:** 0.02 MB
- **Registros:** 146 linhas (20% de teste)
- **Colunas:** 31 colunas

---

## üìä Dataset 5: Unified Dataset (Completo)

### `data/processed/unified_dataset_with_factors.csv` ‚≠ê PRINCIPAL

**Estat√≠sticas:**
- **Tamanho:** 27.25 MB
- **Registros:** 118,082 linhas
- **Colunas:** 31 colunas (9 base + 22 external factors)

**Composi√ß√£o Final:**

| Fonte | Registros | Percentual |
|-------|-----------|------------|
| **zenodo_milan_telecom** | 116,257 | 98.5% |
| **test_dataset** | 730 | 0.6% |
| **kaggle_retail_inventory** | 731 | 0.6% |
| **kaggle_supply_chain** | 364 | 0.3% |
| **Total** | **118,082** | **100%** |

**Caracter√≠sticas:**
- ‚úÖ **Dataset Completo:** Todos os dados mesclados
- ‚úÖ **External Factors:** 22 fatores integrados
- ‚úÖ **Schema Unificado:** Pronto para an√°lise completa
- ‚úÖ **Ideal para:** An√°lise explorat√≥ria, visualiza√ß√µes, an√°lise completa

---

## üéØ Recomenda√ß√µes de Uso

### Para Treinar Modelos ML (ARIMA, Prophet, LSTM):

**‚úÖ RECOMENDADO:** `data/training/unknown_train.csv`

**Raz√µes:**
- ‚úÖ Maior dataset (93,881 registros)
- ‚úÖ J√° dividido train/test
- ‚úÖ Com external factors
- ‚úÖ Pronto para uso direto

**C√≥digo:**

```python
# Carregar dados de treino
train_df = pd.read_csv('data/training/unknown_train.csv')
test_df = pd.read_csv('data/training/unknown_test.csv')

# Filtrar zeros (se necess√°rio)
train_df = train_df[train_df['quantity'] > 0]
test_df = test_df[test_df['quantity'] > 0]

# Preparar para time series
train_df['date'] = pd.to_datetime(train_df['date'])
train_df = train_df.set_index('date').sort_index()

# Extrair s√©rie temporal
series_train = train_df['quantity']

# Treinar modelos...
```

### Para Testes R√°pidos e Prototipagem:

**‚úÖ RECOMENDADO:** `data/training/CONN-001_train.csv`

**Raz√µes:**
- ‚úÖ Dataset menor (584 registros)
- ‚úÖ Dados limpos (sem zeros)
- ‚úÖ Per√≠odo completo (2 anos)
- ‚úÖ R√°pido para iterar

**C√≥digo:**

```python
# Dataset menor para testes r√°pidos
train_small = pd.read_csv('data/training/CONN-001_train.csv')
test_small = pd.read_csv('data/training/CONN-001_test.csv')

# Ideal para:
# - Testes de algoritmos
# - Valida√ß√£o r√°pida
# - Prototipagem
```

### Para An√°lise Completa:

**‚úÖ RECOMENDADO:** `data/processed/unified_dataset_with_factors.csv`

**Raz√µes:**
- ‚úÖ Todos os dados unificados
- ‚úÖ Com external factors
- ‚úÖ An√°lise explorat√≥ria completa

---

## üìê An√°lise Matem√°tica

### Distribui√ß√£o de Quantidade

**Para unknown dataset:**
- **Mean:** 0.0 (devido aos zeros do Zenodo)
- **Std:** 0.0
- **Recomenda√ß√£o:** Filtrar zeros ou corrigir preprocessing

**Para CONN-001 dataset:**
- **Mean:** 6.93 unidades/dia
- **Std:** 2.51 unidades
- **Min:** 3.0 unidades
- **Max:** 11.0 unidades
- **Distribui√ß√£o:** Normalizada e real√≠stica

### An√°lise Temporal

**Unknown Dataset:**
- **Date Range:** 1970-01-01 to 2024-12-30 (artificial devido √† convers√£o de step)
- **Total Days:** ~54 anos (range artificial)
- **Real Period:** Nov 2013 - Jan 2014 (original)

**CONN-001 Dataset:**
- **Date Range:** 2023-01-01 to 2024-12-30
- **Total Days:** 730 dias (2 anos)
- **Realistic:** Dados cont√≠nuos sem gaps

---

## üîç Problemas Identificados e Solu√ß√µes

### Problema 1: Zeros no Zenodo Dataset

**Problema:** Muitos valores de `quantity` s√£o 0.0 no dataset unknown.

**Solu√ß√£o:**
```python
# Filtrar zeros
df = df[df['quantity'] > 0]

# Ou usar apenas CONN-001 que n√£o tem zeros
df = pd.read_csv('data/training/CONN-001_train.csv')
```

### Problema 2: Date Range Artificial

**Problema:** Datas do Zenodo come√ßam em 1970 (convers√£o de step).

**Solu√ß√£o:**
```python
# Op√ß√£o 1: Recalcular datas baseadas no per√≠odo original
# Nov 2013 - Jan 2014 = ~60 dias
start_date = pd.to_datetime('2013-11-01')
df['date'] = start_date + pd.to_timedelta(df['step'], unit='D')

# Op√ß√£o 2: Usar step diretamente como √≠ndice temporal
df['time_index'] = df['step']
df = df.set_index('time_index')
```

### Problema 3: Item ID = "unknown"

**Problema:** Todos os registros do Zenodo t√™m item_id = "unknown".

**Solu√ß√£o:**
```python
# Criar item_id baseado em site_id + episode
df['item_id'] = df['site_id'].astype(str) + '_ep' + df['episode'].astype(str)
```

---

## ‚úÖ Resumo Final

### Datasets Recomendados para ML Training:

1. **`unknown_train.csv`** ‚≠ê **PRINCIPAL**
   - 93,881 registros
   - 31 colunas com external factors
   - 11.61 MB
   - **USE ESTE PARA TREINAR MODELOS ML COMPLETOS**

2. **`CONN-001_train.csv`** ‚≠ê **PARA TESTES**
   - 584 registros
   - 31 colunas
   - 0.06 MB
   - **USE ESTE PARA TESTES R√ÅPIDOS E PROTOPIPAGEM**

3. **`unified_dataset_with_factors.csv`** ‚≠ê **PARA AN√ÅLISE**
   - 118,082 registros
   - 31 colunas
   - 27.25 MB
   - **USE ESTE PARA AN√ÅLISE EXPLORAT√ìRIA COMPLETA**

---

**Status:** ‚úÖ **Todos os datasets prontos e documentados!**

**Pr√≥ximo:** Treinar modelos ML usando os datasets de treinamento!

---

**Nova Corrente Grand Prix SENAI - Demand Forecasting System**

