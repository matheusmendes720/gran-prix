# üöÄ Funcionalidades Avan√ßadas - Sistema Completo

## Nova Corrente - Demand Forecasting System

---

## üìã Vis√£o Geral

Sistema completo de funcionalidades avan√ßadas para processamento inteligente de datasets, incluindo indexa√ß√£o temporal, parsing avan√ßado de PDFs, dashboard de status e sistema de retry.

---

## üéØ Funcionalidades Implementadas

### 1. **Indexa√ß√£o Temporal para Datasets sem Data**

**Arquivo:** `src/utils/temporal_indexing.py`

‚úÖ Cria timestamps sint√©ticos para datasets sem coluna de data  
‚úÖ M√∫ltiplas estrat√©gias de indexa√ß√£o (order, pattern, external)  
‚úÖ Features temporais autom√°ticas (year, month, weekday, etc.)  
‚úÖ Encoding c√≠clico para ML (sin/cos transformations)

**Estrat√©gias:**
- **Order-based**: Baseado na ordem das linhas
- **Pattern-based**: Baseado em padr√µes detectados
- **External**: Merge com dados externos que t√™m timestamps

**Uso:**
```python
from src.utils.temporal_indexing import TemporalIndexer

indexer = TemporalIndexer(base_date='2022-01-01', frequency='D')
df_with_dates = indexer.create_index_from_order(df)

# Com features temporais
df_enhanced = indexer.enhance_with_temporal_features(df_with_dates)
```

---

### 2. **Parser Avan√ßado de PDFs**

**Arquivo:** `src/utils/advanced_pdf_parser.py`

‚úÖ Suporte para m√∫ltiplas bibliotecas (pdfplumber, tabula, camelot, PyPDF2)  
‚úÖ Auto-detec√ß√£o do melhor parser  
‚úÖ Estrat√©gia combinada para m√°xima extra√ß√£o  
‚úÖ Limpeza autom√°tica de dados extra√≠dos

**Parsers Suportados:**
- **pdfplumber**: Extra√ß√£o precisa de tabelas
- **tabula-py**: Extra√ß√£o de tabelas em PDFs complexos
- **camelot**: Extra√ß√£o de tabelas com bordas
- **PyPDF2**: Fallback para extra√ß√£o de texto

**Uso:**
```python
from src.utils.advanced_pdf_parser import AdvancedPDFParser

parser = AdvancedPDFParser()

# Parsear com estrat√©gia autom√°tica
df = parser.parse_pdf(pdf_path, strategy='auto')

# Parsear com parser espec√≠fico
df = parser.parse_pdf(pdf_path, strategy='pdfplumber')

# Extrair todas as tabelas
csv_files = parser.extract_tables_from_pdf(pdf_path, output_dir)
```

---

### 3. **Dashboard de Status do Sistema**

**Arquivo:** `src/utils/system_status_dashboard.py`

‚úÖ Status completo de datasets (registrados, baixados, validados)  
‚úÖ Status do pipeline (download, preprocess, merge, external factors)  
‚úÖ Status de armazenamento (tamanhos, contagens)  
‚úÖ Health check do sistema

**Status Inclu√≠dos:**
- **Datasets**: Total, por status, por fonte, download/validation status
- **Pipeline**: Prontid√£o de cada etapa, progresso
- **Storage**: Tamanhos de dados brutos/processados
- **Health**: Estado geral e componentes

**Uso:**
```bash
# Exibir dashboard
python scripts/show_system_status.py

# Salvar relat√≥rio
python scripts/show_system_status.py --save --output data/registry/system_status.json
```

**Dashboard Exemplo:**
```
================================================================================
SYSTEM STATUS DASHBOARD
================================================================================
Timestamp: 2024-01-01T00:00:00

--------------------------------------------------------------------------------
DATASETS STATUS
--------------------------------------------------------------------------------
Total Registered: 18
By Status:
  discovered: 5
  downloaded: 10
  validated: 8
By Source:
  kaggle: 8
  zenodo: 4
  anatel: 3
  github: 3

Download Status:
  Downloaded: 10
  Not Downloaded: 5
  Failed: 3

--------------------------------------------------------------------------------
PIPELINE STATUS
--------------------------------------------------------------------------------
Download: ‚úì (13 datasets)
Preprocess: ‚úì (10 preprocessed, 3 pending)
Merge: ‚úì (Unified dataset exists)
External Factors: ‚úì (Enriched dataset exists)

--------------------------------------------------------------------------------
STORAGE STATUS
--------------------------------------------------------------------------------
Raw Data: 1250.50 MB (13 datasets)
Processed Data: 850.25 MB (10 datasets)
Total: 2100.75 MB

--------------------------------------------------------------------------------
SYSTEM HEALTH
--------------------------------------------------------------------------------
Overall: HEALTHY

Components:
  registry: ‚úì
  raw_data_dir: ‚úì
  processed_data_dir: ‚úì
  config_file: ‚úì
================================================================================
```

---

### 4. **Sistema de Retry e Recupera√ß√£o**

**Arquivo:** `src/utils/retry_handler.py`

‚úÖ Retry autom√°tico com backoff exponencial  
‚úÖ Jitter aleat√≥rio para evitar thundering herd  
‚úÖ Estrat√©gias de recupera√ß√£o customiz√°veis  
‚úÖ Handlers especializados (download, file operations)

**Caracter√≠sticas:**
- **Backoff Exponencial**: Delay cresce exponencialmente
- **Jitter**: Adiciona aleatoriedade para evitar sincroniza√ß√£o
- **Max Delay**: Limita delay m√°ximo
- **Callbacks**: Fun√ß√µes chamadas ap√≥s cada falha

**Uso:**
```python
from src.utils.retry_handler import RetryHandler, retry_with_recovery

# Retry b√°sico
handler = RetryHandler(max_retries=3, base_delay=1.0)
result = handler.retry(exceptions=(ConnectionError,))(download_func)(url)

# Com decorator
@handler.retry(exceptions=(Exception,))
def risky_operation():
    # ...
    pass

# Com recupera√ß√£o
@retry_with_recovery(
    max_retries=3,
    recovery_strategies=[fallback_strategy1, fallback_strategy2]
)
def critical_operation():
    # ...
    pass

# Handlers especializados
from src.utils.retry_handler import DownloadRetryHandler, FileOperationRetryHandler

download_handler = DownloadRetryHandler(max_retries=3)
file_handler = FileOperationRetryHandler(max_retries=3)

# Download com retry
result = download_handler.download_with_retry(download_func, url)

# Opera√ß√µes de arquivo com retry
data = file_handler.read_with_retry(file_path, pd.read_csv)
file_handler.write_with_retry(file_path, data, pd.DataFrame.to_csv)
```

---

## üîß Integra√ß√µes

### 1. **Integra√ß√£o com Preprocessing**

O sistema de indexa√ß√£o temporal pode ser usado no preprocessing:

```python
from src.utils.temporal_indexing import process_dataset_without_date

# No preprocess_datasets.py
if 'date' not in df.columns:
    config = {
        'temporal_indexing': {
            'strategy': 'order',
            'base_date': '2022-01-01',
            'frequency': 'D',
            'add_temporal_features': True
        }
    }
    df = process_dataset_without_date(dataset_id, df, config, output_path)
```

### 2. **Integra√ß√£o com Download**

O sistema de retry pode ser usado em downloads:

```python
from src.utils.retry_handler import DownloadRetryHandler

handler = DownloadRetryHandler(max_retries=3)

# No download_datasets.py
success = handler.download_with_retry(
    self.download_direct_url,
    url,
    output_path
)
```

### 3. **Integra√ß√£o com PDF Parsing**

O parser avan√ßado pode ser usado em preprocessing:

```python
from src.utils.advanced_pdf_parser import AdvancedPDFParser

parser = AdvancedPDFParser()

# No download ou preprocessing
if file_path.suffix.lower() == '.pdf':
    df = parser.parse_pdf(file_path, strategy='auto')
    df.to_csv(output_csv_path, index=False)
```

---

## üìä Scripts Dispon√≠veis

### Script 1: `scripts/show_system_status.py`

**Prop√≥sito:** Exibir dashboard de status do sistema

**Uso:**
```bash
# Exibir no terminal
python scripts/show_system_status.py

# Salvar em JSON
python scripts/show_system_status.py --save
```

---

## üéØ Casos de Uso

### Caso 1: Processar Dataset sem Data

```python
from src.utils.temporal_indexing import TemporalIndexer

indexer = TemporalIndexer(base_date='2022-01-01')
df = indexer.create_index_from_order(df, sort_by=['item_id'])
df = indexer.enhance_with_temporal_features(df)
```

### Caso 2: Extrair Dados de PDF

```python
from src.utils.advanced_pdf_parser import AdvancedPDFParser

parser = AdvancedPDFParser()
df = parser.parse_pdf('data/raw/internet_aberta_forecast/forecast.pdf')
df.to_csv('data/raw/internet_aberta_forecast/forecast.csv', index=False)
```

### Caso 3: Download com Retry

```python
from src.utils.retry_handler import DownloadRetryHandler

handler = DownloadRetryHandler(max_retries=5)
success = handler.download_with_retry(download_func, url, path)
```

### Caso 4: Verificar Status do Sistema

```bash
python scripts/show_system_status.py
```

---

## üìÅ Estrutura de Arquivos

```
src/utils/
‚îú‚îÄ‚îÄ temporal_indexing.py           ‚≠ê NOVO
‚îú‚îÄ‚îÄ advanced_pdf_parser.py         ‚≠ê NOVO
‚îú‚îÄ‚îÄ system_status_dashboard.py     ‚≠ê NOVO
‚îî‚îÄ‚îÄ retry_handler.py               ‚≠ê NOVO

scripts/
‚îî‚îÄ‚îÄ show_system_status.py           ‚≠ê NOVO

docs/
‚îî‚îÄ‚îÄ ADVANCED_FEATURES_COMPLETE.md   ‚≠ê NOVO
```

---

## ‚úÖ Checklist de Implementa√ß√£o

- [x] Sistema de indexa√ß√£o temporal
- [x] Parser avan√ßado de PDFs
- [x] Dashboard de status
- [x] Sistema de retry e recupera√ß√£o
- [x] Integra√ß√µes com pipeline principal
- [x] Scripts de execu√ß√£o
- [x] Documenta√ß√£o completa

---

## üìä Benef√≠cios

### Indexa√ß√£o Temporal
- ‚úÖ Processa datasets sem timestamps
- ‚úÖ Cria features temporais automaticamente
- ‚úÖ Suporta m√∫ltiplas estrat√©gias

### Parser de PDFs
- ‚úÖ Extrai dados de PDFs complexos
- ‚úÖ M√∫ltiplas bibliotecas para m√°xima compatibilidade
- ‚úÖ Limpeza autom√°tica de dados

### Dashboard
- ‚úÖ Vis√£o completa do sistema
- ‚úÖ Identifica√ß√£o r√°pida de problemas
- ‚úÖ Monitoramento de progresso

### Retry Handler
- ‚úÖ Maior resili√™ncia a falhas
- ‚úÖ Recupera√ß√£o autom√°tica
- ‚úÖ Reduz necessidade de interven√ß√£o manual

---

**Status:** ‚úÖ **FUNCIONALIDADES AVAN√áADAS COMPLETAS**

---

**Nova Corrente Grand Prix SENAI - Demand Forecasting System**

