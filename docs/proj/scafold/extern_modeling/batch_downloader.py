#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
üî• NOVA CORRENTE ‚Äî BATCH DATA DOWNLOADER
Conectores para todas as fontes de dados macro-meso-micro econ√¥micas
Vers√£o: 1.0 | Data: Nov 8, 2025
"""

import pandas as pd
import requests
import json
from datetime import datetime, timedelta
import os
from typing import Dict, List, Optional, Tuple
import logging

# ============================================================================
# LOGGING SETUP
# ============================================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================================
# 1Ô∏è‚É£ IBGE CONNECTOR (PIB, INFLA√á√ÉO, DESEMPREGO)
# ============================================================================

class IBGEConnector:
    """Download dados SIDRA (PIB, IPCA, INPC, IGP-M, desemprego)"""
    
    BASE_URL = "https://apisidra.ibge.gov.br/values"
    
    TABLES = {
        'pib_quarterly': '12462',      # PIB trimestral
        'pib_annual': '5932',          # PIB anual
        'ipca_monthly': '1737',        # IPCA mensal
        'ipca_15': '1705',             # IPCA-15 (pr√©via)
        'inpc': '1736',                # INPC
        'igp_m': '190',                # IGP-M
        'unemployment': '6385',        # Taxa desocupa√ß√£o
        'population': '29168',         # Popula√ß√£o
    }
    
    @staticmethod
    def download(table_name: str, start_date: Optional[str] = None, 
                 end_date: Optional[str] = None) -> pd.DataFrame:
        """
        Download s√©rie hist√≥rica IBGE
        
        Args:
            table_name: chave em TABLES (ex: 'ipca_monthly')
            start_date: formato 'YYYY-MM' (opcional)
            end_date: formato 'YYYY-MM' (opcional)
        
        Returns:
            DataFrame com dados
        """
        table_id = IBGEConnector.TABLES.get(table_name)
        if not table_id:
            raise ValueError(f"Tabela {table_name} n√£o existe. Use: {list(IBGEConnector.TABLES.keys())}")
        
        # Construir URL
        url = f"{IBGEConnector.BASE_URL}/t/{table_id}/n1/v"
        
        try:
            logger.info(f"Baixando IBGE {table_name} de {table_id}...")
            resp = requests.get(url, timeout=30)
            resp.raise_for_status()
            data = resp.json()
            
            # Converter para DataFrame
            df = pd.DataFrame(data)
            df['data'] = pd.to_datetime(df['D3C'], format='%Y%m%d', errors='coerce')
            df = df.sort_values('data')
            
            logger.info(f"‚úì {len(df)} registros baixados")
            return df
        
        except Exception as e:
            logger.error(f"‚úó Erro ao baixar IBGE {table_name}: {e}")
            return pd.DataFrame()


# ============================================================================
# 2Ô∏è‚É£ BACEN CONNECTOR (C√ÇMBIO, SELIC)
# ============================================================================

class BACENConnector:
    """Download dados BACEN (C√¢mbio PTAX, Selic, Taxas)"""
    
    @staticmethod
    def download_ptax(start_date: Optional[str] = None, 
                     end_date: Optional[str] = None) -> pd.DataFrame:
        """
        Download c√¢mbio PTAX (USD/BRL di√°rio)
        
        Args:
            start_date: formato 'YYYY-MM-DD'
            end_date: formato 'YYYY-MM-DD'
        
        Returns:
            DataFrame com data, taxa spot, alta, baixa
        """
        if not start_date:
            start_date = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')
        if not end_date:
            end_date = datetime.now().strftime('%Y-%m-%d')
        
        # Converter para formato BACEN (MM-DD-YYYY)
        start_fmt = datetime.strptime(start_date, '%Y-%m-%d').strftime('%m-%d-%Y')
        end_fmt = datetime.strptime(end_date, '%Y-%m-%d').strftime('%m-%d-%Y')
        
        url = f"https://olinda.bcb.gov.br/olinda/servico/PTAX/versao/v1/odata/CotacaoDolarPeriodo(dataInicial=@dataInicial,dataFinal=@dataFinal)?@dataInicial='{start_fmt}'&@dataFinal='{end_fmt}'&$top=10000&$orderby=dataHora%20asc&$format=json"
        
        try:
            logger.info(f"Baixando PTAX {start_date} a {end_date}...")
            resp = requests.get(url, timeout=30)
            resp.raise_for_status()
            data = resp.json()
            
            if 'value' not in data:
                logger.warning("Resposta PTAX sem dados")
                return pd.DataFrame()
            
            df = pd.DataFrame(data['value'])
            df['dataHora'] = pd.to_datetime(df['dataHora'])
            df['cotacaoVenda'] = pd.to_numeric(df['cotacaoVenda'], errors='coerce')
            df['cotacaoCompra'] = pd.to_numeric(df['cotacaoCompra'], errors='coerce')
            
            logger.info(f"‚úì {len(df)} cota√ß√µes baixadas")
            return df
        
        except Exception as e:
            logger.error(f"‚úó Erro ao baixar PTAX: {e}")
            return pd.DataFrame()
    
    @staticmethod
    def download_selic(series_id: str = '432') -> pd.DataFrame:
        """
        Download Selic hist√≥rica
        
        Args:
            series_id: BCB series ID (padr√£o 432 = Selic)
        
        Returns:
            DataFrame com data, valor
        """
        url = f"https://api.bcb.gov.br/dados/serie/bcdata.sgs.{series_id}/dados"
        
        try:
            logger.info(f"Baixando Selic (s√©rie {series_id})...")
            resp = requests.get(url, timeout=30)
            resp.raise_for_status()
            data = resp.json()
            
            df = pd.DataFrame(data)
            df['data'] = pd.to_datetime(df['data'], format='%d/%m/%Y')
            df['valor'] = pd.to_numeric(df['valor'], errors='coerce')
            
            logger.info(f"‚úì {len(df)} observa√ß√µes baixadas")
            return df
        
        except Exception as e:
            logger.error(f"‚úó Erro ao baixar Selic: {e}")
            return pd.DataFrame()


# ============================================================================
# 3Ô∏è‚É£ INMET CONNECTOR (CLIMA)
# ============================================================================

class INMETConnector:
    """Download dados clim√°ticos INMET (temperatura, precipita√ß√£o)"""
    
    API_URL = "https://bdmep.inmet.gov.br/api/dados/estacao"
    
    @staticmethod
    def download_station_data(station_code: str, 
                             start_date: str, 
                             end_date: str) -> pd.DataFrame:
        """
        Download dados hist√≥ricos esta√ß√£o meteorol√≥gica
        
        Args:
            station_code: c√≥digo INMET da esta√ß√£o (ex: 'A001' Salvador)
            start_date: formato 'YYYY-MM-DD'
            end_date: formato 'YYYY-MM-DD'
        
        Returns:
            DataFrame com temperatura, precipita√ß√£o, umidade
        
        Nota: Esta API requer token/autentica√ß√£o. Alternativa: download manual via portal.
        """
        logger.warning("‚ö†Ô∏è INMET API requer autentica√ß√£o. Use portal: https://bdmep.inmet.gov.br/")
        logger.info("Alternativa: Download manual de https://tempo.inmet.gov.br/")
        return pd.DataFrame()


# ============================================================================
# 4Ô∏è‚É£ ANATEL CONNECTOR (5G, TELECOM)
# ============================================================================

class ANATELConnector:
    """Download dados ANATEL (5G, cobertura, investimentos)"""
    
    DADOS_ABERTOS_URL = "https://dados.anatel.gov.br/api/3/action"
    
    @staticmethod
    def list_datasets() -> List[Dict]:
        """Lista todos datasets dispon√≠veis ANATEL"""
        try:
            logger.info("Listando datasets ANATEL...")
            url = f"{ANATELConnector.DADOS_ABERTOS_URL}/package_search?rows=100"
            resp = requests.get(url, timeout=30)
            resp.raise_for_status()
            data = resp.json()
            
            datasets = [{'name': pkg['name'], 'title': pkg['title']} 
                       for pkg in data['result']['results']]
            logger.info(f"‚úì {len(datasets)} datasets encontrados")
            return datasets
        
        except Exception as e:
            logger.error(f"‚úó Erro ao listar ANATEL: {e}")
            return []
    
    @staticmethod
    def download_5g_coverage() -> pd.DataFrame:
        """Download dados de cobertura 5G por munic√≠pio"""
        logger.info("Download 5G recomendado via portal: https://informacoes.anatel.gov.br/paineis")
        logger.info("(Dados sem API estruturada. Use download manual ou web scraping)")
        return pd.DataFrame()


# ============================================================================
# 5Ô∏è‚É£ COMTRADE CONNECTOR (COM√âRCIO INTERNACIONAL)
# ============================================================================

class ComtradeConnector:
    """Download dados UN Comtrade (importa√ß√£o/exporta√ß√£o telecomunica√ß√µes)"""
    
    BASE_URL = "https://comtradeplus.un.org/api/get"
    
    @staticmethod
    def download_imports(reporter: str = 'BRA', 
                        hs_code: str = '8517',  # Telecom equipment
                        start_year: int = 2019,
                        end_year: int = 2025) -> pd.DataFrame:
        """
        Download importa√ß√µes Brasil por HS code
        
        Args:
            reporter: pa√≠s ('BRA' = Brasil)
            hs_code: c√≥digo HS (8517=telecom, 8525=transmiss√£o, etc.)
            start_year: ano inicial
            end_year: ano final
        
        Returns:
            DataFrame com importa√ß√µes
        
        Nota: Comtrade Plus requer API key. Usar AliceWeb2 (MDIC) ou Comtrade gratuito.
        """
        logger.warning("‚ö†Ô∏è Comtrade Plus requer API key. Alternativas:")
        logger.info("1. AliceWeb2 (MDIC): https://aliceweb2.mdic.gov.br/")
        logger.info("2. Comtrade cl√°ssico (limitado): https://comtrade.un.org/")
        return pd.DataFrame()


# ============================================================================
# 6Ô∏è‚É£ RECEITA FEDERAL CONNECTOR (TRIBUTOS)
# ============================================================================

class ReceitaFederalConnector:
    """Dados tribut√°rios (ICMS, PIS/COFINS, al√≠quotas por estado)"""
    
    @staticmethod
    def get_icms_rates_by_state() -> Dict[str, float]:
        """
        Tabela de al√≠quotas ICMS por estado (telecomunica√ß√µes)
        Fonte: CONFAZ, STF Decis√£o RE 574.706 (LC 194/2022)
        """
        icms_rates = {
            'AC': 0.17, 'AL': 0.17, 'AP': 0.17, 'AM': 0.17,
            'BA': 0.18, 'CE': 0.17, 'DF': 0.17, 'ES': 0.17,
            'GO': 0.17, 'MA': 0.17, 'MT': 0.17, 'MS': 0.17,
            'MG': 0.18, 'PA': 0.17, 'PB': 0.17, 'PR': 0.17,
            'PE': 0.17, 'PI': 0.17, 'RJ': 0.20, 'RN': 0.17,
            'RS': 0.17, 'RO': 0.17, 'RR': 0.17, 'SC': 0.17,
            'SP': 0.18, 'SE': 0.17, 'TO': 0.17
        }
        logger.info(f"‚úì Al√≠quotas ICMS carregadas para {len(icms_rates)} estados")
        return icms_rates
    
    @staticmethod
    def get_federal_tax_rates() -> Dict[str, float]:
        """Al√≠quotas federais PIS/COFINS, IPI (2025)"""
        rates = {
            'pis': 0.0165,           # PIS 1.65%
            'cofins_nc': 0.076,      # COFINS (n√£o-cumulativo) 7.6%
            'cofins_c': 0.03,        # COFINS (cumulativo) 3%
            'pis_cofins_nc': 0.0925,  # Total n√£o-cumulativo 9.25%
            'ipi': 0.0,              # IPI telecom (varia por produto, aqui 0% aprox)
        }
        logger.info("‚úì Taxas federais (PIS/COFINS/IPI) carregadas")
        return rates


# ============================================================================
# 7Ô∏è‚É£ FRETE GLOBAL CONNECTOR (Drewry, Freightos, Baltic)
# ============================================================================

class FreightConnector:
    """Download √≠ndices de frete global (WCI, FBX, BDI)"""
    
    @staticmethod
    def scrape_drewry_wci() -> pd.DataFrame:
        """
        Scrape World Container Index (Drewry) - dados p√∫blicos
        
        Nota: Requer BeautifulSoup/Selenium (dados em tabelas HTML)
        """
        logger.warning("‚ö†Ô∏è WCI requer web scraping. Manual:")
        logger.info("1. Acessar: https://www.drewry.co.uk/")
        logger.info("2. Hist√≥rico: https://www.drewry.co.uk/supply-chain-research/services/indices/world-container-index-(wci)/historical-data")
        return pd.DataFrame()
    
    @staticmethod
    def get_freightos_api_info():
        """Informa√ß√µes para acessar FBX API (requer contato)"""
        logger.info("FBX API: Contatar https://www.freightos.com/freight-api")
        logger.info("Dados hist√≥ricos gr√°tis: https://www.freightos.com/freight-resources/freight-rate-index/historical-data")


# ============================================================================
# 8Ô∏è‚É£ TRADING ECONOMICS CONNECTOR (Indicadores agregados)
# ============================================================================

class TradingEconomicsConnector:
    """Conex√£o Trading Economics (requer API key, ou dados p√∫blicos)"""
    
    @staticmethod
    def list_free_indicators():
        """Indicadores Brasil dispon√≠veis (free tier)"""
        indicators = {
            'Brazil Currency': 'https://tradingeconomics.com/brazil/currency',
            'Brazil Inflation Rate': 'https://tradingeconomics.com/brazil/inflation-rate',
            'Brazil Interest Rate': 'https://tradingeconomics.com/brazil/interest-rate',
            'Brazil GDP': 'https://tradingeconomics.com/brazil/gdp',
            'Brazil Unemployment': 'https://tradingeconomics.com/brazil/unemployment-rate',
        }
        logger.info("‚úì Indicadores TE (acesso livre via web)")
        return indicators


# ============================================================================
# üéØ MAIN ORCHESTRATOR
# ============================================================================

class DataPipelineOrchestrator:
    """Orquestra todos os downloads e consolida√ß√£o"""
    
    def __init__(self, output_dir: str = './dados_baixados'):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        logger.info(f"Pipeline inicializado. Output: {output_dir}")
    
    def run_daily_batch(self) -> Dict[str, pd.DataFrame]:
        """Executa batch di√°rio (dados que mudam frequentemente)"""
        logger.info("=" * 80)
        logger.info("INICIANDO BATCH DI√ÅRIO")
        logger.info("=" * 80)
        
        results = {}
        
        # C√¢mbio (di√°rio)
        logger.info("\n[1/3] Baixando c√¢mbio PTAX...")
        ptax_df = BACENConnector.download_ptax(
            start_date=(datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
        )
        if not ptax_df.empty:
            ptax_df.to_csv(f"{self.output_dir}/ptax_30d_{datetime.now().strftime('%Y%m%d')}.csv")
            results['ptax'] = ptax_df
        
        # Selic (bimestral, mas verificar mudan√ßas)
        logger.info("[2/3] Baixando Selic hist√≥rica...")
        selic_df = BACENConnector.download_selic()
        if not selic_df.empty:
            selic_df.to_csv(f"{self.output_dir}/selic_historico.csv")
            results['selic'] = selic_df
        
        # Impostos (est√°tico, baixar 1x por ano)
        logger.info("[3/3] Carregando tabelas fiscais...")
        icms = ReceitaFederalConnector.get_icms_rates_by_state()
        federal_taxes = ReceitaFederalConnector.get_federal_tax_rates()
        pd.Series(icms).to_csv(f"{self.output_dir}/icms_rates_2025.csv")
        pd.Series(federal_taxes).to_csv(f"{self.output_dir}/federal_tax_rates_2025.csv")
        results['icms'] = icms
        results['federal_taxes'] = federal_taxes
        
        logger.info(f"\n‚úì Batch di√°rio conclu√≠do. {len(results)} datasets.")
        return results
    
    def run_monthly_batch(self) -> Dict[str, pd.DataFrame]:
        """Executa batch mensal (dados mensais)"""
        logger.info("=" * 80)
        logger.info("INICIANDO BATCH MENSAL")
        logger.info("=" * 80)
        
        results = {}
        
        # IPCA
        logger.info("\n[1/3] Baixando IPCA mensal...")
        ipca_df = IBGEConnector.download('ipca_monthly')
        if not ipca_df.empty:
            ipca_df.to_csv(f"{self.output_dir}/ipca_monthly_{datetime.now().strftime('%Y%m%d')}.csv")
            results['ipca'] = ipca_df
        
        # Desemprego
        logger.info("[2/3] Baixando taxa de desocupa√ß√£o...")
        unemployment_df = IBGEConnector.download('unemployment')
        if not unemployment_df.empty:
            unemployment_df.to_csv(f"{self.output_dir}/unemployment_{datetime.now().strftime('%Y%m%d')}.csv")
            results['unemployment'] = unemployment_df
        
        # Clima (exemplo de esta√ß√£o Salvador)
        logger.info("[3/3] Dados clim√°ticos (requer download manual)...")
        logger.info("‚Üí Baixar de https://bdmep.inmet.gov.br/")
        
        logger.info(f"\n‚úì Batch mensal conclu√≠do. {len(results)} datasets.")
        return results
    
    def run_quarterly_batch(self) -> Dict[str, pd.DataFrame]:
        """Executa batch trimestral"""
        logger.info("=" * 80)
        logger.info("INICIANDO BATCH TRIMESTRAL")
        logger.info("=" * 80)
        
        results = {}
        
        # PIB
        logger.info("\nBaixando PIB trimestral...")
        pib_df = IBGEConnector.download('pib_quarterly')
        if not pib_df.empty:
            pib_df.to_csv(f"{self.output_dir}/pib_quarterly_{datetime.now().strftime('%Y%m%d')}.csv")
            results['pib'] = pib_df
        
        logger.info(f"\n‚úì Batch trimestral conclu√≠do. {len(results)} datasets.")
        return results
    
    def generate_master_report(self, daily_results: Dict, 
                               monthly_results: Dict, 
                               quarterly_results: Dict) -> None:
        """Consolida todos os dados em relat√≥rio master"""
        report_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        summary = {
            'execution_date': report_date,
            'daily_datasets': len(daily_results),
            'monthly_datasets': len(monthly_results),
            'quarterly_datasets': len(quarterly_results),
            'files_saved': len(os.listdir(self.output_dir))
        }
        
        with open(f"{self.output_dir}/execution_summary_{datetime.now().strftime('%Y%m%d')}.json", 'w') as f:
            json.dump(summary, f, indent=2, default=str)
        
        logger.info(f"\n‚úÖ PIPELINE CONCLU√çDO")
        logger.info(f"Resumo: {summary}")


# ============================================================================
# üöÄ EXAMPLE USAGE
# ============================================================================

if __name__ == "__main__":
    
    # Inicializar orquestrador
    orchestrator = DataPipelineOrchestrator(output_dir='./nova_corrente_dados')
    
    # Executar batch di√°rio
    daily_data = orchestrator.run_daily_batch()
    
    # Executar batch mensal (opcional)
    # monthly_data = orchestrator.run_monthly_batch()
    
    # Gerar relat√≥rio
    logger.info("\n" + "=" * 80)
    logger.info("PR√ìXIMOS PASSOS:")
    logger.info("=" * 80)
    logger.info("1. Configure APIs (IBGE, BACEN, ANATEL) conforme necess√°rio")
    logger.info("2. Integre com Airflow para agendamento autom√°tico")
    logger.info("3. Configure Feature Store (Feast/Tecton)")
    logger.info("4. Implemente valida√ß√£o de dados (Great Expectations)")
    logger.info("5. Conecte com pipeline ML (Prophet, ARIMAX, TFT)")
