# üöÄ ROADMAP ANALYTICS ENGINEERING COMPLETO
## Nova Corrente - Previsibilidade de Demandas com IA

**Vers√£o:** 2.0 (Atualizado para 4-Day Sprint)  
**Data:** Novembro 2025  
**Status:** ‚úÖ Roadmap Atualizado - Escopo Reduzido para Sprint de 4 Dias  
**Dura√ß√£o Estimada:** 4 dias (D0-D4) - Sprint Intensivo

---

## üö® ATUALIZA√á√ÉO DE ESCOPO - 4-DAY SPRINT

**√öltima Atualiza√ß√£o:** Novembro 2025  
**Escopo Atual:** 4-Day Sprint (Reduzido)  
**Refer√™ncia:** [docs/diagnostics/clusters/00_OVERVIEW_INDEX_4DAY_SPRINT_PT_BR.md](../../diagnostics/clusters/00_OVERVIEW_INDEX_4DAY_SPRINT_PT_BR.md)

### üîÑ Mudan√ßas de Escopo:

**Timeline:**
- ‚ùå **Anterior:** 16 semanas (4 meses)
- ‚úÖ **Atual:** 4 dias (sprint intensivo)

**Stack Tecnol√≥gico:**
- ‚ùå **Anterior:** Delta Lake + S3 + Spark + Databricks + Airflow + dbt + MLflow
- ‚úÖ **Atual:** Parquet + MinIO + DuckDB + Pandas + Simple Orchestrator + Python Scripts

**ML Strategy:**
- ‚ùå **Anterior:** ML Ops completo em deployment (MLflow, model serving, feature store)
- ‚úÖ **Atual:** **NO ML OPS IN DEPLOYMENT** - ML processing separado, apenas resultados pr√©-computados

**Storage:**
- ‚ùå **Anterior:** S3 (cloud) + Delta Lake (ACID transactions)
- ‚úÖ **Atual:** MinIO (local/Docker) + Parquet (lightweight format)

**Compute:**
- ‚ùå **Anterior:** Spark + Databricks (cloud compute)
- ‚úÖ **Atual:** DuckDB (in-process SQL) + Pandas (Python processing)

**Orquestra√ß√£o:**
- ‚ùå **Anterior:** Airflow/Prefect (complex orchestration)
- ‚úÖ **Atual:** Simple scheduler/orchestrator (Python scripts)

**Transforma√ß√µes:**
- ‚ùå **Anterior:** dbt models (SQL transformations)
- ‚úÖ **Atual:** Python scripts + SQL queries (DuckDB)

### üìã Escopo Anterior (Arquivado):

Este documento foi originalmente planejado para implementa√ß√£o de 16 semanas com stack completo de Analytics Engineering. O escopo foi reduzido para um sprint de 4 dias com foco em:
- ‚úÖ MVP funcional
- ‚úÖ Deployment simplificado
- ‚úÖ Zero depend√™ncias de cloud ML
- ‚úÖ Self-hosted deployment
- ‚úÖ Offline deployable

**Refer√™ncia ao Escopo Original:** As se√ß√µes originais foram mantidas para refer√™ncia futura, mas marcadas como "escopo expandido (futuro)".

---

## üìã √çNDICE

1. [Vis√£o Geral de Analytics Engineering](#visao-geral)
2. [Arquitetura de Dados Moderna](#arquitetura-dados)
3. [Modelagem de Dados](#modelagem-dados)
4. [Pipeline de Engenharia de Dados](#pipeline-engenharia)
5. [ML Ops Pipeline](#ml-ops)
6. [Qualidade e Observabilidade](#qualidade-observabilidade)
7. [Infraestrutura como C√≥digo](#infraestrutura-codigo)
8. [Analytics e BI](#analytics-bi)
9. [Governan√ßa de Dados](#governanca-dados)
10. [Roadmap de Implementa√ß√£o](#roadmap-implementacao)
11. [Tecnologias e Ferramentas](#tecnologias-ferramentas)
12. [M√©tricas de Sucesso](#metricas-sucesso)

---

<a name="visao-geral"></a>

## 1. üìä VIS√ÉO GERAL DE ANALYTICS ENGINEERING

### 1.1 O que √© Analytics Engineering?

**Defini√ß√£o:**
Analytics Engineering √© a disciplina que transforma dados brutos em insights acion√°veis atrav√©s de:
- Transforma√ß√£o de dados com c√≥digo (dbt, SQL)
- Versionamento e testes de dados
- Documenta√ß√£o automatizada
- CI/CD para analytics
- Self-service para usu√°rios de neg√≥cio

**Princ√≠pios Fundamentais:**

1. **C√≥digo-First:** Transforma√ß√µes em c√≥digo (n√£o GUI)
2. **Versionamento:** Git para todas transforma√ß√µes
3. **Testes:** Valida√ß√£o autom√°tica de qualidade
4. **Documenta√ß√£o:** Gerada automaticamente
5. **Repetibilidade:** Pipelines idempotentes
6. **Colabora√ß√£o:** Equipes trabalham juntas com c√≥digo

### 1.2 Stack Simplificado para 4-Day Sprint

**Camada de Transforma√ß√£o:**
- ‚úÖ **Python Scripts:** Transforma√ß√µes ETL em Python
- ‚úÖ **SQL (DuckDB):** Queries SQL diretas sobre Parquet
- ‚úÖ **Pandas:** Transforma√ß√µes complexas de dados

**Camada de Armazenamento:**
- ‚úÖ **Parquet:** Formato de arquivo colunar otimizado
- ‚úÖ **MinIO:** Storage S3-compatible (local/Docker)
- ‚úÖ **Parquet Layers:** Bronze (raw) ‚Üí Silver (cleaned) ‚Üí Gold (curated)

**Camada de Compute:**
- ‚úÖ **DuckDB:** In-process SQL engine sobre Parquet
- ‚úÖ **Pandas:** Processamento Python de dados
- ‚úÖ **No Spark/Databricks:** Removido para simplifica√ß√£o

**Camada de Orquestra√ß√£o:**
- ‚úÖ **Simple Scheduler:** Python scripts com cron/schedule
- ‚úÖ **Docker Compose:** Orquestra√ß√£o de servi√ßos
- ‚úÖ **GitHub Actions:** CI/CD b√°sico (opcional)

**Camada de BI:**
- ‚úÖ **FastAPI Backend:** API REST para dados
- ‚úÖ **React Frontend:** Dashboard interativo
- ‚úÖ **Recharts:** Visualiza√ß√£o de dados

### 1.2.1 Stack Expandido (Futuro - Refer√™ncia Original)

**Nota:** O stack original abaixo foi planejado para implementa√ß√£o de 16 semanas. Mantido para refer√™ncia futura.

**Camada de Transforma√ß√£o (Original):**
- **dbt (data build tool):** Framework SQL para transforma√ß√µes
- **SQL:** Linguagem padr√£o de transforma√ß√£o
- **Python:** Para transforma√ß√µes complexas (UDFs)

**Camada de Armazenamento (Original):**
- **Data Lakehouse:** Delta Lake ou Iceberg
- **Medallion Architecture:** Bronze ‚Üí Silver ‚Üí Gold
- **Cloud Data Warehouses:** Snowflake, BigQuery, Redshift

**Camada de Orquestra√ß√£o (Original):**
- **Airflow/Prefect:** Orquestra√ß√£o de pipelines
- **dbt Cloud:** CI/CD para dbt
- **GitHub Actions:** CI/CD para c√≥digo

**Camada de BI (Original):**
- **Metabase/Superset:** Self-service analytics
- **dbt Semantic Layer:** M√©tricas unificadas
- **Embed Analytics:** Integra√ß√£o em apps

### 1.3 Arquitetura Parquet Layers (Bronze/Silver/Gold)

**Camada Bronze (Raw):**
```
- Dados brutos como chegam das fontes
- Sem transforma√ß√µes, apenas ingest√£o
- Schema evolu√ß√£o permitida
- Particionamento por data/hora
- Formato: Parquet (lightweight, no Delta)
- Storage: MinIO (local/Docker)
```

**Camada Silver (Cleaned):**
```
- Dados limpos e validados
- Schema aplicado
- Duplicatas removidas
- Tipos corrigidos
- Ready for analytics
- Processamento: DuckDB + Pandas
```

**Camada Gold (Curated):**
```
- Modelos de neg√≥cio (star schema)
- M√©tricas pr√©-calculadas
- Agrega√ß√µes por dimens√µes
- Ready for API consumption
- Performance otimizado (Parquet)
- ML Results: Precomputed forecasts only
```

### 1.3.1 Arquitetura Expandida (Futuro - Refer√™ncia Original)

**Nota:** A arquitetura Medallion original com Delta Lake foi planejada para 16 semanas. Mantida para refer√™ncia futura.

**Camada Bronze (Original):**
```
- Formato: Parquet/Delta/Iceberg
- Storage: S3 (cloud)
```

**Camada Silver (Original):**
```
- Formato: Delta Lake (ACID transactions)
- Compute: Spark + Databricks
```

**Camada Gold (Original):**
```
- Formato: Delta Lake
- BI Tools: Metabase/Superset
```

### 1.4 Data Vault 2.0 para Escalabilidade

**Componentes:**

1. **Hubs (Entidades de Neg√≥cio):**
   - Item Hub, Torre Hub, Fornecedor Hub
   - Chaves de neg√≥cio √∫nicas
   - Timestamp de cria√ß√£o

2. **Links (Rela√ß√µes):**
   - Item-Torre Link
   - Item-Fornecedor Link
   - Torre-Contrato Link

3. **Satellites (Atributos Hist√≥ricos):**
   - Item Satellite (descri√ß√£o, categoria)
   - Torre Satellite (localiza√ß√£o, status)
   - Forecast Satellite (previs√µes hist√≥ricas)

**Vantagens:**
- Escalabilidade horizontal
- Auditoria completa (tudo hist√≥rico)
- Flexibilidade (novas fontes f√°ceis)
- Performance (particionamento)

---

<a name="arquitetura-dados"></a>

## 2. üèóÔ∏è ARQUITETURA DE DADOS MODERNA

### 2.1 Arquitetura Parquet Simplificada (4-Day Sprint)

**Defini√ß√£o:**
Arquitetura simplificada para sprint de 4 dias:
- ‚úÖ **Storage:** MinIO (S3-compatible, local/Docker)
- ‚úÖ **Format:** Parquet (lightweight, columnar)
- ‚úÖ **Compute:** DuckDB (in-process SQL)
- ‚úÖ **Processing:** Pandas (Python)

**Implementa√ß√£o:**
- ‚úÖ **Parquet:** Formato de arquivo colunar otimizado
- ‚úÖ **MinIO:** Storage local compat√≠vel com S3
- ‚úÖ **DuckDB:** SQL engine sobre Parquet (sem Spark)
- ‚úÖ **No Delta Lake:** Removido para simplifica√ß√£o

**Para Nova Corrente (4-Day Sprint):**
```
Parquet Stack Simplificado:
‚îú‚îÄ‚îÄ Storage: MinIO (local/Docker, S3-compatible)
‚îú‚îÄ‚îÄ Format: Parquet (lightweight, no ACID overhead)
‚îú‚îÄ‚îÄ Compute: DuckDB (in-process SQL engine)
‚îú‚îÄ‚îÄ Processing: Pandas (Python data processing)
‚îî‚îÄ‚îÄ Access: SQL (DuckDB SQL) + Python API
```

**Benef√≠cios:**
- ‚úÖ Zero depend√™ncias de cloud
- ‚úÖ Self-hosted deployment
- ‚úÖ Offline deployable
- ‚úÖ Setup r√°pido (< 1 hora)
- ‚úÖ Custo zero (open source)

### 2.1.1 Data Lakehouse Expandido (Futuro - Refer√™ncia Original)

**Nota:** A arquitetura Data Lakehouse original foi planejada para 16 semanas. Mantida para refer√™ncia futura.

**Defini√ß√£o (Original):**
Arquitetura que combina:
- **Data Lake:** Armazenamento barato e escal√°vel
- **Data Warehouse:** Performance e ACID transactions
- **Benef√≠cios:** Melhor dos dois mundos

**Implementa√ß√£o (Original):**
- **Delta Lake:** ACID transactions sobre Parquet
- **Apache Iceberg:** Tabelas versionadas
- **Apache Hudi:** Upserts e deletes incrementais

**Para Nova Corrente (Original):**
```
Data Lakehouse Stack:
‚îú‚îÄ‚îÄ Storage: S3/MinIO (objeto)
‚îú‚îÄ‚îÄ Format: Delta Lake (transa√ß√µes ACID)
‚îú‚îÄ‚îÄ Compute: Spark (processamento)
‚îú‚îÄ‚îÄ Catalog: Unity Catalog / Hive Metastore
‚îî‚îÄ‚îÄ Access: SQL (Spark SQL, Delta SQL)
```

### 2.2 Streaming e Batch

**Arquitetura Lambda:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Batch    ‚îÇ      ‚îÇ   Streaming  ‚îÇ
‚îÇ   (ETL)    ‚îÇ      ‚îÇ   (Real-time)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ                     ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ   Serving    ‚îÇ
         ‚îÇ    Layer     ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Batch Pipeline:**
- Execu√ß√£o di√°ria/semanal
- Transforma√ß√µes complexas
- Dados hist√≥ricos
- Ferramentas: Airflow, dbt

**Streaming Pipeline:**
- Tempo real (< 1 minuto lat√™ncia)
- Eventos cr√≠ticos (alertas)
- Kafka ‚Üí Flink ‚Üí Delta
- Ferramentas: Kafka, Flink, Kafka Connect

**Para Nova Corrente:**
- **Batch:** Previs√µes di√°rias, relat√≥rios semanais
- **Streaming:** Alertas cr√≠ticos, mudan√ßas de estoque em tempo real

### 2.3 Data Mesh (Microservi√ßos de Dados)

**Conceito:**
Arquitetura distribu√≠da onde:
- Cada dom√≠nio √© dono de seus dados
- Produtos de dados (n√£o apenas datasets)
- Infraestrutura compartilhada self-serve
- Governan√ßa federada

**Para Nova Corrente:**

**Dom√≠nios:**
```
‚îú‚îÄ‚îÄ Forecasting Domain
‚îÇ   ‚îú‚îÄ‚îÄ Forecast Data Products
‚îÇ   ‚îî‚îÄ‚îÄ Model Metrics Data Products
‚îÇ
‚îú‚îÄ‚îÄ Inventory Domain
‚îÇ   ‚îú‚îÄ‚îÄ Stock Levels Data Products
‚îÇ   ‚îî‚îÄ‚îÄ Reorder Points Data Products
‚îÇ
‚îú‚îÄ‚îÄ Procurement Domain
‚îÇ   ‚îú‚îÄ‚îÄ Purchase Orders Data Products
‚îÇ   ‚îî‚îÄ‚îÄ Supplier Performance Data Products
‚îÇ
‚îî‚îÄ‚îÄ Operations Domain
    ‚îú‚îÄ‚îÄ Tower Status Data Products
    ‚îî‚îÄ‚îÄ SLA Metrics Data Products
```

**Benef√≠cios:**
- Escalabilidade horizontal
- Autonomia das equipes
- Reutiliza√ß√£o de produtos
- Governan√ßa descentralizada

### 2.4 Diagrama Arquitetural Simplificado (4-Day Sprint)

```mermaid
graph TB
    subgraph "Data Sources"
        ERP[ERP System]
        WEATHER[Weather APIs]
        ANATEL[Anatel APIs]
        SUPPLIER[Supplier APIs]
    end
    
    subgraph "Ingestion Layer"
        BRONZE[Bronze Layer<br/>Parquet Files<br/>MinIO Storage]
    end
    
    subgraph "Processing Layer"
        SILVER[Silver Layer<br/>Cleaned Parquet]
        DUCKDB[DuckDB<br/>SQL Engine]
        PANDAS[Pandas<br/>Python Processing]
    end
    
    subgraph "Storage Layer"
        MINIO[MinIO<br/>S3-Compatible<br/>Local/Docker]
        GOLD[Gold Layer<br/>Star Schema<br/>Parquet Files]
    end
    
    subgraph "ML Environment (Separate)"
        ML_TRAIN[ML Training<br/>Prophet/ARIMA/LSTM<br/>Separate Environment]
        ML_OUTPUT[Precomputed Results<br/>Parquet Files<br/>model_version metadata]
    end
    
    subgraph "Analytics Layer"
        FASTAPI[FastAPI Backend<br/>REST API<br/>Read-Only]
        REACT[React Frontend<br/>Dashboard<br/>Recharts]
        DUCKDB_QUERY[DuckDB Queries<br/>SQL over Parquet]
    end
    
    subgraph "Deployment"
        DOCKER[Docker Compose<br/>Local Deployment]
        REDIS[Redis Cache<br/>Optional]
    end
    
    ERP & WEATHER & ANATEL & SUPPLIER --> BRONZE
    BRONZE --> SILVER
    SILVER --> DUCKDB
    SILVER --> PANDAS
    DUCKDB --> GOLD
    PANDAS --> GOLD
    GOLD --> MINIO
    
    ML_TRAIN --> ML_OUTPUT
    ML_OUTPUT -.->|Read Only| GOLD
    
    GOLD --> DUCKDB_QUERY
    DUCKDB_QUERY --> FASTAPI
    FASTAPI --> REACT
    FASTAPI --> REDIS
    
    GOLD --> FASTAPI
    FASTAPI --> DOCKER
    
    style ML_TRAIN fill:#ff9999,stroke:#ff0000,stroke-width:2px
    style ML_OUTPUT fill:#ffcccc,stroke:#ff0000,stroke-width:2px
    style GOLD fill:#99ff99,stroke:#00ff00,stroke-width:2px
    style FASTAPI fill:#99ccff,stroke:#0066ff,stroke-width:2px
    style REACT fill:#99ccff,stroke:#0066ff,stroke-width:2px
    style DOCKER fill:#ffcc99,stroke:#ff6600,stroke-width:2px
```

**Legenda:**
- üî¥ **ML Environment (Separate):** ML processing separado, N√ÉO em deployment
- üü¢ **Gold Layer:** Resultados pr√©-computados (read-only)
- üîµ **Analytics Layer:** FastAPI + React (read-only)
- üü† **Deployment:** Docker Compose (self-hosted)

### 2.4.1 Diagrama Arquitetural Expandido (Futuro - Refer√™ncia Original)

**Nota:** O diagrama original com Delta Lake, Spark, MLflow foi planejado para 16 semanas. Mantido para refer√™ncia futura.

```mermaid
graph TB
    subgraph "Data Sources"
        ERP[ERP System]
        WEATHER[Weather APIs]
        ANATEL[Anatel APIs]
        SUPPLIER[Supplier APIs]
    end
    
    subgraph "Ingestion Layer"
        BRONZE[Bronze Layer<br/>Raw Data]
        KAFKA[Kafka Streams<br/>Real-time Events]
    end
    
    subgraph "Processing Layer"
        SILVER[Silver Layer<br/>Cleaned Data]
        DBT[dbt Transformations]
        SPARK[Spark Processing]
    end
    
    subgraph "Storage Layer"
        DELTA[Delta Lake<br/>ACID Transactions]
        GOLD[Gold Layer<br/>Business Models]
    end
    
    subgraph "ML Layer"
        MLFLOW[MLflow<br/>Model Registry]
        FEATURES[Feature Store]
        INFERENCE[Model Serving]
    end
    
    subgraph "Analytics Layer"
        METABASE[Metabase<br/>Self-Service BI]
        SUPERSET[Superset<br/>Dashboards]
        API[REST API<br/>dbt Semantic Layer]
    end
    
    subgraph "Governance"
        DATAHUB[DataHub<br/>Catalog & Lineage]
        GREATEXP[Great Expectations<br/>Data Quality]
    end
    
    ERP & WEATHER & ANATEL & SUPPLIER --> BRONZE
    BRONZE --> KAFKA
    KAFKA --> SILVER
    BRONZE --> SILVER
    SILVER --> DBT
    DBT --> SPARK
    SPARK --> DELTA
    DELTA --> GOLD
    GOLD --> MLFLOW
    MLFLOW --> FEATURES
    FEATURES --> INFERENCE
    GOLD --> METABASE
    GOLD --> SUPERSET
    GOLD --> API
    
    SILVER --> GREATEXP
    GOLD --> DATAHUB
    INFERENCE --> DATAHUB
```

---

<a name="modelagem-dados"></a>

## 3. üìê MODELAGEM DE DADOS

### 3.1 Dimensional (Star Schema)

**Para Analytics de Neg√≥cio:**

```sql
-- Fact Table: Forecast Metrics
CREATE TABLE fact_forecast_metrics (
    forecast_id BIGINT,
    item_id STRING,
    date DATE,
    forecasted_demand DECIMAL(10,2),
    actual_demand DECIMAL(10,2),
    mape DECIMAL(5,2),
    created_at TIMESTAMP
);

-- Dimension: Items
CREATE TABLE dim_items (
    item_id STRING,
    item_name STRING,
    category STRING,
    supplier_id STRING,
    cost DECIMAL(10,2),
    valid_from DATE,
    valid_to DATE
);

-- Dimension: Towers
CREATE TABLE dim_towers (
    tower_id STRING,
    tower_name STRING,
    city STRING,
    state STRING,
    region STRING,
    sla_tier STRING,
    valid_from DATE,
    valid_to DATE
);

-- Dimension: Time
CREATE TABLE dim_time (
    date DATE,
    year INT,
    quarter INT,
    month INT,
    week INT,
    day_of_week INT,
    is_weekend BOOLEAN,
    is_holiday BOOLEAN,
    holiday_name STRING
);
```

**Vantagens:**
- Simples para BI tools
- Performance otimizado
- F√°cil de entender

### 3.2 Data Vault 2.0 (Hubs, Links, Satellites)

**Estrutura para Escalabilidade:**

```sql
-- Hub: Item (Business Key)
CREATE TABLE hub_item (
    item_hk STRING,  -- Hash of item_id
    item_id STRING,  -- Business Key
    load_dt TIMESTAMP
);

-- Link: Item-Tower Relationship
CREATE TABLE link_item_tower (
    item_tower_hk STRING,  -- Hash of (item_id, tower_id)
    item_hk STRING,
    tower_hk STRING,
    load_dt TIMESTAMP
);

-- Satellite: Item Attributes
CREATE TABLE sat_item (
    item_hk STRING,
    item_name STRING,
    category STRING,
    supplier_id STRING,
    cost DECIMAL(10,2),
    load_dt TIMESTAMP,
    load_end_dt TIMESTAMP,
    hash_diff STRING
);

-- Satellite: Forecast History
CREATE TABLE sat_forecast (
    item_hk STRING,
    forecast_date DATE,
    forecasted_demand DECIMAL(10,2),
    model_type STRING,
    confidence_interval_lower DECIMAL(10,2),
    confidence_interval_upper DECIMAL(10,2),
    load_dt TIMESTAMP,
    hash_diff STRING
);
```

**Views de Neg√≥cio (Presentation Layer):**
```sql
-- View: Current Item Details
CREATE VIEW vw_items_current AS
SELECT 
    h.item_id,
    s.item_name,
    s.category,
    s.supplier_id,
    s.cost
FROM hub_item h
INNER JOIN sat_item s ON h.item_hk = s.item_hk
WHERE s.load_end_dt IS NULL;  -- Current version
```

### 3.3 dbt Models e Testes

**Model: stg_items (Staging):**

```sql
-- models/staging/stg_items.sql
{{ config(materialized='view') }}

WITH source AS (
    SELECT * FROM {{ source('bronze', 'raw_items') }}
),

cleaned AS (
    SELECT
        item_id,
        TRIM(item_name) AS item_name,
        LOWER(category) AS category,
        supplier_id,
        CAST(cost AS DECIMAL(10,2)) AS cost,
        created_at
    FROM source
    WHERE item_id IS NOT NULL
)

SELECT * FROM cleaned
```

**Model: dim_items (Dimension):**

```sql
-- models/marts/dim_items.sql
{{ config(materialized='table') }}

WITH staging AS (
    SELECT * FROM {{ ref('stg_items') }}
),

final AS (
    SELECT
        item_id,
        item_name,
        category,
        supplier_id,
        cost,
        CURRENT_TIMESTAMP AS valid_from,
        NULL AS valid_to
    FROM staging
)

SELECT * FROM final
```

**Testes:**

```yaml
# models/schema.yml
version: 2

models:
  - name: dim_items
    columns:
      - name: item_id
        tests:
          - unique
          - not_null
      - name: item_name
        tests:
          - not_null
      - name: cost
        tests:
          - not_null
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 1000000
```

### 3.4 Schema Evolution

**Estrat√©gias:**

1. **Backward Compatible:**
   - Adicionar colunas opcionais
   - N√£o remover colunas (deprecated)
   - Sem mudan√ßas de tipo

2. **Schema Registry:**
   - Kafka Schema Registry
   - Delta Lake schema evolution autom√°tico
   - Valida√ß√£o autom√°tica

3. **Migration Scripts:**
   - Alembic (SQLAlchemy)
   - dbt migrations
   - Versionamento de schemas

---

<a name="pipeline-engenharia"></a>

## 4. üîÑ PIPELINE DE ENGENHARIA DE DADOS

### 4.1 Extra√ß√£o (Fivetran, Airbyte)

**Fivetran:**
- Conectores prontos (ERP, APIs)
- Schema evolution autom√°tico
- Transforma√ß√µes b√°sicas
- Custo: ~$500/m√™s por connector

**Airbyte (Open Source):**
- Self-hosted ou Cloud
- 200+ conectores
- Custom connectors (Python)
- Custo: Infraestrutura pr√≥pria

**Para Nova Corrente:**
```
Extraction Sources:
‚îú‚îÄ‚îÄ ERP System ‚Üí Airbyte (PostgreSQL)
‚îú‚îÄ‚îÄ Weather API ‚Üí Custom Python (cron)
‚îú‚îÄ‚îÄ Anatel API ‚Üí Custom Python (daily)
‚îú‚îÄ‚îÄ Supplier APIs ‚Üí Airbyte (REST)
‚îî‚îÄ‚îÄ Kafka ‚Üí Real-time ingestion
```

### 4.2 Transforma√ß√£o (dbt)

**dbt Project Structure:**
```
nova_corrente_dbt/
‚îú‚îÄ‚îÄ dbt_project.yml
‚îú‚îÄ‚îÄ profiles.yml
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ staging/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_items.sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_towers.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stg_forecasts.sql
‚îÇ   ‚îú‚îÄ‚îÄ intermediate/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ int_item_metrics.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ int_forecast_accuracy.sql
‚îÇ   ‚îî‚îÄ‚îÄ marts/
‚îÇ       ‚îú‚îÄ‚îÄ dim_items.sql
‚îÇ       ‚îú‚îÄ‚îÄ dim_towers.sql
‚îÇ       ‚îú‚îÄ‚îÄ fact_forecasts.sql
‚îÇ       ‚îî‚îÄ‚îÄ metrics/
‚îÇ           ‚îî‚îÄ‚îÄ forecast_accuracy.sql
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ assertions/
‚îÇ   ‚îî‚îÄ‚îÄ custom_tests/
‚îú‚îÄ‚îÄ macros/
‚îÇ   ‚îú‚îÄ‚îÄ reorder_point.sql
‚îÇ   ‚îî‚îÄ‚îÄ safety_stock.sql
‚îî‚îÄ‚îÄ snapshots/
    ‚îî‚îÄ‚îÄ snp_items.sql
```

**Exemplo: Macro Reorder Point**

```sql
-- macros/reorder_point.sql
{% macro calculate_reorder_point(
    avg_demand,
    lead_time,
    std_demand,
    service_level=0.95
) %}
    {% set z_score = 1.96 %}  -- 95% service level
    {% set safety_stock = z_score * std_demand * sqrt(lead_time) %}
    {{ avg_demand * lead_time + safety_stock }}
{% endmacro %}
```

**Uso:**
```sql
SELECT
    item_id,
    {{ calculate_reorder_point(
        avg_daily_demand,
        lead_time,
        std_daily_demand,
        0.95
    ) }} AS reorder_point
FROM {{ ref('int_item_metrics') }}
```

### 4.3 Carregamento (ELT)

**Padr√£o ELT:**
1. **Extract:** Dados brutos ‚Üí Bronze
2. **Load:** Bronze ‚Üí Silver (apenas schema)
3. **Transform:** Silver ‚Üí Gold (dbt transformations)

**Vantagens ELT vs ETL:**
- Flexibilidade (transforma√ß√µes podem mudar)
- Performance (processamento no warehouse)
- Escalabilidade (compute separado de storage)

**Pipeline Airflow:**

```python
# dags/nova_corrente_pipeline.py
from airflow import DAG
from airflow.providers.databricks.operators.databricks import DatabricksRunNowOperator
from airflow.operators.bash import BashOperator

dag = DAG(
    'nova_corrente_daily',
    schedule_interval='@daily',
    catchup=False
)

# Extract
extract_task = BashOperator(
    task_id='extract_data',
    bash_command='python scripts/extract_all_sources.py',
    dag=dag
)

# Load to Bronze
load_bronze = DatabricksRunNowOperator(
    task_id='load_bronze',
    job_id=12345,
    dag=dag
)

# Transform with dbt
run_dbt = BashOperator(
    task_id='run_dbt',
    bash_command='cd dbt && dbt run --profiles-dir .',
    dag=dag
)

# Run tests
test_dbt = BashOperator(
    task_id='test_dbt',
    bash_command='cd dbt && dbt test --profiles-dir .',
    dag=dag
)

extract_task >> load_bronze >> run_dbt >> test_dbt
```

### 4.4 Orquestra√ß√£o Simplificada (4-Day Sprint)

**Simple Scheduler:**
- ‚úÖ Python scripts com cron/schedule
- ‚úÖ Docker Compose para orquestra√ß√£o de servi√ßos
- ‚úÖ GitHub Actions para CI/CD b√°sico (opcional)

**Para Nova Corrente (4-Day Sprint):**
- ‚úÖ **Simple Scheduler:** Python scripts com schedule
- ‚úÖ **Docker Compose:** Orquestra√ß√£o de servi√ßos locais
- ‚úÖ **No Airflow/Prefect:** Removido para simplifica√ß√£o

**Exemplo:**
```python
# scripts/scheduler.py
import schedule
import time

def run_data_pipeline():
    """Run data pipeline daily"""
    # Extract
    extract_data()
    # Transform
    transform_data()
    # Load
    load_to_gold()

# Schedule daily at 2 AM
schedule.every().day.at("02:00").do(run_data_pipeline)

while True:
    schedule.run_pending()
    time.sleep(60)
```

### 4.4.1 Orquestra√ß√£o Expandida (Futuro - Refer√™ncia Original)

**Nota:** Airflow/Prefect foi planejado para implementa√ß√£o de 16 semanas. Mantido para refer√™ncia futura.

**Airflow (Original):**
- Padr√£o da ind√∫stria
- UI robusta
- Muitos operators
- Escal√°vel

**Prefect (Original):**
- Moderno (Python-first)
- UI elegante
- F√°cil de usar
- Boa documenta√ß√£o

**Para Nova Corrente (Original):**
- **Recomenda√ß√£o:** Airflow (mais maduro, mais comunidade)
- **Alternativa:** Prefect (se time prefere Python)

---

<a name="ml-ops"></a>

## 5. ü§ñ ML STRATEGY - NO ML OPS IN DEPLOYMENT

### üîí GLOBAL CONSTRAINT: NO ML OPS LOGIC IN DEPLOYMENT

**Policy:** All Machine Learning (ML) processing, training, and predictive computations remain strictly **off the production deployment path**. Only **precomputed analytical results** (forecasts, KPIs, timeseries insights) are published as datasets to be consumed by the deployed app.

**Reference:** [Global Constraints Document](../../diagnostics/clusters/GLOBAL_CONSTRAINTS_NO_ML_OPS_PT_BR.md)

**Strategic Rationale:**
- ‚úÖ **Self-hosted compute efficiency:** System runs entirely on commodity servers or local HPC resources‚Äîno need for Databricks, Vertex, or SageMaker orchestration
- ‚úÖ **Zero cloud dependency:** Infrastructure fully containerized (Docker/Compose), deployable on-premises or in private networks
- ‚úÖ **Performance optimization:** No model inference or feature pipelines on request path = predictable, low-latency responses (< 500ms cached, < 2s cold)
- ‚úÖ **Security & compliance:** Sensitive training data stays local. Production only exposes derived, sanitized analytics
- ‚úÖ **Cost reduction:** Zero ongoing cloud compute or storage costs post-deploy

**Implementation:**
- ‚ùå **NO ML dependencies** in deployment containers (PyTorch, TensorFlow, scikit-learn, MLflow)
- ‚ùå **NO live inference endpoints** or model serving
- ‚ùå **NO feature pipelines** or real-time ML processing
- ‚úÖ **ONLY precomputed results** stored as Parquet tables (gold layer)
- ‚úÖ **ONLY read operations** for analytical data consumption
- ‚úÖ **Deployment runs offline** (air-gapped or private network)

**ML Processing Environment (Separate):**
- ML processing runs in a separate environment (local/cloud)
- ML outputs Parquet files to shared storage (`/exports/ml_results/`)
- Deployment only needs read-access to that folder
- No ML dependencies in deployment containers

### 5.1 ML Processing (Separate Environment)

**NOTA:** ML processing √© realizado em ambiente separado, N√ÉO em deployment.

**Componentes (Separate ML Environment):**
1. **ML Training:** Prophet, ARIMA, LSTM models
2. **ML Output:** Precomputed forecasts saved as Parquet
3. **ML Metadata:** model_version, generated_at, source, dataset_id
4. **Storage:** Parquet files in `/exports/ml_results/`

**Deployment (Read-Only):**
- Backend reads precomputed Parquet files
- API endpoints return precomputed results
- Frontend displays precomputed insights
- "Last updated" timestamps from metadata

### 5.1.1 MLflow Expandido (Futuro - Refer√™ncia Original)

**Nota:** MLflow foi planejado para implementa√ß√£o de 16 semanas. Mantido para refer√™ncia futura (ML environment separado).

**Componentes:**

1. **Tracking:**
   - Experimentos, m√©tricas, par√¢metros
   - Artifacts (modelos, plots)
   - UI web

2. **Projects:**
   - C√≥digo versionado
   - Depend√™ncias
   - Execu√ß√£o reproduz√≠vel

3. **Models:**
   - Registry de modelos
   - Versionamento
   - Staging (dev/staging/prod)

4. **Model Serving:**
   - REST API
   - Batch inference
   - Real-time serving

**Exemplo:**
```python
import mlflow
import mlflow.prophet

with mlflow.start_run():
    # Log parameters
    mlflow.log_param("model_type", "prophet")
    mlflow.log_param("forecast_steps", 30)
    
    # Train model
    model = train_prophet_model(data)
    
    # Log metrics
    mape = evaluate_model(model, test_data)
    mlflow.log_metric("MAPE", mape)
    
    # Log model
    mlflow.prophet.log_model(model, "model")
    
    # Register to registry
    mlflow.register_model(
        "runs:/{run_id}/model",
        "NovaCorrenteForecast"
    )
```

### 5.2 Kubeflow

**Componentes:**
- Pipelines (orquestra√ß√£o ML)
- Katib (hyperparameter tuning)
- KFServing (model serving)
- Notebooks (Jupyter no K8s)

**Para Produ√ß√£o:**
- Kubernetes-native
- Escal√°vel
- Enterprise-grade

### 5.3 Versionamento de Modelos

**Estrat√©gia:**
```
Model Registry:
‚îú‚îÄ‚îÄ nova_corrente_forecast
‚îÇ   ‚îú‚îÄ‚îÄ v1 (Production)
‚îÇ   ‚îú‚îÄ‚îÄ v2 (Staging)
‚îÇ   ‚îî‚îÄ‚îÄ v3 (Development)
‚îÇ
‚îú‚îÄ‚îÄ nova_corrente_arima
‚îÇ   ‚îî‚îÄ‚îÄ v1 (Production)
‚îÇ
‚îî‚îÄ‚îÄ nova_corrente_ensemble
    ‚îî‚îÄ‚îÄ v1 (Production)
```

**Promo√ß√£o:**
- Dev ‚Üí Staging: CI/CD autom√°tico
- Staging ‚Üí Prod: Aprova√ß√£o manual
- Rollback: Um comando

### 5.4 Feature Stores

**Feast (Open Source):**
```python
# Define features
@feature_view(
    name="item_demand_features",
    entities=["item"],
    ttl=timedelta(days=90)
)
class ItemDemandFeatures:
    avg_daily_demand = Value(dtype=Float32)
    std_daily_demand = Value(dtype=Float32)
    lead_time = Value(dtype=Int32)
    created_at = Value(dtype=UnixTimestamp)
```

**Tecton (Managed):**
- Feature store gerenciado
- Transforma√ß√µes em tempo real
- Integra√ß√£o com MLflow

### 5.5 Model Serving

**Op√ß√µes:**

1. **MLflow Serving:**
   - REST API simples
   - Bom para batch
   - F√°cil deploy

2. **Seldon Core:**
   - Kubernetes-native
   - A/B testing
   - Canary deployments

3. **TorchServe:**
   - PyTorch otimizado
   - Batching autom√°tico
   - Performance

**Para Nova Corrente:**
- **Inicial:** MLflow Serving (simples)
- **Produ√ß√£o:** Seldon Core (K8s, A/B testing)

---

<a name="qualidade-observabilidade"></a>

## 6. ‚úÖ QUALIDADE E OBSERVABILIDADE

### 6.1 Great Expectations

**Expectations (Valida√ß√µes):**

```python
import great_expectations as ge

# Create expectation suite
suite = ge.dataset.SparkDFDataset(df)

# Expect columns to exist
suite.expect_column_to_exist("item_id")
suite.expect_column_to_exist("forecasted_demand")

# Expect values
suite.expect_column_values_to_be_between(
    "forecasted_demand",
    min_value=0,
    max_value=10000
)

# Expect uniqueness
suite.expect_column_values_to_be_unique("item_id")

# Save suite
suite.save_expectation_suite("forecasts_expectations.json")
```

**Data Docs (HTML):**
- Relat√≥rios autom√°ticos
- Valida√ß√£o visual
- Hist√≥rico de resultados

### 6.2 dbt Tests

**Built-in Tests:**
```yaml
models:
  - name: fact_forecasts
    columns:
      - name: item_id
        tests:
          - unique
          - not_null
          - relationships:
              to: ref('dim_items')
              field: item_id
```

**Custom Tests:**
```sql
-- tests/custom/assert_mape_threshold.sql
SELECT item_id, mape
FROM {{ ref('fact_forecasts') }}
WHERE mape > 20  -- Threshold: 20%
```

### 6.3 Data Profiling

**dbt Profiling:**
```bash
dbt run-operation generate_model_profiles
```

**Pandas Profiling:**
```python
import pandas_profiling

profile = df.profile_report()
profile.to_file("forecasts_profile.html")
```

### 6.4 Data Lineage

**dbt Lineage:**
```bash
dbt docs generate
dbt docs serve
```

**DataHub:**
- Lineage autom√°tico
- Catalog de dados
- Metadata management

### 6.5 Alerts

**Integra√ß√£o:**
- Slack notifications
- Email alerts
- PagerDuty (critical)
- Custom webhooks

**Exemplo:**
```python
# Alert on data quality failure
if not validation_result.success:
    send_slack_alert(
        channel="#data-alerts",
        message=f"Data quality failed: {validation_result.summary}"
    )
```

---

<a name="infraestrutura-codigo"></a>

## 7. üèóÔ∏è INFRAESTRUTURA COMO C√ìDIGO

### 7.1 Terraform

**Infraestrutura Cloud:**
```hcl
# terraform/aws/data_warehouse.tf
resource "aws_s3_bucket" "data_lake" {
  bucket = "nova-corrente-data-lake"
  
  versioning {
    enabled = true
  }
  
  lifecycle_rule {
    enabled = true
    expiration {
      days = 90
    }
  }
}

resource "aws_databricks_workspace" "main" {
  account_id     = var.databricks_account_id
  workspace_name = "nova-corrente-workspace"
  deployment_name = "nova-corrente"
  
  tags = {
    Environment = "production"
    Project     = "forecasting"
  }
}
```

### 7.2 Docker e Kubernetes

**Docker Compose (Desenvolvimento):**
```yaml
version: '3.8'
services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: nova_corrente
  
  airflow:
    image: apache/airflow:2.7.0
    depends_on:
      - postgres
  
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.7.0
    ports:
      - "5000:5000"
```

**Kubernetes (Produ√ß√£o):**
```yaml
# k8s/airflow-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-webserver
spec:
  replicas: 3
  selector:
    matchLabels:
      app: airflow-webserver
  template:
    metadata:
      labels:
        app: airflow-webserver
    spec:
      containers:
      - name: airflow
        image: apache/airflow:2.7.0
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
```

### 7.3 CI/CD

**GitHub Actions:**
```yaml
# .github/workflows/dbt.yml
name: dbt CI
on: [push]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run dbt tests
        run: |
          cd dbt
          dbt deps
          dbt run --models staging
          dbt test
```

**dbt Cloud:**
- CI/CD nativo
- Jobs agendados
- Slack/Email notifications

### 7.4 Environments

**Estrutura:**
```
environments/
‚îú‚îÄ‚îÄ dev/
‚îÇ   ‚îú‚îÄ‚îÄ terraform/
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îú‚îÄ‚îÄ staging/
‚îÇ   ‚îú‚îÄ‚îÄ terraform/
‚îÇ   ‚îú‚îÄ‚îÄ k8s/
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îî‚îÄ‚îÄ prod/
    ‚îú‚îÄ‚îÄ terraform/
    ‚îú‚îÄ‚îÄ k8s/
    ‚îî‚îÄ‚îÄ config/
```

---

<a name="analytics-bi"></a>

## 8. üìä ANALYTICS E BI

### 8.1 dbt + BI Tools

**dbt Semantic Layer:**
```yaml
# models/metrics.yml
version: 2

metrics:
  - name: forecast_accuracy
    label: "Forecast Accuracy"
    model: ref('fact_forecasts')
    calculation_method: average
    expression: |
      CASE 
        WHEN actual_demand > 0 
        THEN ABS(forecasted_demand - actual_demand) / actual_demand
        ELSE NULL
      END
    
  - name: total_forecasted_demand
    label: "Total Forecasted Demand"
    model: ref('fact_forecasts')
    calculation_method: sum
    expression: forecasted_demand
```

**Access via API:**
```python
from dbt_semantic_interfaces import SemanticManifest

manifest = SemanticManifest.load("metrics.yml")
metrics = manifest.list_metrics()
```

### 8.2 Metabase/Superset

**Metabase:**
- Self-service BI
- F√°cil de usar
- Query builder visual
- Embed analytics

**Superset:**
- Apache Superset (open source)
- Dashboard avan√ßados
- SQL Lab
- Alerts

**Para Nova Corrente:**
- **Metabase:** Usu√°rios de neg√≥cio (n√£o t√©cnicos)
- **Superset:** Analistas de dados (SQL)

### 8.3 Embed Analytics

**Metabase Embed:**
```javascript
<iframe
  src="https://metabase.novacorrente.com/embed/dashboard/123"
  frameBorder="0"
  width="800"
  height="600"
/>
```

### 8.4 Self-Service

**Capabilities:**
- Query builder (sem SQL)
- Saved queries
- Dashboards customizados
- Export Excel/PDF
- Scheduled reports

---

<a name="governanca-dados"></a>

## 9. üõ°Ô∏è GOVERNAN√áA DE DADOS

### 9.1 Cataloga√ß√£o (DataHub)

**Metadata:**
- Schemas, tables, columns
- Lineage (upstream/downstream)
- Ownership (data stewards)
- Tags (PII, sensitive)

**Integra√ß√£o:**
```python
from datahub.ingestion.api.common import RecordEnvelope

# Ingest metadata
from datahub.ingestion.graph.client import DatahubGraph

graph = DatahubGraph(ConfigDatahub())
graph.emit(metadata)
```

### 9.2 Lineage

**Automatic:**
- dbt lineage (SQL parsing)
- Airflow lineage (task dependencies)
- Spark lineage (Spark UI)

**Manual:**
- DataHub annotations
- Documentation links

### 9.3 Security e Compliance

**Row-Level Security:**
```sql
-- dbt macro
{% macro apply_rls(model_name) %}
  {% set user_email = var('user_email') %}
  
  {% if user_email %}
    ALTER TABLE {{ model_name }} 
    ENABLE ROW LEVEL SECURITY;
    
    CREATE POLICY user_policy ON {{ model_name }}
      FOR SELECT
      USING (owner_email = '{{ user_email }}');
  {% endif %}
{% endmacro %}
```

**Data Masking:**
```sql
-- PII columns masked
SELECT
    item_id,
    mask_pii(item_name) AS item_name,  -- Custom function
    cost
FROM dim_items
```

### 9.4 Documenta√ß√£o

**dbt Docs:**
- Auto-gerada de YAML
- Descriptions, tests, examples
- Acess√≠vel via web

**DataHub:**
- Rich text documentation
- Links, images
- Ownership, tags

---

<a name="roadmap-implementacao"></a>

## 10. üóìÔ∏è ROADMAP DE IMPLEMENTA√á√ÉO - 4-DAY SPRINT

### üìÖ Sprint Overview (4 Days: D0-D4)

**Goal:** Deploy a minimal, functional analytics dashboard with time series data, forecast insights, and supply chain inventory management in **4 days**.

**Key Constraint:** No heavy ML processing in production. ML runs locally, results exported to analytics layer. Focus on BI dashboard and supply chain management.

**Reference:** [4-Day Sprint Overview](../../diagnostics/clusters/00_OVERVIEW_INDEX_4DAY_SPRINT_PT_BR.md)

### D0: Freeze & Planning (4-6 hours)

**All Clusters:**
- [ ] **Data:** Freeze inputs & sample data
- [ ] **Backend:** Freeze endpoints & contract (OpenAPI spec)
- [ ] **Frontend:** Freeze UX & component list (mockups)
- [ ] **Deploy:** Prepare Dockerfiles & compose

**Checkpoint:** All teams aligned, contracts defined, ready to build

### D1: Storage + Data Access (6-8 hours)

**Parallel Work:**
- [ ] **Data:** Storage + Ingestion (MinIO, extractors)
- [ ] **Backend:** Data Access & Queries (DuckDB layer)
- [ ] **Frontend:** Project Scaffold + Components (React + Vite)
- [ ] **Deploy:** Infra & Secrets (local deployment)

**Checkpoint:** Data flowing into storage, backend can query, frontend scaffolded

### D2: API + Frontend Minimal (6-8 hours)

**Parallel Work:**
- [ ] **Data:** Lightweight Transformations (silver layer)
- [ ] **Backend:** API Endpoints & BFF Logic (FastAPI routes)
- [ ] **Frontend:** Charts + Interactions (Recharts, date picker)
- [ ] **Deploy:** CI Pipeline + Automated Builds (GitHub Actions)

**Checkpoint:** API endpoints working, frontend charts rendering, CI pipeline running

### D3: Integration (6-8 hours)

**Parallel Work:**
- [ ] **Data:** Gold Models (Star Schema: dim_item, dim_time, fact_forecast)
- [ ] **Backend:** Auth, Tests & Integration (JWT/API key, pytest)
- [ ] **Frontend:** Responsiveness & Polish (loading states, error handling)
- [ ] **Deploy:** Smoke Tests + Domain (E2E tests, Cloudflare Tunnel/ngrok)

**Checkpoint:** End-to-end integration working, tests passing, ready for deployment

### D4: Deploy & Demo (4-6 hours)

**Final Work:**
- [ ] **Data:** Test & Deliver (end-to-end pipeline, documentation)
- [ ] **Backend:** Finalize Docs & Deploy Readiness (documentation, health check)
- [ ] **Frontend:** Bundle & Integration Test (production build)
- [ ] **Deploy:** Handover & Rollback Plan (documentation, runbook)

**Checkpoint:** All services deployed, stakeholder demo ready, documentation complete

### ‚úÖ Core Acceptance Criteria (All Clusters)

**End-to-End Path:**
- [ ] ‚úÖ Data ingestion ‚Üí bronze ‚Üí silver ‚Üí gold ‚Üí Parquet queries validated
- [ ] ‚úÖ Backend API endpoints return expected JSON
- [ ] ‚úÖ Frontend dashboard renders with correct data
- [ ] ‚úÖ All services deployed and accessible

**Performance Requirements:**
- [ ] ‚úÖ Data queries: < 2s for 30-day time series
- [ ] ‚úÖ API endpoints: < 500ms cached, < 2s cold
- [ ] ‚úÖ Frontend load: < 2.5s on reasonable dev VM
- [ ] ‚úÖ Services start: < 2 minutes

**ML Ops Validation (MANDATORY):**
- [ ] ‚úÖ No ML dependencies in deployment containers (check all Dockerfiles)
- [ ] ‚úÖ Only precomputed ML results ingested (no ML processing)
- [ ] ‚úÖ ML results include metadata (`model_version`, `generated_at`, `source`, `dataset_id`)
- [ ] ‚úÖ Deployment can run offline (no ML API calls)
- [ ] ‚úÖ Image sizes < 600 MB per container
- [ ] ‚úÖ CPU-only deployment (no GPU required)
- [ ] ‚úÖ Zero cloud compute costs (fully self-hosted)

### 10.1 Roadmap Expandido (Futuro - Refer√™ncia Original)

**Nota:** O roadmap original de 16 semanas foi planejado para implementa√ß√£o completa. Mantido para refer√™ncia futura.

### Fase 0: Foundation (Semanas 1-2) - Original

**Objetivos:**
- Setup infraestrutura b√°sica
- Configurar dbt project
- Criar pipelines Bronze/Silver

**Entregas:**
- [ ] Terraform para AWS/GCP
- [ ] S3/Cloud Storage (Bronze layer)
- [ ] dbt project structure
- [ ] Airflow DAG b√°sico
- [ ] Documenta√ß√£o inicial

### Fase 1: Data Foundation (Semanas 3-4) - Original

**Objetivos:**
- Implementar Silver layer
- Criar modelos dbt staging
- Setup Data Quality (Great Expectations)

**Entregas:**
- [ ] Staging models (stg_items, stg_towers, stg_forecasts)
- [ ] Data quality tests
- [ ] Great Expectations suite
- [ ] Data profiling reports

### Fase 2: Analytics Layer (Semanas 5-8) - Original

**Objetivos:**
- Implementar Gold layer (star schema)
- Criar m√©tricas de neg√≥cio
- Setup BI tools

**Entregas:**
- [ ] Dimension models (dim_items, dim_towers, dim_time)
- [ ] Fact models (fact_forecasts, fact_inventory)
- [ ] dbt metrics (MAPE, forecast accuracy)
- [ ] Metabase/Superset configurado
- [ ] Dashboards b√°sicos

### Fase 3: ML Ops (Semanas 9-12) - Original

**Objetivos:**
- Setup MLflow
- Feature store
- Model serving

**Entregas:**
- [ ] MLflow tracking
- [ ] Model registry
- [ ] Feature store (Feast ou Tecton)
- [ ] Model serving (MLflow ou Seldon)
- [ ] A/B testing setup

### Fase 4: Advanced Features (Semanas 13-16) - Original

**Objetivos:**
- Governan√ßa completa
- Streaming pipeline
- Otimiza√ß√µes

**Entregas:**
- [ ] DataHub catalog
- [ ] Streaming pipeline (Kafka + Flink)
- [ ] Performance optimization
- [ ] Advanced dashboards
- [ ] Self-service analytics

---

<a name="tecnologias-ferramentas"></a>

## 11. üõ†Ô∏è TECNOLOGIAS E FERRAMENTAS

### 11.1 Stack Simplificado (4-Day Sprint)

**Camada de Armazenamento:**
- ‚úÖ **MinIO:** S3-compatible storage (local/Docker)
- ‚úÖ **Format:** Parquet (lightweight, columnar)
- ‚úÖ **No Delta Lake:** Removido para simplifica√ß√£o

**Camada de Compute:**
- ‚úÖ **DuckDB:** In-process SQL engine sobre Parquet
- ‚úÖ **Pandas:** Python data processing
- ‚úÖ **No Spark/Databricks:** Removido para simplifica√ß√£o

**Camada de Transforma√ß√£o:**
- ‚úÖ **Python Scripts:** ETL transformations
- ‚úÖ **SQL (DuckDB):** Queries SQL diretas
- ‚úÖ **No dbt:** Removido para simplifica√ß√£o

**Camada de Orquestra√ß√£o:**
- ‚úÖ **Simple Scheduler:** Python scripts com schedule
- ‚úÖ **Docker Compose:** Service orchestration
- ‚úÖ **No Airflow/Prefect:** Removido para simplifica√ß√£o

**Camada de ML:**
- ‚úÖ **Separate ML Environment:** ML processing separado
- ‚úÖ **Precomputed Results:** Parquet files com metadata
- ‚úÖ **NO ML in Deployment:** Constraint obrigat√≥rio
- ‚úÖ **No MLflow/Feature Store:** Removido de deployment

**Camada de BI:**
- ‚úÖ **FastAPI:** REST API backend
- ‚úÖ **React:** Frontend dashboard
- ‚úÖ **Recharts:** Data visualization
- ‚úÖ **No Metabase/Superset:** Removido para simplifica√ß√£o

**Camada de Deployment:**
- ‚úÖ **Docker Compose:** Local deployment
- ‚úÖ **Redis:** Optional caching
- ‚úÖ **No K8s:** Removido para simplifica√ß√£o

### 11.1.1 Stack Expandido (Futuro - Refer√™ncia Original)

**Nota:** O stack original foi planejado para 16 semanas. Mantido para refer√™ncia futura.

**Camada de Armazenamento (Original):**
- **Cloud:** AWS S3 / GCP Cloud Storage
- **Format:** Delta Lake
- **Compute:** Databricks / Spark on K8s

**Camada de Transforma√ß√£o (Original):**
- **dbt:** Transforma√ß√µes SQL
- **Python:** UDFs complexas
- **Airflow:** Orquestra√ß√£o

**Camada de ML (Original):**
- **MLflow:** Experiment tracking + Registry
- **Feast:** Feature store
- **Seldon Core:** Model serving

**Camada de BI (Original):**
- **Metabase:** Self-service BI
- **Superset:** Advanced dashboards
- **dbt Semantic Layer:** Metrics API

**Camada de Governan√ßa (Original):**
- **DataHub:** Catalog
- **Great Expectations:** Data quality
- **dbt Tests:** Validation

### 11.2 Alternativas

**Cloud Providers:**
- **AWS:** S3, Glue, Redshift, SageMaker
- **GCP:** Cloud Storage, BigQuery, Vertex AI
- **Azure:** ADLS, Synapse, Azure ML

**Compute:**
- **Databricks:** Managed Spark
- **Snowflake:** Data warehouse
- **BigQuery:** Serverless warehouse

**Orquestra√ß√£o:**
- **Airflow:** Padr√£o da ind√∫stria
- **Prefect:** Modern Python-first
- **Dagster:** Data-aware orchestration

### 11.3 Custos Estimados (Mensal)

**AWS Stack:**
```
S3 Storage (10TB):        $230
Databricks (Medium):      $1,500
Airflow (Managed):        $200
MLflow (Self-hosted):    $100
Metabase Cloud:           $85
DataHub (Self-hosted):   $150
---------------------------------
Total: ~$2,265/m√™s
```

**Open Source Stack (Self-hosted):**
```
Compute (K8s):           $500
Storage (S3):            $230
Monitoring:              $50
---------------------------------
Total: ~$780/m√™s
```

### 11.4 TCO (Total Cost of Ownership)

**Ano 1:**
- Infraestrutura: $27,000
- Ferramentas: $14,400
- Desenvolvimento: $120,000 (1 FTE)
- **Total: $161,400**

**Ano 2+ (Otimizado):**
- Infraestrutura: $15,000
- Ferramentas: $10,000
- Manuten√ß√£o: $60,000 (0.5 FTE)
- **Total: $85,000/ano**

---

<a name="metricas-sucesso"></a>

## 12. üìà M√âTRICAS DE SUCESSO

### 12.1 KPIs T√©cnicos

**Data Quality:**
- Test pass rate: >95%
- Data freshness: <1 hora
- Schema changes: <5%/m√™s

**Pipeline Performance:**
- Bronze ingestion: <30 min/dia
- Silver processing: <1 hora/dia
- Gold transformations: <30 min/dia
- **Total pipeline: <2 horas/dia**

**Model Performance:**
- MAPE: <15% (target)
- Inference latency: <100ms
- Model retraining: Semanal

### 12.2 KPIs de Neg√≥cio

**Previsibilidade:**
- Rupturas reduzidas: -60%
- Estoque otimizado: -20%
- Lead time accuracy: >85%

**Ado√ß√£o:**
- Usu√°rios ativos: 20+ usu√°rios
- Dashboards utilizados: 10+ dashboards
- Queries self-service: 100+/dia

**ROI:**
- Payback: 6-12 meses
- ROI Ano 1: 80-180%
- Economia estoque: R$ 500K+/ano

### 12.3 Dashboards de Monitoramento

**Operational Dashboard:**
- Pipeline status (Airflow)
- Data quality scores (Great Expectations)
- Model performance (MLflow)
- System health (Grafana)

**Business Dashboard:**
- Forecast accuracy (MAPE por item)
- Inventory levels vs Reorder Points
- Alert trends
- ROI metrics

---

## üéØ CONCLUS√ÉO

Este roadmap foi atualizado para o **4-Day Sprint** com escopo reduzido e foco em MVP funcional:

‚úÖ **Arquitetura Parquet Layers** (Bronze/Silver/Gold)  
‚úÖ **Python Scripts + DuckDB** para transforma√ß√µes  
‚úÖ **NO ML OPS IN DEPLOYMENT** (ML processing separado)  
‚úÖ **FastAPI + React** para analytics  
‚úÖ **Docker Compose** para deployment self-hosted  
‚úÖ **Roadmap de 4 dias** (sprint intensivo)

### üìã Escopo Atual (4-Day Sprint)

**Timeline:** 4 dias (D0-D4)  
**Stack:** Parquet + MinIO + DuckDB + Pandas + FastAPI + React  
**ML Strategy:** NO ML in deployment, apenas resultados pr√©-computados  
**Deployment:** Docker Compose (self-hosted, offline deployable)

### üìö Escopo Expandido (Futuro)

O roadmap original de 16 semanas com stack completo (Delta Lake, Spark, dbt, Airflow, MLflow) foi mantido para refer√™ncia futura nas se√ß√µes marcadas como "Futuro - Refer√™ncia Original".

**Pr√≥ximos Passos (4-Day Sprint):**
1. Revisar cluster documents (Data, Backend, Frontend, Deploy)
2. Alinhar equipes (4 clusters, 1-2 engenheiros cada)
3. Iniciar D0 (Freeze & Planning)
4. Executar sprint D0-D4

**Pr√≥ximos Passos (Futuro - Escopo Expandido):**
1. Revisar roadmap expandido com stakeholders
2. Priorizar fases (start with Fase 0)
3. Alocar recursos (1-2 engenheiros)
4. Iniciar implementa√ß√£o de 16 semanas

---

**Documento criado:** Novembro 2025  
**Vers√£o:** 2.0 (Atualizado para 4-Day Sprint)  
**√öltima Atualiza√ß√£o:** Novembro 2025  
**Autor:** Equipe Grand Prix SENAI  
**Status:** ‚úÖ Roadmap Atualizado - Escopo Reduzido para 4-Day Sprint

**Refer√™ncias:**
- [4-Day Sprint Overview](../../diagnostics/clusters/00_OVERVIEW_INDEX_4DAY_SPRINT_PT_BR.md)
- [Global Constraints](../../diagnostics/clusters/GLOBAL_CONSTRAINTS_NO_ML_OPS_PT_BR.md)

**CENTRALIZED REPORTS & CHANGELOG SYSTEM COMPLETE!**

