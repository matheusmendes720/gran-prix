# üßÆ F√ìRMULAS AVAN√áADAS ML/DL - GUIA COMPLETO
## Do B√°sico ao Avan√ßado para Previsibilidade de Demandas

**Vers√£o:** 1.0  
**Data:** Novembro 2025  
**N√≠vel:** Iniciante ‚Üí Intermedi√°rio ‚Üí Avan√ßado ‚Üí Produ√ß√£o

---

## üìã √çNDICE

1. [Fundamentos Matem√°ticos](#fundamentos)
2. [Time Series Forecasting (Iniciante)](#iniciante)
3. [Ensemble Methods (Intermedi√°rio)](#intermediario)
4. [Deep Learning (Avan√ßado)](#avancado)
5. [Pipeline Produ√ß√£o (Implementa√ß√£o)](#producao)

---

<a name="fundamentos"></a>
## 1. üìê FUNDAMENTOS MATEM√ÅTICOS

### 1.1 Nota√ß√£o e Conceitos Base

**Nota√ß√£o:**
- $t$: Tempo (discreto, dias)
- $y_t$: Demanda observada no tempo $t$
- $\hat{y}_t$: Previs√£o da demanda no tempo $t$
- $\epsilon_t$: Erro no tempo $t$ (ru√≠do)
- $\sigma$: Desvio padr√£o
- $\mu$: M√©dia

**Operadores:**
- $B$: Backshift operator ($B y_t = y_{t-1}$)
- $\nabla$: Operador de diferen√ßa ($\nabla y_t = y_t - y_{t-1}$)
- $\Delta$: Primeira diferen√ßa ($\Delta y_t = (1-B)y_t$)

### 1.2 M√©tricas de Erro

**MAPE (Mean Absolute Percentage Error):**
$$\text{MAPE} = \frac{100}{n} \sum_{t=1}^{n} \left|\frac{y_t - \hat{y}_t}{y_t}\right|$$

**RMSE (Root Mean Squared Error):**
$$\text{RMSE} = \sqrt{\frac{1}{n} \sum_{t=1}^{n}(y_t - \hat{y}_t)^2}$$

**MAE (Mean Absolute Error):**
$$\text{MAE} = \frac{1}{n} \sum_{t=1}^{n}|y_t - \hat{y}_t|$$

**MASE (Mean Absolute Scaled Error):**
$$\text{MASE} = \frac{\text{MAE}}{\frac{1}{n-1}\sum_{t=2}^{n}|y_t - y_{t-1}|}$$

### 1.3 Estat√≠stica Descritiva

**Mean (M√©dia):**
$$\bar{y} = \frac{1}{n} \sum_{t=1}^{n} y_t$$

**Variance (Vari√¢ncia):**
$$\sigma^2 = \frac{1}{n-1} \sum_{t=1}^{n}(y_t - \bar{y})^2$$

**Autocovariance (Autocovari√¢ncia):**
$$\gamma_k = \text{Cov}(y_t, y_{t-k}) = E[(y_t - \mu)(y_{t-k} - \mu)]$$

**Autocorrelation (Autocorrela√ß√£o):**
$$\rho_k = \frac{\gamma_k}{\gamma_0}$$

---

<a name="iniciante"></a>
## 2. üìä TIME SERIES FORECASTING (INICIANTE)

### 2.1 Random Walk (Baseline)

**Formula√ß√£o:**
$$y_t = y_{t-1} + \epsilon_t$$

**Previs√£o:**
$$\hat{y}_{t+1} = y_t$$

**Interpreta√ß√£o:** Previs√£o √© igual ao √∫ltimo valor observado.

**Uso:** Baseline simples para compara√ß√£o.

### 2.2 Simple Moving Average (SMA)

**Formula√ß√£o:**
$$\hat{y}_{t+1} = \frac{1}{m} \sum_{i=0}^{m-1} y_{t-i}$$

Onde $m$ √© a janela de m√©dia.

**Exemplo:** $m=7$ (m√©dia semanal)
$$\hat{y}_{t+1} = \frac{y_t + y_{t-1} + \cdots + y_{t-6}}{7}$$

**Vantagem:** R√°pido, interpret√°vel.  
**Desvantagem:** N√£o captura tend√™ncias.

### 2.3 Exponential Smoothing (Holt-Winters)

**Simple Exponential Smoothing:**
$$\hat{y}_{t+1} = \alpha y_t + (1-\alpha)\hat{y}_t$$

**Holt's Linear Method (Tend√™ncia):**
$$y_t = l_{t-1} + b_{t-1}$$
$$l_t = \alpha y_t + (1-\alpha)(l_{t-1} + b_{t-1})$$
$$b_t = \beta(l_t - l_{t-1}) + (1-\beta)b_{t-1}$$

**Holt-Winters (Tend√™ncia + Sazonalidade):**
$$y_t = (l_{t-1} + b_{t-1}) \cdot s_{t-m}$$
$$l_t = \alpha \frac{y_t}{s_{t-m}} + (1-\alpha)(l_{t-1} + b_{t-1})$$
$$b_t = \beta(l_t - l_{t-1}) + (1-\beta)b_{t-1}$$
$$s_t = \gamma \frac{y_t}{l_t} + (1-\gamma)s_{t-m}$$

**Par√¢metros:**
- $\alpha$: N√≠vel (0 < Œ± < 1)
- $\beta$: Tend√™ncia (0 < Œ≤ < 1)
- $\gamma$: Sazonalidade (0 < Œ≥ < 1)
- $m$: Per√≠odo sazonal (7 semanal, 12 mensal)

---

### 2.4 ARIMA (AutoRegressive Integrated Moving Average)

**Formula√ß√£o Geral ARIMA(p,d,q):**
$$\phi_p(B)(1-B)^d y_t = \theta_q(B) \epsilon_t$$

Onde:
- $p$: ordem AR (autoregressivo)
- $d$: ordem integra√ß√£o (diferencia√ß√£o)
- $q$: ordem MA (m√©dia m√≥vel)

**AR(1) - First Order Autoregressive:**
$$y_t = c + \phi_1 y_{t-1} + \epsilon_t$$

**MA(1) - First Order Moving Average:**
$$y_t = c + \epsilon_t + \theta_1 \epsilon_{t-1}$$

**ARMA(1,1) - Combined:**
$$y_t = c + \phi_1 y_{t-1} + \epsilon_t + \theta_1 \epsilon_{t-1}$$

**Estacionariedade:** Requer que as ra√≠zes de $\phi_p(B) = 0$ estejam fora do c√≠rculo unit√°rio.

### 2.5 SARIMA (Sazonal ARIMA)

**Formula√ß√£o SARIMA(p,d,q)(P,D,Q)[s]:**
$$\Phi_P(B^s) \phi_p(B)(1-B^s)^D(1-B)^d y_t = \Theta_Q(B^s)\theta_q(B)\epsilon_t$$

**Exemplo SARIMA(1,1,1)(1,1,1)[7]:**
$$(1 - \phi_1 B)(1 - \Phi_1 B^7)(1-B)(1-B^7)y_t = (1 + \theta_1 B)(1 + \Theta_1 B^7)\epsilon_t$$

**Par√¢metros:**
- $(p,d,q)$: Componente n√£o-sazonal
- $(P,D,Q)$: Componente sazonal
- $s$: Per√≠odo sazonal (7=di√°rio, 12=mensal)

**Para Nova Corrente:** SARIMA recomendado para capturar sazonalidade semanal.

---

<a name="intermediario"></a>
## 3. üéØ ENSEMBLE METHODS (INTERMEDI√ÅRIO)

### 3.1 Prophet (Meta Forecasting)

**Modelo Aditivo:**
$$y_t = g(t) + s(t) + h(t) + \epsilon_t$$

**Componentes:**

**Trend (Tend√™ncia):**
$$g(t) = \beta_0 + \beta_1 t + \sum_{k=1}^{K} \gamma_k s_k(t)$$

**Sazonalidade:**
$$s(t) = \sum_{k=1}^{K} \left[ a_k \cos\left(\frac{2\pi kt}{P}\right) + b_k \sin\left(\frac{2\pi kt}{P}\right) \right]$$

**Feriados:**
$$h(t) = \sum_{i=1}^{H} \beta_{h,i} \mathbb{1}(t \in H_i)$$

**Regressores Ex√≥genos:**
$$y_t = g(t) + s(t) + h(t) + \sum_{j=1}^{J} \beta_j x_{j,t} + \epsilon_t$$

**Vantagens:**
- M√∫ltiplas sazonalidades autom√°ticas
- Tolerante a missing data
- Interpret√°vel
- Feriados customiz√°veis

### 3.2 Ensemble Weighted Average

**F√≥rmula:**
$$\hat{y}_{\text{ensemble}} = \sum_{i=1}^{M} w_i \hat{y}_i$$

**Restri√ß√£o:** $\sum_{i=1}^{M} w_i = 1$

**Pesos por Performance:**
$$w_i = \frac{1/\text{MAPE}_i}{\sum_{j=1}^{M} 1/\text{MAPE}_j}$$

**Exemplo:** ARIMA(30%) + Prophet(30%) + LSTM(40%)
$$\hat{y}_{\text{final}} = 0.3 \cdot \hat{y}_{\text{ARIMA}} + 0.3 \cdot \hat{y}_{\text{Prophet}} + 0.4 \cdot \hat{y}_{\text{LSTM}}$$

### 3.3 Stacking Ensemble

**F√≥rmula:**
$$\hat{y}_{\text{stacked}} = f_{\text{meta}}(\hat{y}_1, \hat{y}_2, \ldots, \hat{y}_M)$$

Onde $f_{\text{meta}}$ √© um modelo meta-aprendiz (ex: regress√£o linear).

**Implementa√ß√£o:**
```
Camada 1 (Base):
- Modelo 1: ARIMA
- Modelo 2: Prophet
- Modelo 3: XGBoost

Camada 2 (Meta):
- Input: Previs√µes Camada 1
- Output: Previs√£o final
- Algoritmo: Linear Regression ou MLP
```

---

<a name="avancado"></a>
## 4. üß† DEEP LEARNING (AVAN√áADO)

### 4.1 LSTM (Long Short-Term Memory)

**C√©lula LSTM:**

**Forget Gate:**
$$f_t = \sigma(W_f \cdot [h_{t-1}, x_t] + b_f)$$

**Input Gate:**
$$i_t = \sigma(W_i \cdot [h_{t-1}, x_t] + b_i)$$
$$\tilde{C}_t = \tanh(W_C \cdot [h_{t-1}, x_t] + b_C)$$

**Cell State:**
$$C_t = f_t * C_{t-1} + i_t * \tilde{C}_t$$

**Output Gate:**
$$o_t = \sigma(W_o \cdot [h_{t-1}, x_t] + b_o)$$
$$h_t = o_t * \tanh(C_t)$$

**Onde:**
- $\sigma$: Sigmoid function
- $*$: Element-wise multiplication
- $W$: Weight matrices
- $b$: Bias vectors

### 4.2 GRU (Gated Recurrent Unit) - Simplifica√ß√£o LSTM

**Reset Gate:**
$$r_t = \sigma(W_r \cdot [h_{t-1}, x_t])$$

**Update Gate:**
$$z_t = \sigma(W_z \cdot [h_{t-1}, x_t])$$

**Hidden State:**
$$\tilde{h}_t = \tanh(W \cdot [r_t * h_{t-1}, x_t])$$
$$h_t = (1 - z_t) * h_{t-1} + z_t * \tilde{h}_t$$

**Vantagem:** Menos par√¢metros que LSTM, similar performance.

### 4.3 Attention Mechanism

**Self-Attention:**
$$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$$

**Multi-Head Attention:**
$$\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, \ldots, \text{head}_h)W^O$$

Onde cada head:
$$\text{head}_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)$$

**Aplica√ß√£o:** Previs√£o longa depend√™ncia temporal.

### 4.4 CNN-LSTM Hybrid

**Formula√ß√£o:**
1. **CNN:** Extrair features locais de janela temporal
2. **LSTM:** Capturar depend√™ncias longas
3. **Dense:** Output final

**Arquitetura:**
$$h_{\text{cnn}} = \text{CNN}(x_{t-k:t})$$
$$h_{\text{lstm}} = \text{LSTM}(h_{\text{cnn}})$$
$$\hat{y}_t = \text{Dense}(h_{\text{lstm}})$$

---

<a name="producao"></a>
## 5. üöÄ PIPELINE PRODU√á√ÉO (IMPLEMENTA√á√ÉO)

### 5.1 Reorder Point (PP) Calculation

**F√≥rmula Base:**
$$\text{PP} = D \times L + SS$$

Onde:
- $D$: Demanda di√°ria m√©dia (da IA)
- $L$: Lead time (dias)
- $SS$: Safety Stock

**Safety Stock Estat√≠stico:**
$$SS = Z_{\alpha} \times \sigma_D \times \sqrt{L}$$

**Ajuste Risk Factor:**
$$SS = Z_{\alpha} \times \sigma_D \times \sqrt{L} \times RF$$

**Exemplo:** $Z_{0.95} = 1.65$, $\sigma_D = 2.5$, $L = 14$, $RF = 1.3$
$$SS = 1.65 \times 2.5 \times \sqrt{14} \times 1.3 = 18.8 \approx 19$$

### 5.2 Economic Order Quantity (EOQ)

**F√≥rmula Base:**
$$\text{EOQ} = \sqrt{\frac{2DS}{H}}$$

Onde:
- $D$: Demanda anual
- $S$: Custo do pedido (setup cost)
- $H$: Custo de manuten√ß√£o de estoque por unidade/ano

**Com Lead Time:**
$$\text{EOQ} = \sqrt{\frac{2DS + L \times D^2}{H}}$$

### 5.3 Optimized Lead Time

**F√≥rmula:**
$$L_{\text{opt}} = \bar{L} + Z_{\alpha} \times \sigma_L$$

**Confidence Interval:**
$$L_{\text{adjusted}} = L_{\text{base}} \times (1 + \text{Risk Factor})$$

**Risk Factor Calculation:**
$$\text{RF} = f(\text{Clima}, \text{Econ√¥mico}, \text{Operacional})$$

---

## üìê F√ìRMULAS ESPEC√çFICAS NOVA CORRENTE

### Reorder Point Completo com Fatores Externos

**Demanda Ajustada:**
$$D_{\text{adj}}(t) = \hat{D}(t) \times \prod_{i=1}^{n} M_i(t)$$

Onde $M_i(t)$ s√£o multiplicadores de fatores externos:
- $M_{\text{clima}}(t)$: Multiplicador clima
- $M_{\text{econ}}(t)$: Multiplicador econ√¥mico
- $M_{\text{tech}}(t)$: Multiplicador tecnol√≥gico
- $M_{\text{op}}(t)$: Multiplicador operacional

**Reorder Point Final:**
$$\text{PP}(t) = D_{\text{adj}}(t) \times L_{\text{opt}} + SS(t)$$

### Intervalos de Confian√ßa

**95% Confidence Interval:**
$$\hat{y}_t \pm 1.96 \times \sigma_{\text{forecast}}$$

**Prediction Interval:**
$$\hat{y}_t \pm t_{\alpha/2, n-2} \times s_e \times \sqrt{1 + \frac{1}{n} + \frac{(x_t - \bar{x})^2}{\sum(x_i - \bar{x})^2}}$$

---

## üéØ RESUMO FORMULA√á√ïES POR N√çVEL

**Iniciante:** SMA, Exponential Smoothing, ARIMA b√°sico  
**Intermedi√°rio:** SARIMA, Prophet, Ensemble averaging  
**Avan√ßado:** LSTM, GRU, Attention, CNN-LSTM  
**Produ√ß√£o:** PP calculation, EOQ, Confian√ßa intervals

---

**Documento Final:** Novembro 2025  
**Vers√£o:** 1.0  
**Status:** ‚úÖ Refer√™ncia Matem√°tica Completa

**CENTRALIZED REPORTS & CHANGELOG SYSTEM COMPLETE!**


