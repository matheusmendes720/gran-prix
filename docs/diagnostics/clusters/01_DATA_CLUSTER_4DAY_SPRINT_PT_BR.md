****# üìä DATA CLUSTER - 4-DAY SPRINT PLAN
## Nova Corrente - Analytics Data Foundation

**Vers√£o:** 1.0  
**Data:** Novembro 2025  
**Status:** üöÄ Execution-Ready  
**Sprint:** 4 Days (D0-D4)  
**Cluster Lead:** Data Engineer  
**Team Size:** 1-2 Engineers

---

## üìã QUICK ORIENTATION

**Goal:** Create a reproducible, queryable analytics store (time series focused) that supports the dashboard and API reads with simple schema and ingestion ‚Äî **deploy in 4 days**.

**Key Constraint:** No heavy cloud/Databricks/ML production runs this sprint. Use local or lightweight managed infra (MinIO or S3 if account exists). Keep formats Parquet. Use Delta only as optional upgrade if trivial to add.

**Reference Documents:**
- [Diagn√≥stico Completo](../COMPREHENSIVE_DATA_ENGINEERING_DIAGNOSTIC_PT_BR.md) - Gap analysis completo
- [Lista de Tarefas Cr√≠ticas](../CRITICAL_TASKS_PRIORITY_LIST_PT_BR.md) - TASK 1.1-1.4, 2.1-2.3
- [Global Constraints](./GLOBAL_CONSTRAINTS_NO_ML_OPS_PT_BR.md) - Complete policy document

---

## üîí GLOBAL STRATEGIC CONSTRAINT ‚Äî "NO ML OPS LOGIC IN DEPLOYMENT"

**Reference:** [Global Constraints Document](./GLOBAL_CONSTRAINTS_NO_ML_OPS_PT_BR.md)

**Policy:** All Machine Learning (ML) processing, training, and predictive computations remain strictly **off the production deployment path**. Only **precomputed analytical results** are ingested as static Parquet files.

**Data Cluster Specific Rules:**
- ‚úÖ Only ingest and transform **pre-aggregated or model-output data**, not raw training features
- ‚úÖ Store ML results (predictions, forecasts, metrics) as static Parquet tables (`gold` layer)
- ‚úÖ Label each ML-generated file with version metadata: `model_version`, `generated_at`, `source`, `dataset_id`
- ‚ùå **NO feature engineering** in ingestion scripts
- ‚ùå **NO ML processing** in transformation scripts
- ‚ùå **NO ML dependencies** in deployment containers

**Validation:**
- [ ] Check ingestion scripts have NO ML dependencies
- [ ] Check transformation scripts have NO ML processing
- [ ] Verify all ML results include required metadata columns
- [ ] Verify schema registry documents ML result metadata

---

## üéØ KEY CONSTRAINTS & ASSUMPTIONS

### Technical Constraints
- ‚úÖ **Storage:** MinIO (Docker) or S3 (if AWS account exists)
- ‚úÖ **Format:** Parquet (snappy compression)
- ‚úÖ **Schema:** Minimal star schema (only columns needed by dashboards)
- ‚úÖ **Processing:** Lightweight (Pandas/Spark job, no full dbt)
- ‚ùå **Deferred:** Delta Lake, full dbt, Databricks, Great Expectations
- ‚ùå **NO ML dependencies:** No PyTorch, TensorFlow, scikit-learn, MLflow

### Business Constraints
- **Data Sources:** Existing CSVs + External APIs (time series only)
- **ML Processing:** Local only, results exported to `gold` as facts
- **Analytics Focus:** Forecast accuracy, inventory levels, demand trends
- **Scale:** Small-medium datasets (< 10GB total)

### Scope Reduction Triggers
- If external APIs unavailable ‚Üí Use existing CSVs only
- If MinIO provisioning fails ‚Üí Use PostgreSQL for small datasets
- If Parquet processing stalls ‚Üí Use CSV + PostgreSQL (worse scale, faster setup)

---

## üìÖ DELIVERABLES (DAY-BY-DAY)

### **D0 (TODAY): Freeze Inputs & Sample Data** ‚è±Ô∏è 2-4 hours
**Owner:** Data Lead  
**Deliverables:**
- [ ] Freeze list of external APIs and CSVs to use
- [ ] Sample extract for each source (max 1-2 days history for speed)
- [ ] Export sample CSVs to `data/raw/`
- [ ] Document schema for each source
- [ ] Create `data/schema_registry.json` with column definitions
- [ ] **Verify NO ML dependencies** in sample data extraction scripts

**Acceptance Criteria:**
- ‚úÖ All sample files in `data/raw/` with documented schema
- ‚úÖ Schema registry JSON validates
- ‚úÖ NO ML dependencies in extraction scripts

**Output Files:**
- `data/raw/samples/` - Sample data files
- `data/schema_registry.json` - Schema definitions

---

### **D1: Storage + Ingestion** ‚è±Ô∏è 6-8 hours
**Owner:** 1-2 Data Engineers  
**Deliverables:**

#### Storage Setup
- [ ] Provision MinIO (docker-compose) or configure S3 buckets
- [ ] Create buckets: `nova-bronze` (raw), `nova-silver` (cleaned), `nova-gold` (analytics)
- [ ] Test upload/download via Python client
- [ ] Configure IAM roles/policies (if S3)

#### Ingestion Scripts
- [ ] Implement extractor scripts (Python) for:
  - [ ] External API time series (Weather, Economic, 5G) - **READ ONLY**
  - [ ] Existing CSV files (Nova Corrente data)
  - [ ] **Precomputed ML results** (forecasts, metrics) - **READ ONLY from external ML environment**
- [ ] Write Parquet to bronze partitioned by `date` (year/month/day)
- [ ] **Validate ML results schema:** Must include `model_version`, `generated_at`, `source`, `dataset_id` columns
- [ ] Keep schema explicit (validate column types)
- [ ] Add logging and error handling
- [ ] **Verify NO ML dependencies** in extractor scripts

**Acceptance Criteria:**
- ‚úÖ MinIO/S3 buckets accessible
- ‚úÖ Extractor scripts write Parquet to bronze
- ‚úÖ Partitioning works (year=YYYY/month=MM/day=DD)
- ‚úÖ Sample data ingestion successful
- ‚úÖ ML results include required metadata columns
- ‚úÖ NO ML dependencies in extractor scripts

**Output Files:**
- `backend/pipelines/extractors/` - Extractor scripts
- `backend/pipelines/extractors/api_extractor.py`
- `backend/pipelines/extractors/csv_extractor.py`
- `backend/pipelines/extractors/ml_results_extractor.py` - Precomputed ML results
- `docker-compose.yml` (MinIO service if using)

**Technical Specs:**
```python
# Example ML results schema validation
required_columns = ['model_version', 'generated_at', 'source', 'dataset_id']
for col in required_columns:
    if col not in df.columns:
        raise ValueError(f"ML results must include {col} column")
```

---

### **D2: Lightweight Transformations** ‚è±Ô∏è 6-8 hours
**Owner:** 1 Data Engineer  
**Deliverables:**

#### Transformation Scripts
- [ ] Implement SQL-like transformation scripts (Pandas/Spark job):
  - [ ] `stg_items.sql` or `stg_items.py` - Clean items data
  - [ ] `stg_forecasts.sql` or `stg_forecasts.py` - Clean forecasts data (from precomputed ML results)
  - [ ] `stg_inventory.sql` or `stg_inventory.py` - Clean inventory data
- [ ] Materialize outputs to silver Parquet
- [ ] Add basic validation (null checks, type casts, duplicates removal)
- [ ] **Preserve ML metadata:** Keep `model_version`, `generated_at`, `source`, `dataset_id` columns
- [ ] **Verify NO ML processing** in transformation scripts

**If dbt available (optional):**
- [ ] Install `dbt-core` + `dbt-spark` (or `dbt-duckdb`)
- [ ] Create `dbt_project.yml` with basic config
- [ ] Create `models/staging/` with SQL models
- [ ] Test `dbt run --models staging.*`
- [ ] **Verify NO ML dependencies** in dbt project

**Acceptance Criteria:**
- ‚úÖ Silver Parquet files created from bronze
- ‚úÖ Data cleaned (no nulls in key columns, types correct)
- ‚úÖ Duplicates removed
- ‚úÖ Schema validated
- ‚úÖ ML metadata preserved
- ‚úÖ NO ML processing in transformation scripts

**Output Files:**
- `backend/pipelines/transformations/` - Transformation scripts
- `backend/pipelines/transformations/stg_items.py`
- `backend/pipelines/transformations/stg_forecasts.py`
- `backend/pipelines/transformations/stg_inventory.py`
- OR `dbt/models/staging/` if using dbt

**Technical Specs:**
```python
# Example transformation - preserve ML metadata
def transform_forecasts(bronze_path, silver_path):
    df = pd.read_parquet(bronze_path)
    # Clean: trim, lowercase, type cast
    df['forecast'] = pd.to_numeric(df['forecast'], errors='coerce')
    df['actual'] = pd.to_numeric(df['actual'], errors='coerce')
    # Preserve ML metadata
    ml_metadata = ['model_version', 'generated_at', 'source', 'dataset_id']
    for col in ml_metadata:
        if col not in df.columns:
            raise ValueError(f"ML metadata column {col} missing")
    # Write to silver
    df.to_parquet(silver_path, partition_cols=['date'])
```

---

### **D3: Gold Models (Star Schema)** ‚è±Ô∏è 6-8 hours
**Owner:** 1 Data Engineer  
**Deliverables:**

#### Gold Layer Creation
- [ ] Create minimal star schema:
  - [ ] `dim_item.sql` or `.py` - Dimensions: `(id, sku, name, category)`
  - [ ] `dim_time.sql` or `.py` - Dimensions: `(date, year, month, day_of_week)`
  - [ ] `fact_forecast.sql` or `.py` - Facts: `(date, item_id, forecast, actual, source, model_version, generated_at, dataset_id)` - **PRECOMPUTED FROM ML**
- [ ] Only columns needed by dashboards (see Backend section for requirements)
- [ ] Precompute aggregates required by dashboards:
  - [ ] 7-day rolling averages (from precomputed forecasts)
  - [ ] 30-day totals (from precomputed forecasts)
  - [ ] TTL: cache daily (refresh schedule)
- [ ] **Preserve ML metadata** in fact tables

**Acceptance Criteria:**
- ‚úÖ Gold Parquet files created (dim_item, dim_time, fact_forecast)
- ‚úÖ Aggregates precomputed
- ‚úÖ Schema matches dashboard requirements
- ‚úÖ ML metadata included in fact_forecast
- ‚úÖ Query test: `SELECT * FROM fact_forecast WHERE date >= '2025-10-01'` returns < 2s

**Output Files:**
- `backend/pipelines/models/` - Gold models
- `backend/pipelines/models/dim_item.py`
- `backend/pipelines/models/dim_time.py`
- `backend/pipelines/models/fact_forecast.py`
- OR `dbt/models/marts/` if using dbt

**Technical Specs:**
```python
# Example fact table with ML metadata
fact_forecast = {
    'date': 'date',
    'item_id': 'string',
    'forecast': 'float',
    'actual': 'float',
    'source': 'string',  # 'prophet', 'arima', 'lstm', 'ensemble'
    'model_version': 'string',  # ML metadata
    'generated_at': 'timestamp',  # ML metadata
    'dataset_id': 'string',  # ML metadata
    'mape': 'float',
    'created_at': 'timestamp'
}
```

---

### **D4: Test & Deliver** ‚è±Ô∏è 4-6 hours
**Owner:** 1 Data Engineer  
**Deliverables:**

#### End-to-End Testing
- [ ] Run complete pipeline: pull ‚Üí bronze ‚Üí silver ‚Üí gold
- [ ] Validate Parquet queries via SQL (DuckDB or Spark SQL)
- [ ] Provide example SQL queries for backend endpoints:
  - [ ] `get_timeseries(item_id, start, end)` query
  - [ ] `get_aggregate(item_ids, window)` query
  - [ ] `get_inventory(item_id, date)` query
- [ ] Document data locations and access patterns
- [ ] Create `README_DATA.md` with usage examples
- [ ] **Verify NO ML dependencies** in entire pipeline

**Acceptance Criteria:**
- ‚úÖ End-to-end pipeline runs without error
- ‚úÖ All queries return expected results
- ‚úÖ Documentation complete
- ‚úÖ Backend can read Parquet files successfully
- ‚úÖ NO ML dependencies in pipeline

**Output Files:**
- `docs/data/README_DATA.md` - Data documentation
- `docs/data/example_queries.sql` - SQL examples
- `data/gold/` - Final gold layer Parquet files

---

## üîß SUB-TASKS & TECHNICAL SPECS

### Storage Specifications

#### MinIO Setup (Docker)
```yaml
# docker-compose.yml excerpt
services:
  minio:
    image: minio/minio:latest
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
```

#### S3 Setup (AWS)
```python
# Requirements
- AWS account
- IAM user with S3 access
- Buckets: nova-corrente-bronze, nova-corrente-silver, nova-corrente-gold
- Lifecycle policy: 90 days retention for bronze
```

#### Partitioning Strategy
```
Bronze: year=YYYY/month=MM/day=DD
Silver: date=YYYY-MM-DD (minimal partitioning)
Gold: date=YYYY-MM-DD (for query performance)
```

#### File Format
- **Format:** Parquet (snappy compression)
- **Schema:** Explicit column types (date/datetime, int/float, string/varchar)
- **Validation:** Schema registry JSON

---

### Schema Registry

**File:** `data/schema_registry.json`

```json
{
  "bronze": {
    "erp_items": {
      "item_id": "string",
      "item_name": "string",
      "cost": "float",
      "date": "date"
    },
    "forecasts": {
      "item_id": "string",
      "date": "date",
      "forecast": "float",
      "actual": "float",
      "source": "string",
      "model_version": "string",
      "generated_at": "timestamp",
      "dataset_id": "string"
    }
  },
  "silver": {
    "stg_items": {
      "item_id": "string (PK)",
      "item_name": "string (trimmed, lowercase)",
      "cost": "float",
      "date": "date"
    },
    "stg_forecasts": {
      "item_id": "string",
      "date": "date",
      "forecast": "float",
      "actual": "float",
      "source": "string",
      "model_version": "string",
      "generated_at": "timestamp",
      "dataset_id": "string"
    }
  },
  "gold": {
    "dim_item": {
      "item_id": "string (PK)",
      "sku": "string",
      "name": "string",
      "category": "string"
    },
    "fact_forecast": {
      "date": "date",
      "item_id": "string (FK)",
      "forecast": "float",
      "actual": "float",
      "source": "string",
      "model_version": "string",
      "generated_at": "timestamp",
      "dataset_id": "string",
      "mape": "float"
    }
  }
}
```

---

### Validation Specifications

#### Minimal Validation (No Great Expectations)
```python
# Basic validation checks
1. Not null: item_id, date, forecast, actual
2. Type validation: float columns are numeric
3. Range validation: forecast >= 0, actual >= 0
4. Uniqueness: (item_id, date, source) combination unique
5. Row count: Sample row counts match expected
6. ML metadata: model_version, generated_at, source, dataset_id present
```

#### Error Handling
- Log errors to `logs/data_ingestion.log`
- Retry failed API calls (3 attempts)
- Skip invalid rows (log and continue)
- Alert on critical failures (email/Slack)

---

## ‚úÖ SUCCESS CRITERIA (ACCEPTANCE TESTS)

### Functional Requirements
- [ ] ‚úÖ End-to-end job runs without error for sample day set
- [ ] ‚úÖ `fact_forecast` query of last 30 days aggregates returns < 2s on local/dev machine
- [ ] ‚úÖ All dashboard endpoints (see Backend section) return required fields (no missing keys)
- [ ] ‚úÖ Data quality: < 1% null values in key columns
- [ ] ‚úÖ Schema validation: All columns match schema registry

### Performance Requirements
- [ ] ‚úÖ Bronze ingestion: < 5 min for 1 day of data
- [ ] ‚úÖ Silver transformation: < 10 min for 1 day of data
- [ ] ‚úÖ Gold aggregation: < 15 min for 1 day of data
- [ ] ‚úÖ Query performance: < 2s for 30-day time series

### ML Ops Validation (MANDATORY)
- [ ] ‚úÖ No ML dependencies in ingestion scripts
- [ ] ‚úÖ No ML dependencies in transformation scripts
- [ ] ‚úÖ Only precomputed ML results ingested (no ML processing)
- [ ] ‚úÖ ML results include metadata (`model_version`, `generated_at`, `source`, `dataset_id`)
- [ ] ‚úÖ Deployment can run offline (no ML API calls)

### Documentation Requirements
- [ ] ‚úÖ Schema registry documented
- [ ] ‚úÖ Data locations documented
- [ ] ‚úÖ Example queries provided
- [ ] ‚úÖ Access patterns documented

---

## üö® SCOPE-REDUCTION OPTIONS (IF BLOCKERS)

### Option 1: Absolute Minimal (No External APIs)
**Trigger:** External APIs unavailable or rate-limited

**Changes:**
- Use existing CSVs only (from `data/processed/`)
- Map CSVs to schema directly
- Skip real-time ingestion
- Update documentation to reflect static data

**Impact:** ‚ö†Ô∏è No real-time updates, but functional for demo

**Constraint Compliance:** ‚úÖ Still compliant (no ML processing)

---

### Option 2: Minimal Analytics (No Dimensions)
**Trigger:** Time pressure or complex joins failing

**Changes:**
- Materialize only `fact_forecast` (no dims)
- Compute labels on backend (join in API layer)
- Simpler schema, faster to build

**Impact:** ‚ö†Ô∏è More complex queries in backend, but faster to deploy

**Constraint Compliance:** ‚úÖ Still compliant (no ML processing)

---

### Option 3: No Parquet (PostgreSQL Only)
**Trigger:** MinIO/Parquet provisioning stalls

**Changes:**
- Use PostgreSQL for small datasets (< 1GB)
- Store data in PostgreSQL tables
- Backend queries PostgreSQL directly
- Worse scale but faster to stand up

**Impact:** ‚ö†Ô∏è Doesn't scale well, but functional for MVP

**Constraint Compliance:** ‚úÖ Still compliant (no ML processing)

---

## üîó KEY RECOMMENDATIONS

### Technical Decisions
1. **Use DuckDB for Parquet queries** - Fastest path to SQL over Parquet without Spark
2. **Partition by date** - Enables efficient time series queries
3. **Precompute aggregates** - Reduces query time in dashboard
4. **Schema registry JSON** - Single source of truth for schema
5. **Preserve ML metadata** - Traceability for precomputed results

### Follow-Up Questions (Answer Quickly)
1. **Storage:** Do you have AWS account and prefer S3, or default to MinIO docker-compose?
2. **Transformation:** Prefer Python scripts or dbt SQL? (dbt recommended if time allows)
3. **Data Sources:** Which external APIs are critical? (Weather, Economic, 5G - prioritize)
4. **Schema:** What exact columns are needed by dashboard? (See Backend section)
5. **ML Results:** Where will precomputed ML results be stored? (shared storage path)

---

## üìö REFERENCE LINKS

- [Diagn√≥stico Completo](../COMPREHENSIVE_DATA_ENGINEERING_DIAGNOSTIC_PT_BR.md#storage-layer) - Storage gaps analysis
- [Tarefas Cr√≠ticas](../CRITICAL_TASKS_PRIORITY_LIST_PT_BR.md#task-11-setup-cloud-storage-s3minio) - TASK 1.1-1.4
- [Backend Cluster](./02_BACKEND_CLUSTER_4DAY_SPRINT_PT_BR.md) - API requirements
- [Global Constraints](./GLOBAL_CONSTRAINTS_NO_ML_OPS_PT_BR.md) - Complete policy
- [Roadmap Analytics](../../proj/roadmaps/ANALYTICS_ENGINEERING_ROADMAP_COMPLETE_PT_BR.md#arquitetura-dados) - Full architecture vision

---

## üìù NEXT STEPS

1. **Assign Cluster Lead:** Data Engineer
2. **Assign Team:** 1-2 Engineers
3. **Kickoff Meeting:** Review this document, assign tasks
4. **Daily Standup:** 9 AM - Review progress, blockers
5. **End of Day:** Acceptance test for each day's deliverables

---

**Documento criado:** Novembro 2025  
**Vers√£o:** 1.0  
**Status:** ‚úÖ Execution-Ready - 4-Day Sprint Plan

**CENTRALIZED REPORTS & CHANGELOG SYSTEM COMPLETE!**

