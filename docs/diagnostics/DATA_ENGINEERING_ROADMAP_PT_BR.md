# ğŸ—ºï¸ ROADMAP DE ENGENHARIA DE DADOS - NOVA CORRENTE
## Status Atual vs. Plano de ImplementaÃ§Ã£o (16 Semanas)

**VersÃ£o:** 3.0  
**Data:** Novembro 2025  
**Status:** ğŸ“‹ Roadmap Atualizado - Com Status Real de ImplementaÃ§Ã£o  
**Progresso Atual:** 15% Implementado (Fase 0 parcial)  
**Ãšltima AtualizaÃ§Ã£o DiagnÃ³stico:** Novembro 2025

---

## ğŸ“Š EXECUTIVE SUMMARY

### VisÃ£o Geral
Este roadmap define a implementaÃ§Ã£o completa da arquitetura de engenharia de dados para o projeto Nova Corrente, transformando o sistema atual (baseado em CSV e scripts Python) em uma plataforma moderna de Data Lakehouse com orquestraÃ§Ã£o profissional.

**ğŸ” IMPORTANTE:** Este documento foi atualizado com base no [diagnÃ³stico completo](./COMPREHENSIVE_DATA_ENGINEERING_DIAGNOSTIC_PT_BR.md) que identificou exatamente o que foi implementado e o que estÃ¡ faltando.

### Objetivos EstratÃ©gicos
1. **Escalabilidade:** Suportar crescimento de dados de GB â†’ TB
2. **Confiabilidade:** Garantir qualidade de dados (99.9% accuracy)
3. **Performance:** Reduzir tempo de processamento em 80%
4. **GovernanÃ§a:** Implementar data catalog e lineage tracking
5. **Self-Service:** Permitir anÃ¡lises sem dependÃªncia de engenharia

### MÃ©tricas de Sucesso
| MÃ©trica | Atual | Meta (16 semanas) | Status |
|---------|-------|-------------------|---------|
| **Data Quality Score** | 60% (validaÃ§Ã£o manual) | 95% (Great Expectations) | ğŸ”´ 35% gap |
| **Pipeline Latency** | 4h (batch scripts) | 30min (Airflow otimizado) | ğŸ”´ 88% gap |
| **Storage Efficiency** | CSV (27MB nÃ£o escalÃ¡vel) | Delta Lake (compressÃ£o 70%) | ğŸ”´ 100% gap |
| **Query Performance** | 30s (CSV full scan) | <3s (Delta Lake indexed) | ğŸ”´ 90% gap |
| **Data Governance** | 0% (sem catalog) | 90% (DataHub + lineage) | ğŸ”´ 100% gap |

### O Que JÃ¡ Existe âœ…
1. **ETL BÃ¡sico Python** - `orchestrator_service.py` com scheduler bÃ¡sico (schedule library)
2. **Feature Engineering** - 73 features implementadas em `backend/pipelines/feature_calculation_etl.py`
3. **Database PostgreSQL** - Schema inicial em `backend/data/Nova_Corrente_ML_Ready_DB.sql`
4. **Pipelines ETL** - Scripts Python para Anatel 5G, Weather, Economic, Brazilian Calendar
5. **Data Processing** - 19 scripts de processamento em `backend/pipelines/data_processing/`
6. **ValidaÃ§Ã£o BÃ¡sica** - Scripts manuais em `backend/pipelines/monitoring/`
7. **API FastAPI** - Endpoints bÃ¡sicos em `backend/api/enhanced_api.py`

### O Que NÃƒO Existe âŒ
1. **Data Lakehouse (Bronze/Silver/Gold)** - 0% implementado
2. **Delta Lake** - 0% implementado
3. **dbt (data build tool)** - 0% implementado
4. **Apache Airflow** - 0% implementado (apenas scheduler Python bÃ¡sico)
5. **Great Expectations** - 0% implementado
6. **MLflow** - 0% implementado
7. **Star Schema (Gold Layer)** - 0% implementado
8. **Metabase/Superset** - 0% implementado
9. **DataHub Catalog** - 0% implementado
10. **Cloud Storage (S3/MinIO)** - 0% implementado

---

## ğŸ“‹ RESUMO EXECUTIVO: O QUE JÃ FOI FEITO vs. O QUE FALTA

### ğŸŸ¢ IMPLEMENTADO (15%)

| Componente | Status | LocalizaÃ§Ã£o | Qualidade |
|------------|--------|---------------|----------|
| **ETL Pipelines** | âœ… 70% | `backend/pipelines/*.py` | Funcional, mas sem Airflow |
| **Feature Engineering** | âœ… 100% | `backend/pipelines/feature_calculation_etl.py` | 73 features completas |
| **Data Collectors** | âœ… 80% | `backend/data/collectors/` | Weather, Economic, 5G |
| **PostgreSQL Schema** | âœ… 60% | `backend/data/Nova_Corrente_ML_Ready_DB.sql` | Schema inicial, nÃ£o star schema |
| **Orchestrator BÃ¡sico** | âš ï¸ 20% | `backend/pipelines/orchestrator_service.py` | Scheduler Python, sem UI |
| **ML Models** | âœ… 90% | `backend/ml/models/` | Prophet, ARIMA, LSTM |
| **Model Registry BÃ¡sico** | âš ï¸ 10% | `backend/services/ml_models/` | Pickle local, sem MLflow |
| **API FastAPI** | âœ… 80% | `backend/api/enhanced_api.py` | Endpoints bÃ¡sicos |
| **DocumentaÃ§Ã£o** | âœ… 100% | `docs/` | Completa e detalhada |

### ğŸ”´ FALTANDO (85%)

| Componente | Status | Impacto | Prioridade |
|------------|--------|---------|------------|
| **Cloud Storage (MinIO/S3)** | âŒ 0% | Bloqueando TUDO | ğŸ”´ğŸ”´ğŸ”´ CRÃTICA |
| **Delta Lake** | âŒ 0% | Sem ACID, sem scala | ğŸ”´ğŸ”´ğŸ”´ CRÃTICA |
| **dbt** | âŒ 0% | Transform sem testes | ğŸ”´ğŸ”´ğŸ”´ CRÃTICA |
| **Apache Airflow** | âŒ 0% | Orq. sem UI/retry | ğŸ”´ğŸ”´ğŸ”´ CRÃTICA |
| **Bronze/Silver/Gold Layers** | âŒ 0% | Arquitetura incompleta | ğŸ”´ğŸ”´ ALTA |
| **Great Expectations** | âŒ 0% | Qualidade nÃ£o validada | ğŸ”´ğŸ”´ ALTA |
| **Star Schema (Gold)** | âŒ 0% | Analytics nÃ£o otimizado | ğŸŸ¡ MÃ‰DIA |
| **MLflow** | âŒ 0% | ML sem tracking | ğŸŸ¡ MÃ‰DIA |
| **Metabase/BI** | âŒ 0% | Sem self-service | ğŸŸ¡ MÃ‰DIA |
| **DataHub Catalog** | âŒ 0% | Sem governanÃ§a | ğŸŸ¢ BAIXA |
| **Streaming (Kafka)** | âŒ 0% | Sem real-time | ğŸŸ¢ BAIXA |

---

## ğŸ¯ PRÃ“XIMOS PASSOS PRIORITÃRIOS

### ğŸ”¥ SPRINT 1: FUNDAÃ‡ÃƒO CRÃTICA (Semana 1-2)
**Objetivo:** Estabelecer infraestrutura base que estÃ¡ bloqueando tudo

**Tasks em Ordem de ExecuÃ§Ã£o:**

1. **TASK 1.1: Setup MinIO** (Dia 1-2)
   - ğŸ¯ Bloqueia tudo
   - ğŸ“ Criar buckets Bronze/Silver/Gold
   - ğŸ“ Migrar CSV existentes para MinIO
   - âœ… CritÃ©rio: MinIO rodando + dados migrados

2. **TASK 1.2: Implementar Delta Lake** (Dia 3-7)
   - ğŸ¯ Depende de MinIO
   - ğŸ“ Setup PySpark + Delta Lake
   - ğŸ“ Migrar dados para Delta format
   - âœ… CritÃ©rio: ACID transactions funcionando

3. **TASK 1.3: Setup dbt** (Dia 8-12)
   - ğŸ¯ Depende de Delta Lake
   - ğŸ“ Criar projeto dbt
   - ğŸ“ Migrar transformaÃ§Ãµes Python â†’ SQL
   - âœ… CritÃ©rio: 5 staging models rodando

4. **TASK 1.4: Setup Airflow** (Dia 8-12, paralelo com dbt)
   - ğŸ¯ Depende de MinIO + Delta Lake
   - ğŸ“ Substituir orchestrator_service.py
   - ğŸ“ Criar DAGs
   - âœ… CritÃ©rio: Airflow UI + DAGs rodando

**Resultado Esperado ApÃ³s Sprint 1:**
- âœ… Infraestrutura base funcionando
- âœ… Dados em Delta Lake (nÃ£o mais CSV)
- âœ… TransformaÃ§Ãµes versionadas (dbt)
- âœ… OrquestraÃ§Ã£o profissional (Airflow)
- ğŸ“ˆ Progresso: 15% â†’ 40%

---

### ğŸŸ¡ SPRINT 2: CAMADA DE DADOS (Semana 3-4)
**Objetivo:** Implementar Bronze/Silver com qualidade

**Tasks:**

5. **TASK 2.1: Bronze Layer** (Dia 13-16)
   - Refatorar extractors existentes
   - Salvar em MinIO/Bronze (Parquet)
   - Particionamento year/month/day

6. **TASK 2.2: Silver Layer** (Dia 17-21)
   - Criar dbt staging models
   - Limpeza e validaÃ§Ã£o
   - Testes dbt

7. **TASK 2.3: Great Expectations** (Dia 22-26)
   - Expectation suites
   - Data quality reports
   - Alertas automÃ¡ticos

**Resultado Esperado ApÃ³s Sprint 2:**
- âœ… Bronze layer ingerindo dados daily
- âœ… Silver layer com dados limpos
- âœ… Qualidade >95% validada
- ğŸ“ˆ Progresso: 40% â†’ 65%

---

### ğŸŸ¢ SPRINT 3-4: ANALYTICS + ML OPS (Semana 5-12)
**Objetivo:** Gold layer + MLflow (menor prioridade, pode ser adiado)

**Tasks (em ordem):**

8. **TASK 3.1: Gold Layer (Star Schema)** - Semana 5-6
9. **TASK 3.2: Metabase** - Semana 7
10. **TASK 3.3: dbt Metrics** - Semana 7
11. **TASK 4.1: MLflow** - Semana 9-10
12. **TASK 4.2: Feature Store (Opcional)** - Semana 11-12

**Resultado Esperado ApÃ³s Sprint 3-4:**
- âœ… Analytics layer completo
- âœ… BI self-service funcionando
- âœ… ML tracking profissional
- ğŸ“ˆ Progresso: 65% â†’ 90%

---

## ğŸš¨ BLOQUEADORES CRÃTICOS IDENTIFICADOS

### 1ï¸âƒ£ Falta de Cloud Storage
**Problema:** CSV files nÃ£o escalam, sem backup, sem ACID  
**SoluÃ§Ã£o:** TASK 1.1 (MinIO) - **URGENTE**  
**Impacto:** Bloqueando 100% do roadmap

### 2ï¸âƒ£ Falta de Delta Lake
**Problema:** Sem transaÃ§Ãµes ACID, sem time travel, sem schema evolution  
**SoluÃ§Ã£o:** TASK 1.2 (Delta Lake) - **URGENTE**  
**Impacto:** Bloqueando Silver/Gold layers

### 3ï¸âƒ£ Falta de dbt
**Problema:** TransformaÃ§Ãµes nÃ£o versionadas, sem testes, cÃ³digo duplicado  
**SoluÃ§Ã£o:** TASK 1.3 (dbt) - **URGENTE**  
**Impacto:** Qualidade nÃ£o garantida

### 4ï¸âƒ£ Falta de Airflow
**Problema:** Orchestrator bÃ¡sico sem UI, retry, alerting  
**SoluÃ§Ã£o:** TASK 1.4 (Airflow) - **URGENTE**  
**Impacto:** OperaÃ§Ãµes difÃ­ceis, debugging complexo

---

## ğŸ“Š MÃ‰TRICAS DE PROGRESSO ATUALIZADAS

### Por Fase

| Fase | Planejado | Real Atual | Gap | PrÃ³xima Meta |
|------|-----------|------------|-----|---------------|
| **Fase 0: Foundation** | 100% | **15%** | 85% | 40% (apÃ³s Sprint 1) |
| **Fase 1: Data Foundation** | 100% | **40%** | 60% | 65% (apÃ³s Sprint 2) |
| **Fase 2: Analytics Layer** | 100% | **0%** | 100% | 25% (apÃ³s Sprint 3) |
| **Fase 3: ML Ops** | 100% | **10%** | 90% | 50% (apÃ³s Sprint 4) |
| **Fase 4: Advanced** | 100% | **0%** | 100% | Adiado (post-MVP) |
| **TOTAL** | 100% | **15%** | 85% | **40%** (meta 4 semanas) |

### Por Componente

| Componente | Atual | Meta 4 Sem | Meta 8 Sem | Meta 16 Sem |
|------------|-------|------------|------------|-------------|
| **Storage (MinIO/S3)** | 0% | **100%** | 100% | 100% |
| **Delta Lake** | 0% | **100%** | 100% | 100% |
| **dbt** | 0% | **80%** | 100% | 100% |
| **Airflow** | 20% | **100%** | 100% | 100% |
| **Bronze Layer** | 50% | 80% | **100%** | 100% |
| **Silver Layer** | 0% | 60% | **100%** | 100% |
| **Great Expectations** | 0% | 50% | **100%** | 100% |
| **Gold Layer** | 0% | 0% | 50% | **100%** |
| **Metabase** | 0% | 0% | 50% | **100%** |
| **MLflow** | 0% | 0% | 30% | **100%** |
| **DataHub** | 0% | 0% | 0% | 80% |

---

### FASE 0: FOUNDATION (Semanas 1-2) - **FUNDAÃ‡ÃƒO CRÃTICA**
**Objetivo:** Estabelecer infraestrutura base  
**Progresso Real:** ğŸ”´ **15%** (somente documentaÃ§Ã£o e scripts bÃ¡sicos)  
**Status:** âš ï¸ CRÃTICO - Bloqueando todas as outras fases

#### âœ… O Que JÃ FOI FEITO
- âœ… DocumentaÃ§Ã£o completa do projeto
- âœ… Scripts Python ETL bÃ¡sicos (clima, economia, 5G)
- âœ… Orchestrator Python com scheduler bÃ¡sico (`schedule` library)
- âœ… PostgreSQL schema inicial
- âš ï¸ Docker Compose bÃ¡sico (backend, frontend, scheduler)

#### âŒ O Que FALTA FAZER
- âŒ Cloud Storage (S3/MinIO) - 0% implementado
- âŒ Delta Lake - 0% implementado
- âŒ dbt project - 0% implementado
- âŒ Apache Airflow - 0% implementado
- âŒ Terraform IaC - 0% implementado

#### Stack TecnolÃ³gico
```yaml
Storage:
  - Cloud: AWS S3 / Azure Blob / MinIO (self-hosted)
  - Format: Delta Lake (ACID transactions)
  - Partitioning: year/month/day

Transformation:
  - Framework: dbt (data build tool)
  - Language: SQL + Jinja2
  - Testing: dbt tests + Great Expectations

Orchestration:
  - Engine: Apache Airflow 2.x
  - Deployment: Docker Compose / Kubernetes
  - Scheduler: Cron + Event-based

Infrastructure:
  - IaC: Terraform
  - Containers: Docker + Docker Compose
  - CI/CD: GitHub Actions
```

#### Tasks CrÃ­ticas

##### ğŸ”´ TASK 1.1: Setup Cloud Storage (3-5 dias)
**Prioridade:** CRÃTICA  
**Owner:** Data Engineering Lead  
**Status Atual:** âŒ **NÃƒO INICIADO** (0%)  
**Impacto:** Bloqueando TUDO - sem storage escalÃ¡vel, nada funciona

**SituaÃ§Ã£o Atual:**
- âŒ Dados armazenados em CSV files (`data/processed/*.csv`, `data/raw/*.csv`)
- âŒ Total: ~27MB de dados (NÃƒO ESCALA para TB)
- âŒ Sem particionamento, sem ACID, sem versionamento
- âŒ Sem backup automÃ¡tico, sem disaster recovery

**Subtarefas:**
- [ ] **CRÃTICO:** Provisionar MinIO local (alternativa gratuita ao S3)
  - [ ] `nova-corrente-bronze` (raw data) - Parquet files
  - [ ] `nova-corrente-silver` (cleaned data) - Delta Lake
  - [ ] `nova-corrente-gold` (analytics-ready) - Star Schema
- [ ] Configurar MinIO access keys e policies
- [ ] Setup lifecycle policies (Bronze: 90d retention)
- [ ] Migrar dados CSV existentes â†’ MinIO/Parquet
- [ ] Testar upload/download de arquivos
- [ ] Documentar acesso e credenciais

**DependÃªncias:** Nenhuma  
**Bloqueia:** TASK 1.2, 1.3, 1.4, 2.1

**CritÃ©rios de Aceite:**
- âœ… MinIO rodando via Docker Compose
- âœ… Buckets criados e acessÃ­veis
- âœ… Dados CSV migrados para Parquet
- âœ… Scripts de teste executados com sucesso
- âœ… DocumentaÃ§Ã£o completa

**Alternativa AWS:** Se orÃ§amento permitir, usar AWS S3 ($100-300/mÃªs para ~1TB)

---

##### ğŸ”´ TASK 1.2: Implementar Delta Lake (5-7 dias)
**Prioridade:** CRÃTICA  
**Owner:** Data Engineering Lead  
**Status Atual:** âŒ **NÃƒO INICIADO** (0%)  
**Impacto:** Sem ACID, sem time travel, sem schema evolution

**SituaÃ§Ã£o Atual:**
- âŒ CSV files sem transaÃ§Ãµes ACID
- âŒ Sem versionamento de dados (nÃ£o consegue rollback)
- âŒ Sem schema evolution (mudanÃ§as quebram sistema)
- âŒ Sem otimizaÃ§Ã£o de queries (full scan sempre)
- âŒ Sem compactaÃ§Ã£o eficiente

**Dados Existentes para Migrar:**
```
data/processed/
â”œâ”€â”€ unified_dataset_with_factors.csv (27MB, 118K rows, 31 features)
â”œâ”€â”€ feature_engineered_data.csv
data/training/
â”œâ”€â”€ unknown_train.csv (93,881 rows)
â”œâ”€â”€ unknown_test.csv (23,471 rows)
data/raw/
â”œâ”€â”€ anatel_5g/ (dados brutos 5G)
â”œâ”€â”€ weather/ (dados climÃ¡ticos)
â”œâ”€â”€ economic/ (dados econÃ´micos)
â””â”€â”€ ... (33 subdiretorios)
```

**Subtarefas:**
- [ ] Setup PySpark local (ou Databricks Community Edition)
- [ ] Instalar Delta Lake libraries (`pip install delta-spark`)
- [ ] Criar Bronze layer (raw data)
  - [ ] Migrar `data/raw/**/*.csv` â†’ Parquet â†’ Delta
  - [ ] Implementar particionamento `year/month/day`
  - [ ] Adicionar metadata (source, extraction_time)
- [ ] Criar Silver layer (cleaned data)
  - [ ] Migrar `data/processed/*.csv` â†’ Delta
- [ ] Testar ACID transactions (insert, update, delete)
- [ ] Testar time travel (versioning, rollback)
- [ ] Configurar Z-ordering para queries otimizadas
- [ ] Setup Delta Lake metadata catalog

**DependÃªncias:** TASK 1.1 (MinIO/S3)  
**Bloqueia:** TASK 1.3, 2.1, 2.2

**CritÃ©rios de Aceite:**
- âœ… Bronze layer com todos os dados migrados
- âœ… ACID transactions testadas e funcionando
- âœ… Time travel funcionando (rollback para versÃ£o anterior)
- âœ… Particionamento por data otimizado
- âœ… Performance: queries 10x mais rÃ¡pidas que CSV
- âœ… CompressÃ£o: 70% reduÃ§Ã£o em storage vs CSV

---

##### ğŸ”´ TASK 1.3: Setup dbt Project (4-6 dias)
**Prioridade:** CRÃTICA  
**Owner:** Analytics Engineer  
**Status Atual:** âŒ **NÃƒO IMPLEMENTADO** (0%)  
**Impacto:** TransformaÃ§Ãµes nÃ£o versionadas, sem testes, sem documentaÃ§Ã£o

**SituaÃ§Ã£o Atual:**
- âŒ TransformaÃ§Ãµes em scripts Python (`backend/pipelines/data_processing/*.py`)
- âŒ 19 scripts de processamento SEM versionamento adequado
- âŒ Sem testes automÃ¡ticos de qualidade
- âŒ Sem documentaÃ§Ã£o automÃ¡tica
- âŒ CÃ³digo duplicado entre scripts
- âŒ DifÃ­cil manutenÃ§Ã£o e debugging

**Scripts Existentes para Migrar:**
```
backend/pipelines/data_processing/
â”œâ”€â”€ data_aggregation.py
â”œâ”€â”€ data_cleaning.py
â”œâ”€â”€ feature_engineering.py
â”œâ”€â”€ time_series_preparation.py
â””â”€â”€ ... (15+ scripts de transformaÃ§Ã£o)
```

**Subtarefas:**
- [ ] Instalar `dbt-core` + `dbt-spark` (para Delta Lake)
- [ ] Criar estrutura do projeto dbt:
  ```
  dbt_nova_corrente/
  â”œâ”€â”€ dbt_project.yml
  â”œâ”€â”€ profiles.yml (conexÃ£o Delta Lake)
  â”œâ”€â”€ models/
  â”‚   â”œâ”€â”€ staging/ (camada Silver)
  â”‚   â”‚   â”œâ”€â”€ stg_items.sql
  â”‚   â”‚   â”œâ”€â”€ stg_towers.sql
  â”‚   â”‚   â”œâ”€â”€ stg_weather.sql
  â”‚   â”‚   â”œâ”€â”€ stg_economic.sql
  â”‚   â”‚   â””â”€â”€ stg_5g.sql
  â”‚   â”œâ”€â”€ intermediate/
  â”‚   â””â”€â”€ marts/ (camada Gold)
  â”œâ”€â”€ tests/ (validaÃ§Ãµes automÃ¡ticas)
  â”œâ”€â”€ macros/ (reorder_point, safety_stock)
  â””â”€â”€ docs/
  ```
- [ ] Migrar transformaÃ§Ãµes Python â†’ SQL dbt models
- [ ] Criar testes dbt (not_null, unique, relationships)
- [ ] Configurar CI/CD (GitHub Actions para dbt test/run)
- [ ] Gerar dbt docs (documentaÃ§Ã£o HTML automÃ¡tica)

**DependÃªncias:** TASK 1.2 (Delta Lake)  
**Bloqueia:** TASK 2.2, 2.3, 3.1

**CritÃ©rios de Aceite:**
- âœ… dbt project inicializado e funcionando
- âœ… ConexÃ£o com Delta Lake testada
- âœ… Pelo menos 5 staging models rodando (stg_items, stg_towers, etc.)
- âœ… Testes dbt passando (100% coverage)
- âœ… CI/CD configurado (GitHub Actions)
- âœ… DocumentaÃ§Ã£o HTML gerada (dbt docs generate)

---

##### ğŸ”´ TASK 1.4: Setup Apache Airflow (4-6 dias)
**Prioridade:** CRÃTICA  
**Owner:** Data Engineering Lead  
**Status Atual:** âš ï¸ **20% PARCIAL** (apenas Python scheduler bÃ¡sico)  
**Impacto:** Sem orquestraÃ§Ã£o visual, sem retry automÃ¡tico, difÃ­cil monitoramento

**SituaÃ§Ã£o Atual:**
- âš ï¸ **JÃ EXISTE:** `orchestrator_service.py` com scheduler bÃ¡sico
  - Usa biblioteca `schedule` (Python puro)
  - Threading bÃ¡sico para execuÃ§Ã£o
  - Sem UI, sem visualizaÃ§Ã£o de DAGs
  - Sem retry automÃ¡tico
  - Sem alerting integrado
  - DifÃ­cil debugging

**CÃ³digo Existente:**
```python
# backend/pipelines/orchestrator_service.py
class OrchestratorService:
    def start_scheduler(self, time_str: str = "02:00"):
        schedule.every().day.at(time_str).do(self.run_complete_pipeline)
        # Threading bÃ¡sico - sem Airflow
```

**O Que FALTA:**
- âŒ Apache Airflow Web UI (visualizaÃ§Ã£o de DAGs)
- âŒ Retry policies automÃ¡ticas
- âŒ DependÃªncias entre tasks visuais
- âŒ Alerting integrado (Slack/Email)
- âŒ Logs centralizados e searchable
- âŒ Backfill automÃ¡tico

**Subtarefas:**
- [ ] Setup Airflow via Docker Compose
  - [ ] Web server (port 8080)
  - [ ] Scheduler
  - [ ] Worker (Celery executor)
  - [ ] PostgreSQL metadata DB
  - [ ] Redis (message broker)
- [ ] Configurar conexÃµes Airflow:
  - [ ] MinIO/S3 connection
  - [ ] Delta Lake/Spark connection
  - [ ] PostgreSQL connection
- [ ] Criar DAGs (migrar de orchestrator_service.py):
  - [ ] `extract_bronze_dag.py` (ingestÃ£o daily)
  - [ ] `bronze_to_silver_dag.py` (limpeza + validaÃ§Ã£o)
  - [ ] `silver_to_gold_dag.py` (analytics layer)
- [ ] Migrar lÃ³gica de `orchestrator_service.py` â†’ Airflow DAGs
- [ ] Configurar retry policies (3 tentativas, exponential backoff)
- [ ] Setup alerting (Slack webhook ou Email SMTP)
- [ ] Configurar monitoring dashboard

**DependÃªncias:** TASK 1.1 (MinIO), TASK 1.2 (Delta Lake)  
**Bloqueia:** TASK 2.1, 2.2, 2.3

**CritÃ©rios de Aceite:**
- âœ… Airflow rodando (web UI acessÃ­vel em localhost:8080)
- âœ… Pelo menos 3 DAGs criados e executando
- âœ… Retry funcionando (testar com falha proposital)
- âœ… Alertas configurados (Slack ou Email)
- âœ… Logs centralizados e searchable
- âœ… `orchestrator_service.py` depreciado (substituÃ­do por Airflow)

---

### FASE 1: DATA FOUNDATION (Semanas 3-4) - **CAMADA DE DADOS**
**Objetivo:** Implementar Bronze/Silver layers  
**Progresso Real:** ğŸŸ¡ **40%** (pipelines ETL existem, mas sem Medallion architecture)  
**Status:** âš ï¸ PARCIAL - Precisa refatorar para Bronze/Silver

#### âœ… O Que JÃ FOI FEITO
- âœ… **Pipelines ETL implementados:**
  - `anatel_5g_etl.py` - ExtraÃ§Ã£o dados 5G da Anatel
  - `climate_etl.py` - ExtraÃ§Ã£o dados climÃ¡ticos
  - `economic_etl.py` - ExtraÃ§Ã£o dados econÃ´micos
  - `brazilian_calendar_etl.py` - CalendÃ¡rio brasileiro (feriados)
  - `feature_calculation_etl.py` - CÃ¡lculo de 73 features
- âœ… Data collectors em `backend/data/collectors/`
- âœ… Data loaders em `backend/data/loaders/`
- âœ… Feature engineering bÃ¡sico implementado

#### âŒ O Que FALTA FAZER
- âŒ Bronze Layer (raw data em Delta Lake) - 0%
- âŒ Silver Layer (cleaned data em Delta Lake) - 0%
- âŒ Particionamento year/month/day - 0%
- âŒ Great Expectations (validaÃ§Ã£o automÃ¡tica) - 0%
- âŒ dbt staging models - 0%
- âŒ Data quality reports automÃ¡ticos - 0%

#### Arquitetura Medallion

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SOURCES                               â”‚
â”‚  ERP | Weather API | Economic API | 5G API | Manual Uploads â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BRONZE LAYER (Raw)                        â”‚
â”‚  - Formato: Parquet + Delta Lake                            â”‚
â”‚  - Particionamento: year/month/day                          â”‚
â”‚  - RetenÃ§Ã£o: 90 dias                                        â”‚
â”‚  - Schema: Exactly as source                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SILVER LAYER (Cleaned)                     â”‚
â”‚  - TransformaÃ§Ã£o: dbt staging models                        â”‚
â”‚  - ValidaÃ§Ã£o: Great Expectations                            â”‚
â”‚  - DeduplicaÃ§Ã£o, limpeza, type casting                      â”‚
â”‚  - Schema validado e documentado                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Tasks Principais

##### ğŸŸ¡ TASK 2.1: Criar Bronze Layer (3-4 dias)
**Prioridade:** ALTA  
**Owner:** Data Engineer  
**Status Atual:** âš ï¸ **50% PARCIAL** (extractors existem, falta Bronze layer)  
**Impacto:** Dados brutos nÃ£o organizados, sem particionamento

**SituaÃ§Ã£o Atual:**
- âœ… **JÃ EXISTEM extractors:**
  - `climate_etl.py` - Weather API (OpenWeather implementado)
  - `economic_etl.py` - Economic API (Banco Central implementado)
  - `anatel_5g_etl.py` - 5G API (Anatel implementado)
  - `brazilian_calendar_etl.py` - CalendÃ¡rio brasileiro
- âš ï¸ **MAS:** Salvam em CSV (`data/raw/`), nÃ£o em Bronze Layer
- âŒ Sem particionamento year/month/day
- âŒ Sem metadata padronizada (extraction_time, source)
- âŒ Sem Airflow DAG (apenas `orchestrator_service.py`)

**O Que FALTA:**
- âŒ Refatorar extractors para salvar em MinIO/Bronze (Parquet)
- âŒ Implementar particionamento automÃ¡tico
- âŒ Adicionar metadata padronizada
- âŒ Migrar de orchestrator_service.py â†’ Airflow DAG

**Subtarefas:**
- [ ] **Refatorar extractors existentes:**
  - [ ] Modificar `climate_etl.py` â†’ salvar em MinIO/Bronze/Parquet
  - [ ] Modificar `economic_etl.py` â†’ salvar em MinIO/Bronze/Parquet
  - [ ] Modificar `anatel_5g_etl.py` â†’ salvar em MinIO/Bronze/Parquet
  - [ ] Modificar `brazilian_calendar_etl.py` â†’ salvar em MinIO/Bronze/Parquet
- [ ] Implementar particionamento year/month/day em cada extractor
- [ ] Adicionar metadata padrÃ£o:
  ```python
  metadata = {
      'extraction_time': datetime.now(),
      'source': 'anatel_api',
      'dataset_id': 'bronze_5g_towers',
      'version': '1.0'
  }
  ```
- [ ] Criar Airflow DAG `extract_bronze_dag.py`:
  ```python
  extract_climate >> extract_economic >> extract_5g >> extract_calendar
  ```
- [ ] Setup monitoring de ingestÃ£o (alertas se falhar)

**DependÃªncias:** TASK 1.1 (MinIO), TASK 1.4 (Airflow)  
**Bloqueia:** TASK 2.2

**CritÃ©rios de Aceite:**
- âœ… Dados brutos salvos em MinIO/Bronze (Parquet + Delta)
- âœ… Particionamento year/month/day funcionando
- âœ… Metadata padronizada em todos os datasets
- âœ… Airflow DAG executando diariamente
- âœ… Monitoring configurado (alertas em caso de falha)

---

##### ğŸŸ¡ TASK 2.2: Criar Silver Layer - dbt Staging (5-7 dias)
**Prioridade:** ALTA  
**Owner:** Analytics Engineer

**Subtarefas:**
- [ ] Criar dbt staging models:
  - [ ] `stg_items.sql` (limpeza de itens)
  - [ ] `stg_towers.sql` (limpeza de torres)
  - [ ] `stg_forecasts.sql` (limpeza de previsÃµes)
  - [ ] `stg_weather.sql`
  - [ ] `stg_economic.sql`
  - [ ] `stg_5g.sql`
- [ ] Implementar transformaÃ§Ãµes:
  - Trim strings
  - Lowercase/normalize categoricals
  - Type casting (int, float, date)
  - Remove duplicates
  - Handle nulls
- [ ] Criar testes dbt:
  - `not_null` tests
  - `unique` tests
  - `relationships` tests (FK validation)
  - Custom tests (business logic)
- [ ] Materializar como Delta tables (Silver layer)
- [ ] Documentar modelos (schema.yml)

**DependÃªncias:** TASK 1.3 (dbt), TASK 2.1 (Bronze)  
**Bloqueia:** TASK 2.3, 3.1

**CritÃ©rios de Aceite:**
- âœ… Staging models criados e testados
- âœ… Dados limpos em Silver layer
- âœ… Testes dbt passando
- âœ… DocumentaÃ§Ã£o completa

---

##### ğŸŸ¡ TASK 2.3: Setup Great Expectations (4-6 dias)
**Prioridade:** ALTA  
**Owner:** Data Quality Engineer

**Subtarefas:**
- [ ] Instalar Great Expectations
- [ ] Criar expectation suites:
  - [ ] `items_expectations.json`
    - expect_column_values_to_not_be_null
    - expect_column_values_to_be_unique
    - expect_column_values_to_be_in_set
  - [ ] `towers_expectations.json`
  - [ ] `forecasts_expectations.json`
- [ ] Configurar checkpoints (validation points)
- [ ] Integrar com Airflow (validation task)
- [ ] Gerar data docs (HTML reports)
- [ ] Configurar alertas (Slack/Email)
- [ ] Setup historical validation tracking

**DependÃªncias:** TASK 2.2 (Silver Layer)  
**Bloqueia:** TASK 3.1

**CritÃ©rios de Aceite:**
- âœ… Expectation suites criadas
- âœ… Checkpoints configurados
- âœ… ValidaÃ§Ã£o automÃ¡tica funcionando
- âœ… Data docs gerados
- âœ… Alertas configurados

---

### FASE 2: ANALYTICS LAYER (Semanas 5-8) - **CAMADA ANALÃTICA**
**Objetivo:** Implementar Gold layer (Star Schema)  
**Progresso Real:** âŒ **0%** (nada implementado)  
**Status:** ğŸ”´ CRÃTICO - Bloqueado por Fase 0 e 1

#### âœ… O Que JÃ FOI FEITO
- âš ï¸ PostgreSQL schema inicial existe (`backend/data/Nova_Corrente_ML_Ready_DB.sql`)
- âš ï¸ Mas NÃƒO Ã© modelagem dimensional (star schema)

#### âŒ O Que FALTA FAZER
- âŒ Gold Layer (Star Schema) - 0%
- âŒ DimensÃµes (dim_items, dim_towers, dim_time) - 0%
- âŒ Fatos (fact_forecasts, fact_inventory) - 0%
- âŒ dbt marts - 0%
- âŒ Metabase - 0%
- âŒ dbt Metrics - 0%
- âŒ BI Dashboards - 0%

**Bloqueador:** Fase 0 (Delta Lake, dbt) e Fase 1 (Silver layer) precisam estar completos primeiro

#### Modelagem Dimensional

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     GOLD LAYER (Analytics)                   â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  dim_items   â”‚     â”‚ fact_forecasts   â”‚                 â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                 â”‚
â”‚  â”‚ item_id (PK) â”‚â—„â”€â”€â”€â”€â”¤ item_id (FK)     â”‚                 â”‚
â”‚  â”‚ item_name    â”‚     â”‚ tower_id (FK)    â”‚                 â”‚
â”‚  â”‚ category     â”‚     â”‚ date_id (FK)     â”‚                 â”‚
â”‚  â”‚ supplier     â”‚     â”‚ forecasted_qty   â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ actual_qty       â”‚                 â”‚
â”‚                       â”‚ mape             â”‚                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚  â”‚ dim_towers   â”‚                                           â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ tower_id(PK) â”‚â—„â”€â”€â”€â”€â”¤ fact_inventory   â”‚                 â”‚
â”‚  â”‚ tower_name   â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                 â”‚
â”‚  â”‚ region       â”‚     â”‚ item_id (FK)     â”‚                 â”‚
â”‚  â”‚ 5g_status    â”‚     â”‚ tower_id (FK)    â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ date_id (FK)     â”‚                 â”‚
â”‚                       â”‚ stock_level      â”‚                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ reorder_point    â”‚                 â”‚
â”‚  â”‚  dim_time    â”‚     â”‚ safety_stock     â”‚                 â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚  â”‚ date_id (PK) â”‚                                           â”‚
â”‚  â”‚ date         â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚  â”‚ year         â”‚                                           â”‚
â”‚  â”‚ month        â”‚                                           â”‚
â”‚  â”‚ day_of_week  â”‚                                           â”‚
â”‚  â”‚ is_holiday   â”‚                                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Tasks Principais

##### ğŸŸ¢ TASK 3.1: Criar Gold Layer - Star Schema (7-10 dias)
**Prioridade:** MÃ‰DIA  
**Owner:** Analytics Engineer

**Subtarefas:**
- [ ] Criar dimensÃµes (dbt marts):
  - [ ] `dim_items.sql`
    ```sql
    -- SCD Type 2 para histÃ³rico de mudanÃ§as
    SELECT
      item_id,
      item_name,
      category,
      supplier,
      valid_from,
      valid_to,
      is_current
    FROM {{ ref('stg_items') }}
    ```
  - [ ] `dim_towers.sql`
  - [ ] `dim_time.sql` (calendar dimension)
- [ ] Criar fatos:
  - [ ] `fact_forecasts.sql`
    ```sql
    -- Grain: item x tower x date
    SELECT
      i.item_id,
      t.tower_id,
      d.date_id,
      f.forecasted_qty,
      f.actual_qty,
      ABS(f.forecasted_qty - f.actual_qty) / f.actual_qty AS mape
    FROM {{ ref('stg_forecasts') }} f
    LEFT JOIN {{ ref('dim_items') }} i ON f.item = i.item_name
    LEFT JOIN {{ ref('dim_towers') }} t ON f.tower = t.tower_name
    LEFT JOIN {{ ref('dim_time') }} d ON f.date = d.date
    ```
  - [ ] `fact_inventory.sql`
- [ ] Configurar particionamento e clustering
- [ ] Materializar como Delta tables (Gold layer)
- [ ] Criar testes dbt (referential integrity)
- [ ] Documentar modelos (ER diagram)

**DependÃªncias:** TASK 2.2 (Silver Layer)  
**Bloqueia:** TASK 3.2, 3.3

**CritÃ©rios de Aceite:**
- âœ… Star schema implementado
- âœ… DimensÃµes e fatos materializados
- âœ… Testes de integridade passando
- âœ… Performance otimizada (< 3s queries)
- âœ… DocumentaÃ§Ã£o completa

---

##### ğŸŸ¢ TASK 3.2: Setup Metabase (2-3 dias)
**Prioridade:** MÃ‰DIA  
**Owner:** BI Engineer

**Subtarefas:**
- [ ] Setup Metabase via Docker Compose
- [ ] Conectar com Gold layer (via Spark JDBC)
- [ ] Criar dashboards bÃ¡sicos:
  - [ ] **Forecast Accuracy Dashboard**
    - MAPE por item
    - MAPE por torre
    - MAPE trend (temporal)
  - [ ] **Inventory Levels Dashboard**
    - Stock atual por item
    - Items abaixo do reorder point
    - Safety stock coverage
  - [ ] **Demand Forecast Dashboard**
    - PrevisÃµes prÃ³ximos 30 dias
    - ComparaÃ§Ã£o com histÃ³rico
- [ ] Configurar usuÃ¡rios e permissÃµes
- [ ] Setup scheduled email reports

**DependÃªncias:** TASK 3.1 (Gold Layer)  
**Bloqueia:** Nenhuma

**CritÃ©rios de Aceite:**
- âœ… Metabase rodando e acessÃ­vel
- âœ… Dashboards criados e funcionais
- âœ… UsuÃ¡rios configurados
- âœ… Reports agendados

---

##### ğŸŸ¢ TASK 3.3: Criar dbt Metrics (3-4 dias)
**Prioridade:** MÃ‰DIA  
**Owner:** Analytics Engineer

**Subtarefas:**
- [ ] Criar `metrics.yml` com mÃ©tricas de negÃ³cio:
  ```yaml
  metrics:
    - name: forecast_accuracy
      label: Forecast Accuracy (MAPE)
      type: average
      sql: mape
      timestamp: date
      time_grains: [day, week, month]
      dimensions: [item_id, tower_id]
  
    - name: total_forecasted_demand
      label: Total Forecasted Demand
      type: sum
      sql: forecasted_qty
      timestamp: date
  
    - name: inventory_turnover
      label: Inventory Turnover
      type: derived
      sql: total_demand / avg_inventory
  ```
- [ ] Testar mÃ©tricas (dbt run-metrics)
- [ ] Expor via dbt Semantic Layer API
- [ ] Integrar com Metabase

**DependÃªncias:** TASK 3.1 (Gold Layer)  
**Bloqueia:** Nenhuma

**CritÃ©rios de Aceite:**
- âœ… MÃ©tricas definidas e testadas
- âœ… Semantic Layer API funcionando
- âœ… Metabase consumindo mÃ©tricas

---

### FASE 3: ML OPS (Semanas 9-12) - **MACHINE LEARNING OPS**
**Objetivo:** Implementar MLflow e Feature Store  
**Progresso Real:** âš ï¸ **10%** (model registry bÃ¡sico existe)  
**Status:** ğŸŸ¡ PARCIAL - ML existe, mas sem MLflow

âš ï¸ **IMPORTANTE:** Seguindo a polÃ­tica [GLOBAL_CONSTRAINTS_NO_ML_OPS_PT_BR.md](./clusters/GLOBAL_CONSTRAINTS_NO_ML_OPS_PT_BR.md), o ML Ops NÃƒO estarÃ¡ no deployment de produÃ§Ã£o. Apenas resultados prÃ©-computados serÃ£o expostos.

#### âœ… O Que JÃ FOI FEITO
- âœ… **Modelos ML implementados:**
  - `backend/ml/models/` - Prophet, ARIMA, LSTM implementados
  - `backend/ml/training/` - Scripts de treinamento
  - `backend/ml/inference/` - Scripts de inferÃªncia
- âœ… Model registry bÃ¡sico: `backend/services/ml_models/model_registry.py`
- âœ… Feature engineering: 73 features calculadas
- âš ï¸ **MAS:** Modelos salvos em Pickle local, sem versionamento adequado

#### âŒ O Que FALTA FAZER
- âŒ MLflow (experiment tracking, model registry, serving) - 0%
- âŒ Feature Store (Feast/Tecton) - 0%
- âŒ Model monitoring (drift detection) - 0%
- âŒ A/B testing setup - 0%
- âŒ Precomputed results pipeline (para deployment) - 0%

#### Tasks Principais

##### ğŸŸ¢ TASK 4.1: Setup MLflow (4-6 dias)
**Prioridade:** MÃ‰DIA  
**Owner:** ML Engineer

**Subtarefas:**
- [ ] Setup MLflow via Docker Compose
  - Tracking Server
  - Model Registry
  - Artifact Store (S3)
  - Backend Store (PostgreSQL)
- [ ] Integrar MLflow tracking nos modelos:
  - [ ] Prophet model
  - [ ] ARIMA model
  - [ ] LSTM model
- [ ] Configurar experiment tracking:
  ```python
  import mlflow
  
  with mlflow.start_run():
      mlflow.log_params({"horizon": 30, "seasonality": "weekly"})
      mlflow.log_metrics({"mape": 0.12, "rmse": 45.3})
      mlflow.log_model(model, "prophet_model")
  ```
- [ ] Criar model registry (staging, production)
- [ ] Configurar model serving (REST API)
- [ ] Setup monitoring de modelos (drift detection)

**DependÃªncias:** Nenhuma (pode ser paralelo)  
**Bloqueia:** Nenhuma

**CritÃ©rios de Aceite:**
- âœ… MLflow rodando (web UI acessÃ­vel)
- âœ… Experiment tracking funcionando
- âœ… Model registry criado
- âœ… Model serving testado

---

##### ğŸŸ¢ TASK 4.2: Feature Store (Opcional) (7-10 dias)
**Prioridade:** BAIXA  
**Owner:** ML Engineer

**Subtarefas:**
- [ ] Avaliar Feast vs Tecton
- [ ] Setup feature store escolhido
- [ ] Migrar features existentes (73 features):
  - Temporal features (lags, rolling windows)
  - Weather features
  - Economic features
  - 5G features
- [ ] Criar feature views
- [ ] Integrar com ML training
- [ ] Setup feature monitoring

**DependÃªncias:** TASK 4.1 (MLflow)  
**Bloqueia:** Nenhuma

**CritÃ©rios de Aceite:**
- âœ… Feature store rodando
- âœ… Features migradas
- âœ… Feature serving funcionando

---

### FASE 4: ADVANCED FEATURES (Semanas 13-16) - **RECURSOS AVANÃ‡ADOS**
**Objetivo:** Implementar Data Catalog e otimizaÃ§Ãµes  
**Progresso Real:** âŒ **0%** (nada implementado)  
**Status:** ğŸ”´ NÃƒO INICIADO - Menor prioridade

#### âŒ O Que FALTA FAZER
- âŒ DataHub (data catalog) - 0%
- âŒ Lineage tracking - 0%
- âŒ Performance optimization (Z-ordering, clustering) - 0%
- âŒ Streaming pipeline (Kafka, Flink) - 0%
- âŒ Self-service analytics - 0%

**Nota:** Fase 4 Ã© opcional para MVP, pode ser adiada se houver restriÃ§Ã£o de tempo/orÃ§amento

#### Tasks Principais

##### ğŸŸ¡ TASK 5.1: Setup DataHub (4-6 dias)
**Prioridade:** BAIXA  
**Owner:** Data Engineer

**Subtarefas:**
- [ ] Setup DataHub via Docker Compose
- [ ] Ingestar metadata de datasets:
  - Delta Lake tables
  - dbt models
  - Airflow DAGs
- [ ] Configurar lineage tracking
- [ ] Adicionar ownership e tags
- [ ] Configurar search e discovery
- [ ] Integrar com autenticaÃ§Ã£o (SSO)

**DependÃªncias:** Nenhuma (pode ser paralelo)  
**Bloqueia:** Nenhuma

**CritÃ©rios de Aceite:**
- âœ… DataHub rodando (web UI acessÃ­vel)
- âœ… Metadata ingestado
- âœ… Lineage visualizado
- âœ… Search funcionando

---

##### ğŸŸ¡ TASK 5.2: Performance Optimization (5-7 dias)
**Prioridade:** BAIXA  
**Owner:** Data Engineer

**Subtarefas:**
- [ ] Implementar Z-ordering em Delta tables
- [ ] Configurar liquid clustering
- [ ] Otimizar particionamento
- [ ] Setup caching (Redis/Memcached)
- [ ] Implementar query pushdown
- [ ] Benchmark performance (before/after)

**DependÃªncias:** TASK 3.1 (Gold Layer)  
**Bloqueia:** Nenhuma

**CritÃ©rios de Aceite:**
- âœ… Query performance < 3s
- âœ… Storage efficiency > 70%
- âœ… Benchmark completo

---

##### ğŸŸ¡ TASK 5.3: Streaming Pipeline (Opcional) (10-14 dias)
**Prioridade:** BAIXA  
**Owner:** Data Engineer

**Subtarefas:**
- [ ] Setup Kafka cluster
- [ ] Criar topics (items, forecasts, alerts)
- [ ] Implementar Kafka producers
- [ ] Setup Flink/Spark Streaming
- [ ] Criar streaming jobs
- [ ] Integrar com batch pipelines (Lambda architecture)
- [ ] Setup monitoring (Prometheus + Grafana)

**DependÃªncias:** TASK 1.4 (Airflow)  
**Bloqueia:** Nenhuma

**CritÃ©rios de Aceite:**
- âœ… Kafka rodando
- âœ… Streaming jobs processando dados
- âœ… Alertas em tempo real funcionando

---

## ğŸ“ˆ TRACKING & MONITORING

### KPIs por Fase

| Fase | KPI | Meta | Como Medir |
|------|-----|------|------------|
| **Fase 0** | Infrastructure Up | 100% | Todos os serviÃ§os rodando |
| **Fase 1** | Data Quality Score | >95% | Great Expectations reports |
| **Fase 2** | Query Performance | <3s | Benchmark queries |
| **Fase 3** | Model Accuracy | MAPE <15% | MLflow metrics |
| **Fase 4** | Data Discovery | >90% | DataHub usage metrics |

### Monitoring Dashboard

```yaml
Metrics to Track:
  - Pipeline Success Rate (target: >99%)
  - Data Freshness (target: <1h delay)
  - Storage Growth (monitor monthly)
  - Query Performance (P95 <3s)
  - Data Quality Score (>95%)
  - Model Performance (MAPE <15%)
```

---

## ğŸš¨ RISK MANAGEMENT

### Riscos Identificados

| Risco | Probabilidade | Impacto | MitigaÃ§Ã£o |
|-------|--------------|---------|-----------|
| **Cloud costs exceeding budget** | Alta | Alto | Start with MinIO (self-hosted), migrate later |
| **Team lacks dbt experience** | MÃ©dia | MÃ©dio | Training + pair programming |
| **Data sources unstable** | Alta | Alto | Implement retry logic + alerting |
| **Performance issues** | MÃ©dia | Alto | Early benchmarking + optimization |
| **Scope creep** | Alta | MÃ©dio | Strict phase gates + sign-offs |

### Contingency Plans

1. **Budget Overrun:** Usar MinIO ao invÃ©s de S3
2. **Timeline Delay:** Priorizar Fase 0-1, adiar Fase 4
3. **Technical Blocker:** Escalar para arquiteto sÃªnior

---

## âœ… DEFINITION OF DONE

### Por Fase

#### Fase 0: Foundation
- [ ] S3 buckets provisionados e acessÃ­veis
- [ ] Delta Lake com dados migrados
- [ ] dbt project com pelo menos 1 modelo funcionando
- [ ] Airflow com pelo menos 1 DAG executando
- [ ] CI/CD configurado (GitHub Actions)
- [ ] DocumentaÃ§Ã£o tÃ©cnica completa

#### Fase 1: Data Foundation
- [ ] Bronze layer ingerindo dados diariamente
- [ ] Silver layer com staging models materializados
- [ ] Great Expectations validando qualidade (>95% score)
- [ ] Testes dbt passando (100% coverage)
- [ ] Data profiling reports gerados

#### Fase 2: Analytics Layer
- [ ] Gold layer com star schema implementado
- [ ] Metabase com dashboards criados
- [ ] dbt metrics funcionando
- [ ] Query performance <3s (P95)
- [ ] BI users treinados

#### Fase 3: ML Ops
- [ ] MLflow tracking funcionando
- [ ] Model registry com modelos versionados
- [ ] Feature store implementado (opcional)
- [ ] Model serving testado
- [ ] Monitoring de modelos configurado

#### Fase 4: Advanced
- [ ] DataHub catalog populado
- [ ] Performance otimizado (70% storage savings)
- [ ] Streaming pipeline funcionando (opcional)
- [ ] GovernanÃ§a completa (lineage, ownership)

---

## ğŸ“š DOCUMENTATION & TRAINING

### DocumentaÃ§Ã£o NecessÃ¡ria

1. **Architecture Diagrams**
   - Data flow diagrams
   - Infrastructure diagrams
   - Network diagrams

2. **Technical Docs**
   - dbt model documentation
   - Airflow DAG documentation
   - API documentation

3. **Runbooks**
   - Incident response
   - Deployment procedures
   - Backup/restore procedures

4. **User Guides**
   - Metabase user guide
   - DataHub search guide
   - Self-service analytics guide

### Training Plan

| Audience | Training | Duration |
|----------|----------|----------|
| **Data Engineers** | dbt + Airflow workshop | 2 dias |
| **Analytics Engineers** | dbt advanced patterns | 1 dia |
| **BI Users** | Metabase self-service | 4 horas |
| **Developers** | Data catalog usage | 2 horas |

---

## ğŸ¯ NEXT STEPS

### Immediate Actions (This Week)

1. **Setup Project Kickoff Meeting**
   - Align on roadmap
   - Assign owners
   - Set up communication channels

2. **Provision Infrastructure**
   - Create AWS/GCP accounts (ou setup MinIO)
   - Setup GitHub repository
   - Configure CI/CD

3. **Start TASK 1.1: Cloud Storage**
   - Create S3 buckets
   - Configure IAM
   - Test connectivity

### Week 2-4 Focus

- Complete Fase 0 (Foundation)
- Start Fase 1 (Data Foundation)
- Weekly sync meetings
- Risk monitoring

---

## ğŸ“ STAKEHOLDER COMMUNICATION

### Weekly Status Report Template

```markdown
# Data Engineering Weekly Status - Week X

## Progress
- âœ… Completed: [Task list]
- ğŸš§ In Progress: [Task list]
- ğŸ”´ Blocked: [Task list with blockers]

## Metrics
- Data Quality Score: XX%
- Pipeline Success Rate: XX%
- Storage Used: XX GB

## Risks & Issues
- [List of active risks]
- [Mitigation actions]

## Next Week Plan
- [Task list]
```

### Monthly Steering Committee Review

- Phase completion status
- Budget vs actual
- Risk register update
- Go/No-Go decision for next phase

---

## ğŸ“Š APPENDIX

### A. Technology Stack Details

```yaml
Storage:
  - Delta Lake 2.x
  - AWS S3 / Azure Blob / MinIO

Transformation:
  - dbt-core 1.7+
  - dbt-databricks / dbt-spark

Orchestration:
  - Apache Airflow 2.8+
  - Celery executor

Data Quality:
  - Great Expectations 0.18+

ML Ops:
  - MLflow 2.10+
  - Feast 0.35+ (optional)

BI:
  - Metabase 0.48+
  - Apache Superset (optional)

Data Catalog:
  - DataHub 0.12+

Streaming (Optional):
  - Apache Kafka 3.6+
  - Apache Flink 1.18+
```

### B. Cost Estimation

| Component | Monthly Cost (USD) | Notes |
|-----------|-------------------|-------|
| **S3 Storage** | $100-300 | ~1TB data |
| **Compute (Airflow)** | $200-400 | t3.large EC2 |
| **Delta Lake (Databricks)** | $500-1000 | Community edition free |
| **Monitoring** | $50-100 | CloudWatch/Datadog |
| **Total** | **$850-1800** | Or $0 with self-hosted MinIO |

**Self-Hosted Alternative:** ~$200/month (bare metal servers)

### C. Team Structure

```
Data Engineering Team (4-6 pessoas)
â”œâ”€â”€ Data Engineering Lead (1)
â”‚   â””â”€â”€ ResponsÃ¡vel por Fase 0-1
â”œâ”€â”€ Analytics Engineer (1-2)
â”‚   â””â”€â”€ ResponsÃ¡vel por dbt + Fase 2
â”œâ”€â”€ ML Engineer (1)
â”‚   â””â”€â”€ ResponsÃ¡vel por Fase 3
â””â”€â”€ Data Quality Engineer (1)
    â””â”€â”€ ResponsÃ¡vel por Great Expectations
```

---

**Documento criado:** Novembro 2025  
**VersÃ£o:** 3.0  
**Status:** âœ… Roadmap Atualizado - Status Real Baseado em DiagnÃ³stico Completo

**ReferÃªncias:**
- [DiagnÃ³stico Completo](./COMPREHENSIVE_DATA_ENGINEERING_DIAGNOSTIC_PT_BR.md) - Gap analysis detalhado
- [Lista de Tarefas CrÃ­ticas](./CRITICAL_TASKS_PRIORITY_LIST_PT_BR.md) - Tasks priorizadas
- [Constraints Globais](./clusters/GLOBAL_CONSTRAINTS_NO_ML_OPS_PT_BR.md) - PolÃ­tica de ML Ops

**Resumo de MudanÃ§as (v3.0):**
- âœ… Adicionado status real de implementaÃ§Ã£o baseado em cÃ³digo existente
- âœ… Identificado o que JÃ FOI FEITO (15%) vs. o que FALTA (85%)
- âœ… Atualizado progresso por fase e componente
- âœ… Adicionado bloqueadores crÃ­ticos identificados
- âœ… Criado plano de sprints prioritÃ¡rio (Sprint 1-2 crÃ­ticos)
- âœ… Detalhado situaÃ§Ã£o atual de cada task com arquivos existentes
- âœ… Adicionado mÃ©tricas de progresso realistas (0% â†’ 40% â†’ 65% â†’ 90%)

**PrÃ³xima AÃ§Ã£o Imediata:**
ğŸ”´ **TASK 1.1: Setup MinIO** - Bloqueando TUDO, comeÃ§ar HOJE!
